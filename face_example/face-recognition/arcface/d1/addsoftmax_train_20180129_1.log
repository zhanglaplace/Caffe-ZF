I0129 17:58:12.458088 30839 caffe.cpp:218] Using GPUs 0
I0129 17:58:12.505587 30839 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I0129 17:58:13.413612 30839 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.1
display: 100
max_iter: 70000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "face_snapshot/vgg_train_test"
solver_mode: GPU
device_id: 0
net: "face_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 60000
stepvalue: 70000
iter_size: 1
I0129 17:58:13.413779 30839 solver.cpp:87] Creating training net from net file: face_train_test.prototxt
I0129 17:58:13.414692 30839 net.cpp:51] Initializing net from parameters: 
name: "Face-ResNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.0078125
    mirror: true
    mean_value: 128
  }
  image_data_param {
    source: "/data/vggface2/VGGFACE_train_list-112X96-add.txt"
    batch_size: 256
    shuffle: true
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "PReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "PReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_3"
  type: "Convolution"
  bottom: "conv1_2"
  top: "conv1_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_3"
  type: "PReLU"
  bottom: "conv1_3"
  top: "conv1_3"
}
layer {
  name: "res1_3"
  type: "Eltwise"
  bottom: "conv1_1"
  bottom: "conv1_3"
  top: "res1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "res1_3"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_3"
  type: "PReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "res2_3"
  type: "Eltwise"
  bottom: "conv2_1"
  bottom: "conv2_3"
  top: "res2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4"
  type: "Convolution"
  bottom: "res2_3"
  top: "conv2_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_4"
  type: "PReLU"
  bottom: "conv2_4"
  top: "conv2_4"
}
layer {
  name: "conv2_5"
  type: "Convolution"
  bottom: "conv2_4"
  top: "conv2_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_5"
  type: "PReLU"
  bottom: "conv2_5"
  top: "conv2_5"
}
layer {
  name: "res2_5"
  type: "Eltwise"
  bottom: "res2_3"
  bottom: "conv2_5"
  top: "res2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "res2_5"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "res3_3"
  type: "Eltwise"
  bottom: "conv3_1"
  bottom: "conv3_3"
  top: "res3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "res3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3_4"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "PReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "res3_5"
  type: "Eltwise"
  bottom: "res3_3"
  bottom: "conv3_5"
  top: "res3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_6"
  type: "Convolution"
  bottom: "res3_5"
  top: "conv3_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_6"
  type: "PReLU"
  bottom: "conv3_6"
  top: "conv3_6"
}
layer {
  name: "conv3_7"
  type: "Convolution"
  bottom: "conv3_6"
  top: "conv3_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_7"
  type: "PReLU"
  bottom: "conv3_7"
  top: "conv3_7"
}
layer {
  name: "res3_7"
  type: "Eltwise"
  bottom: "res3_5"
  bottom: "conv3_7"
  top: "res3_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_8"
  type: "Convolution"
  bottom: "res3_7"
  top: "conv3_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_8"
  type: "PReLU"
  bottom: "conv3_8"
  top: "conv3_8"
}
layer {
  name: "conv3_9"
  type: "Convolution"
  bottom: "conv3_8"
  top: "conv3_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_9"
  type: "PReLU"
  bottom: "conv3_9"
  top: "conv3_9"
}
layer {
  name: "res3_9"
  type: "Eltwise"
  bottom: "res3_7"
  bottom: "conv3_9"
  top: "res3_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "res3_9"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "res4_3"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_3"
  top: "res4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res4_3"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "norm1"
  type: "Normalize"
  bottom: "fc5"
  top: "norm1"
}
layer {
  name: "fc6_l2"
  type: "InnerProduct"
  bottom: "norm1"
  top: "fc6"
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 9131
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    normalize: true
  }
}
layer {
  name: "label_Margin"
  type: "LabelMargin"
  bottom: "fc6"
  bottom: "label"
  top: "fc6_margin"
  label_margin_param {
    bias: 0.35
  }
}
layer {
  name: "fc6_margin_scale"
  type: "Scale"
  bottom: "fc6_margin"
  top: "fc6_margin_scale"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      type: "constant"
      value: 64
    }
    min_value: 30
  }
}
layer {
  name: "softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc6_margin_scale"
  bottom: "label"
  top: "softmax_loss"
  loss_weight: 1
}
I0129 17:58:13.415001 30839 layer_factory.hpp:77] Creating layer data
I0129 17:58:13.415032 30839 net.cpp:84] Creating Layer data
I0129 17:58:13.415042 30839 net.cpp:380] data -> data
I0129 17:58:13.415062 30839 net.cpp:380] data -> label
I0129 17:58:13.415128 30839 image_data_layer.cpp:38] Opening file /data/vggface2/VGGFACE_train_list-112X96-add.txt
I0129 17:58:15.326050 30839 image_data_layer.cpp:53] Shuffling data
I0129 17:58:16.596108 30839 image_data_layer.cpp:63] A total of 3306982 images.
I0129 17:58:16.598242 30839 image_data_layer.cpp:90] output data size: 256,3,112,96
I0129 17:58:16.710125 30839 net.cpp:122] Setting up data
I0129 17:58:16.710180 30839 net.cpp:129] Top shape: 256 3 112 96 (8257536)
I0129 17:58:16.710188 30839 net.cpp:129] Top shape: 256 (256)
I0129 17:58:16.710191 30839 net.cpp:137] Memory required for data: 33031168
I0129 17:58:16.710217 30839 layer_factory.hpp:77] Creating layer label_data_1_split
I0129 17:58:16.710242 30839 net.cpp:84] Creating Layer label_data_1_split
I0129 17:58:16.710250 30839 net.cpp:406] label_data_1_split <- label
I0129 17:58:16.710269 30839 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0129 17:58:16.710286 30839 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0129 17:58:16.710346 30839 net.cpp:122] Setting up label_data_1_split
I0129 17:58:16.710355 30839 net.cpp:129] Top shape: 256 (256)
I0129 17:58:16.710360 30839 net.cpp:129] Top shape: 256 (256)
I0129 17:58:16.710362 30839 net.cpp:137] Memory required for data: 33033216
I0129 17:58:16.710367 30839 layer_factory.hpp:77] Creating layer conv1_1
I0129 17:58:16.710392 30839 net.cpp:84] Creating Layer conv1_1
I0129 17:58:16.710397 30839 net.cpp:406] conv1_1 <- data
I0129 17:58:16.710407 30839 net.cpp:380] conv1_1 -> conv1_1
I0129 17:58:17.508129 30839 net.cpp:122] Setting up conv1_1
I0129 17:58:17.508177 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.508182 30839 net.cpp:137] Memory required for data: 209193984
I0129 17:58:17.508208 30839 layer_factory.hpp:77] Creating layer relu1_1
I0129 17:58:17.508234 30839 net.cpp:84] Creating Layer relu1_1
I0129 17:58:17.508237 30839 net.cpp:406] relu1_1 <- conv1_1
I0129 17:58:17.508244 30839 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0129 17:58:17.512259 30839 net.cpp:122] Setting up relu1_1
I0129 17:58:17.512290 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.512293 30839 net.cpp:137] Memory required for data: 385354752
I0129 17:58:17.512302 30839 layer_factory.hpp:77] Creating layer conv1_1_relu1_1_0_split
I0129 17:58:17.512313 30839 net.cpp:84] Creating Layer conv1_1_relu1_1_0_split
I0129 17:58:17.512317 30839 net.cpp:406] conv1_1_relu1_1_0_split <- conv1_1
I0129 17:58:17.512334 30839 net.cpp:380] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_0
I0129 17:58:17.512344 30839 net.cpp:380] conv1_1_relu1_1_0_split -> conv1_1_relu1_1_0_split_1
I0129 17:58:17.512396 30839 net.cpp:122] Setting up conv1_1_relu1_1_0_split
I0129 17:58:17.512405 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.512409 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.512413 30839 net.cpp:137] Memory required for data: 737676288
I0129 17:58:17.512416 30839 layer_factory.hpp:77] Creating layer conv1_2
I0129 17:58:17.512428 30839 net.cpp:84] Creating Layer conv1_2
I0129 17:58:17.512434 30839 net.cpp:406] conv1_2 <- conv1_1_relu1_1_0_split_0
I0129 17:58:17.512442 30839 net.cpp:380] conv1_2 -> conv1_2
I0129 17:58:17.517158 30839 net.cpp:122] Setting up conv1_2
I0129 17:58:17.517184 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.517210 30839 net.cpp:137] Memory required for data: 913837056
I0129 17:58:17.517220 30839 layer_factory.hpp:77] Creating layer relu1_2
I0129 17:58:17.517236 30839 net.cpp:84] Creating Layer relu1_2
I0129 17:58:17.517241 30839 net.cpp:406] relu1_2 <- conv1_2
I0129 17:58:17.517246 30839 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0129 17:58:17.517437 30839 net.cpp:122] Setting up relu1_2
I0129 17:58:17.517447 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.517451 30839 net.cpp:137] Memory required for data: 1089997824
I0129 17:58:17.517455 30839 layer_factory.hpp:77] Creating layer conv1_3
I0129 17:58:17.517465 30839 net.cpp:84] Creating Layer conv1_3
I0129 17:58:17.517468 30839 net.cpp:406] conv1_3 <- conv1_2
I0129 17:58:17.517474 30839 net.cpp:380] conv1_3 -> conv1_3
I0129 17:58:17.523545 30839 net.cpp:122] Setting up conv1_3
I0129 17:58:17.523561 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.523566 30839 net.cpp:137] Memory required for data: 1266158592
I0129 17:58:17.523573 30839 layer_factory.hpp:77] Creating layer relu1_3
I0129 17:58:17.523584 30839 net.cpp:84] Creating Layer relu1_3
I0129 17:58:17.523588 30839 net.cpp:406] relu1_3 <- conv1_3
I0129 17:58:17.523593 30839 net.cpp:367] relu1_3 -> conv1_3 (in-place)
I0129 17:58:17.523782 30839 net.cpp:122] Setting up relu1_3
I0129 17:58:17.523792 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.523795 30839 net.cpp:137] Memory required for data: 1442319360
I0129 17:58:17.523803 30839 layer_factory.hpp:77] Creating layer res1_3
I0129 17:58:17.523815 30839 net.cpp:84] Creating Layer res1_3
I0129 17:58:17.523820 30839 net.cpp:406] res1_3 <- conv1_1_relu1_1_0_split_1
I0129 17:58:17.523825 30839 net.cpp:406] res1_3 <- conv1_3
I0129 17:58:17.523830 30839 net.cpp:380] res1_3 -> res1_3
I0129 17:58:17.523862 30839 net.cpp:122] Setting up res1_3
I0129 17:58:17.523870 30839 net.cpp:129] Top shape: 256 64 56 48 (44040192)
I0129 17:58:17.523874 30839 net.cpp:137] Memory required for data: 1618480128
I0129 17:58:17.523876 30839 layer_factory.hpp:77] Creating layer conv2_1
I0129 17:58:17.523888 30839 net.cpp:84] Creating Layer conv2_1
I0129 17:58:17.523891 30839 net.cpp:406] conv2_1 <- res1_3
I0129 17:58:17.523900 30839 net.cpp:380] conv2_1 -> conv2_1
I0129 17:58:17.530488 30839 net.cpp:122] Setting up conv2_1
I0129 17:58:17.530515 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.530520 30839 net.cpp:137] Memory required for data: 1706560512
I0129 17:58:17.530526 30839 layer_factory.hpp:77] Creating layer relu2_1
I0129 17:58:17.530535 30839 net.cpp:84] Creating Layer relu2_1
I0129 17:58:17.530539 30839 net.cpp:406] relu2_1 <- conv2_1
I0129 17:58:17.530546 30839 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0129 17:58:17.530704 30839 net.cpp:122] Setting up relu2_1
I0129 17:58:17.530716 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.530719 30839 net.cpp:137] Memory required for data: 1794640896
I0129 17:58:17.530725 30839 layer_factory.hpp:77] Creating layer conv2_1_relu2_1_0_split
I0129 17:58:17.530730 30839 net.cpp:84] Creating Layer conv2_1_relu2_1_0_split
I0129 17:58:17.530733 30839 net.cpp:406] conv2_1_relu2_1_0_split <- conv2_1
I0129 17:58:17.530741 30839 net.cpp:380] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_0
I0129 17:58:17.530748 30839 net.cpp:380] conv2_1_relu2_1_0_split -> conv2_1_relu2_1_0_split_1
I0129 17:58:17.530787 30839 net.cpp:122] Setting up conv2_1_relu2_1_0_split
I0129 17:58:17.530795 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.530799 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.530802 30839 net.cpp:137] Memory required for data: 1970801664
I0129 17:58:17.530805 30839 layer_factory.hpp:77] Creating layer conv2_2
I0129 17:58:17.530818 30839 net.cpp:84] Creating Layer conv2_2
I0129 17:58:17.530823 30839 net.cpp:406] conv2_2 <- conv2_1_relu2_1_0_split_0
I0129 17:58:17.530833 30839 net.cpp:380] conv2_2 -> conv2_2
I0129 17:58:17.533638 30839 net.cpp:122] Setting up conv2_2
I0129 17:58:17.533675 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.533679 30839 net.cpp:137] Memory required for data: 2058882048
I0129 17:58:17.533686 30839 layer_factory.hpp:77] Creating layer relu2_2
I0129 17:58:17.533694 30839 net.cpp:84] Creating Layer relu2_2
I0129 17:58:17.533699 30839 net.cpp:406] relu2_2 <- conv2_2
I0129 17:58:17.533704 30839 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0129 17:58:17.533862 30839 net.cpp:122] Setting up relu2_2
I0129 17:58:17.533871 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.533875 30839 net.cpp:137] Memory required for data: 2146962432
I0129 17:58:17.533879 30839 layer_factory.hpp:77] Creating layer conv2_3
I0129 17:58:17.533890 30839 net.cpp:84] Creating Layer conv2_3
I0129 17:58:17.533895 30839 net.cpp:406] conv2_3 <- conv2_2
I0129 17:58:17.533903 30839 net.cpp:380] conv2_3 -> conv2_3
I0129 17:58:17.542505 30839 net.cpp:122] Setting up conv2_3
I0129 17:58:17.542536 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.542539 30839 net.cpp:137] Memory required for data: 2235042816
I0129 17:58:17.542553 30839 layer_factory.hpp:77] Creating layer relu2_3
I0129 17:58:17.542572 30839 net.cpp:84] Creating Layer relu2_3
I0129 17:58:17.542587 30839 net.cpp:406] relu2_3 <- conv2_3
I0129 17:58:17.542593 30839 net.cpp:367] relu2_3 -> conv2_3 (in-place)
I0129 17:58:17.542763 30839 net.cpp:122] Setting up relu2_3
I0129 17:58:17.542774 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.542778 30839 net.cpp:137] Memory required for data: 2323123200
I0129 17:58:17.542783 30839 layer_factory.hpp:77] Creating layer res2_3
I0129 17:58:17.542791 30839 net.cpp:84] Creating Layer res2_3
I0129 17:58:17.542795 30839 net.cpp:406] res2_3 <- conv2_1_relu2_1_0_split_1
I0129 17:58:17.542801 30839 net.cpp:406] res2_3 <- conv2_3
I0129 17:58:17.542809 30839 net.cpp:380] res2_3 -> res2_3
I0129 17:58:17.542840 30839 net.cpp:122] Setting up res2_3
I0129 17:58:17.542847 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.542850 30839 net.cpp:137] Memory required for data: 2411203584
I0129 17:58:17.542855 30839 layer_factory.hpp:77] Creating layer res2_3_res2_3_0_split
I0129 17:58:17.542860 30839 net.cpp:84] Creating Layer res2_3_res2_3_0_split
I0129 17:58:17.542863 30839 net.cpp:406] res2_3_res2_3_0_split <- res2_3
I0129 17:58:17.542876 30839 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_0
I0129 17:58:17.542891 30839 net.cpp:380] res2_3_res2_3_0_split -> res2_3_res2_3_0_split_1
I0129 17:58:17.542930 30839 net.cpp:122] Setting up res2_3_res2_3_0_split
I0129 17:58:17.542940 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.542945 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.542948 30839 net.cpp:137] Memory required for data: 2587364352
I0129 17:58:17.542951 30839 layer_factory.hpp:77] Creating layer conv2_4
I0129 17:58:17.542966 30839 net.cpp:84] Creating Layer conv2_4
I0129 17:58:17.542976 30839 net.cpp:406] conv2_4 <- res2_3_res2_3_0_split_0
I0129 17:58:17.542984 30839 net.cpp:380] conv2_4 -> conv2_4
I0129 17:58:17.546061 30839 net.cpp:122] Setting up conv2_4
I0129 17:58:17.546087 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.546092 30839 net.cpp:137] Memory required for data: 2675444736
I0129 17:58:17.546099 30839 layer_factory.hpp:77] Creating layer relu2_4
I0129 17:58:17.546108 30839 net.cpp:84] Creating Layer relu2_4
I0129 17:58:17.546113 30839 net.cpp:406] relu2_4 <- conv2_4
I0129 17:58:17.546118 30839 net.cpp:367] relu2_4 -> conv2_4 (in-place)
I0129 17:58:17.546277 30839 net.cpp:122] Setting up relu2_4
I0129 17:58:17.546288 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.546291 30839 net.cpp:137] Memory required for data: 2763525120
I0129 17:58:17.546296 30839 layer_factory.hpp:77] Creating layer conv2_5
I0129 17:58:17.546308 30839 net.cpp:84] Creating Layer conv2_5
I0129 17:58:17.546313 30839 net.cpp:406] conv2_5 <- conv2_4
I0129 17:58:17.546321 30839 net.cpp:380] conv2_5 -> conv2_5
I0129 17:58:17.550513 30839 net.cpp:122] Setting up conv2_5
I0129 17:58:17.550541 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.550545 30839 net.cpp:137] Memory required for data: 2851605504
I0129 17:58:17.550551 30839 layer_factory.hpp:77] Creating layer relu2_5
I0129 17:58:17.550559 30839 net.cpp:84] Creating Layer relu2_5
I0129 17:58:17.550562 30839 net.cpp:406] relu2_5 <- conv2_5
I0129 17:58:17.550570 30839 net.cpp:367] relu2_5 -> conv2_5 (in-place)
I0129 17:58:17.550729 30839 net.cpp:122] Setting up relu2_5
I0129 17:58:17.550739 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.550741 30839 net.cpp:137] Memory required for data: 2939685888
I0129 17:58:17.550748 30839 layer_factory.hpp:77] Creating layer res2_5
I0129 17:58:17.550756 30839 net.cpp:84] Creating Layer res2_5
I0129 17:58:17.550760 30839 net.cpp:406] res2_5 <- res2_3_res2_3_0_split_1
I0129 17:58:17.550765 30839 net.cpp:406] res2_5 <- conv2_5
I0129 17:58:17.550770 30839 net.cpp:380] res2_5 -> res2_5
I0129 17:58:17.550798 30839 net.cpp:122] Setting up res2_5
I0129 17:58:17.550806 30839 net.cpp:129] Top shape: 256 128 28 24 (22020096)
I0129 17:58:17.550808 30839 net.cpp:137] Memory required for data: 3027766272
I0129 17:58:17.550812 30839 layer_factory.hpp:77] Creating layer conv3_1
I0129 17:58:17.550822 30839 net.cpp:84] Creating Layer conv3_1
I0129 17:58:17.550827 30839 net.cpp:406] conv3_1 <- res2_5
I0129 17:58:17.550834 30839 net.cpp:380] conv3_1 -> conv3_1
I0129 17:58:17.554653 30839 net.cpp:122] Setting up conv3_1
I0129 17:58:17.554679 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.554683 30839 net.cpp:137] Memory required for data: 3071806464
I0129 17:58:17.554690 30839 layer_factory.hpp:77] Creating layer relu3_1
I0129 17:58:17.554698 30839 net.cpp:84] Creating Layer relu3_1
I0129 17:58:17.554702 30839 net.cpp:406] relu3_1 <- conv3_1
I0129 17:58:17.554709 30839 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0129 17:58:17.554841 30839 net.cpp:122] Setting up relu3_1
I0129 17:58:17.554850 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.554853 30839 net.cpp:137] Memory required for data: 3115846656
I0129 17:58:17.554858 30839 layer_factory.hpp:77] Creating layer conv3_1_relu3_1_0_split
I0129 17:58:17.554867 30839 net.cpp:84] Creating Layer conv3_1_relu3_1_0_split
I0129 17:58:17.554870 30839 net.cpp:406] conv3_1_relu3_1_0_split <- conv3_1
I0129 17:58:17.554877 30839 net.cpp:380] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_0
I0129 17:58:17.554884 30839 net.cpp:380] conv3_1_relu3_1_0_split -> conv3_1_relu3_1_0_split_1
I0129 17:58:17.554925 30839 net.cpp:122] Setting up conv3_1_relu3_1_0_split
I0129 17:58:17.554935 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.554939 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.554942 30839 net.cpp:137] Memory required for data: 3203927040
I0129 17:58:17.554945 30839 layer_factory.hpp:77] Creating layer conv3_2
I0129 17:58:17.554956 30839 net.cpp:84] Creating Layer conv3_2
I0129 17:58:17.554960 30839 net.cpp:406] conv3_2 <- conv3_1_relu3_1_0_split_0
I0129 17:58:17.554966 30839 net.cpp:380] conv3_2 -> conv3_2
I0129 17:58:17.563102 30839 net.cpp:122] Setting up conv3_2
I0129 17:58:17.563127 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.563132 30839 net.cpp:137] Memory required for data: 3247967232
I0129 17:58:17.563138 30839 layer_factory.hpp:77] Creating layer relu3_2
I0129 17:58:17.563148 30839 net.cpp:84] Creating Layer relu3_2
I0129 17:58:17.563153 30839 net.cpp:406] relu3_2 <- conv3_2
I0129 17:58:17.563158 30839 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0129 17:58:17.563299 30839 net.cpp:122] Setting up relu3_2
I0129 17:58:17.563309 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.563313 30839 net.cpp:137] Memory required for data: 3292007424
I0129 17:58:17.563318 30839 layer_factory.hpp:77] Creating layer conv3_3
I0129 17:58:17.563328 30839 net.cpp:84] Creating Layer conv3_3
I0129 17:58:17.563333 30839 net.cpp:406] conv3_3 <- conv3_2
I0129 17:58:17.563354 30839 net.cpp:380] conv3_3 -> conv3_3
I0129 17:58:17.577082 30839 net.cpp:122] Setting up conv3_3
I0129 17:58:17.577109 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.577113 30839 net.cpp:137] Memory required for data: 3336047616
I0129 17:58:17.577121 30839 layer_factory.hpp:77] Creating layer relu3_3
I0129 17:58:17.577128 30839 net.cpp:84] Creating Layer relu3_3
I0129 17:58:17.577132 30839 net.cpp:406] relu3_3 <- conv3_3
I0129 17:58:17.577137 30839 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0129 17:58:17.577286 30839 net.cpp:122] Setting up relu3_3
I0129 17:58:17.577296 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.577298 30839 net.cpp:137] Memory required for data: 3380087808
I0129 17:58:17.577309 30839 layer_factory.hpp:77] Creating layer res3_3
I0129 17:58:17.577320 30839 net.cpp:84] Creating Layer res3_3
I0129 17:58:17.577323 30839 net.cpp:406] res3_3 <- conv3_1_relu3_1_0_split_1
I0129 17:58:17.577328 30839 net.cpp:406] res3_3 <- conv3_3
I0129 17:58:17.577333 30839 net.cpp:380] res3_3 -> res3_3
I0129 17:58:17.577363 30839 net.cpp:122] Setting up res3_3
I0129 17:58:17.577371 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.577374 30839 net.cpp:137] Memory required for data: 3424128000
I0129 17:58:17.577379 30839 layer_factory.hpp:77] Creating layer res3_3_res3_3_0_split
I0129 17:58:17.577397 30839 net.cpp:84] Creating Layer res3_3_res3_3_0_split
I0129 17:58:17.577401 30839 net.cpp:406] res3_3_res3_3_0_split <- res3_3
I0129 17:58:17.577406 30839 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_0
I0129 17:58:17.577414 30839 net.cpp:380] res3_3_res3_3_0_split -> res3_3_res3_3_0_split_1
I0129 17:58:17.577450 30839 net.cpp:122] Setting up res3_3_res3_3_0_split
I0129 17:58:17.577458 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.577462 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.577466 30839 net.cpp:137] Memory required for data: 3512208384
I0129 17:58:17.577468 30839 layer_factory.hpp:77] Creating layer conv3_4
I0129 17:58:17.577481 30839 net.cpp:84] Creating Layer conv3_4
I0129 17:58:17.577486 30839 net.cpp:406] conv3_4 <- res3_3_res3_3_0_split_0
I0129 17:58:17.577493 30839 net.cpp:380] conv3_4 -> conv3_4
I0129 17:58:17.585629 30839 net.cpp:122] Setting up conv3_4
I0129 17:58:17.585655 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.585659 30839 net.cpp:137] Memory required for data: 3556248576
I0129 17:58:17.585665 30839 layer_factory.hpp:77] Creating layer relu3_4
I0129 17:58:17.585675 30839 net.cpp:84] Creating Layer relu3_4
I0129 17:58:17.585678 30839 net.cpp:406] relu3_4 <- conv3_4
I0129 17:58:17.585683 30839 net.cpp:367] relu3_4 -> conv3_4 (in-place)
I0129 17:58:17.585839 30839 net.cpp:122] Setting up relu3_4
I0129 17:58:17.585850 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.585852 30839 net.cpp:137] Memory required for data: 3600288768
I0129 17:58:17.585858 30839 layer_factory.hpp:77] Creating layer conv3_5
I0129 17:58:17.585871 30839 net.cpp:84] Creating Layer conv3_5
I0129 17:58:17.585876 30839 net.cpp:406] conv3_5 <- conv3_4
I0129 17:58:17.585885 30839 net.cpp:380] conv3_5 -> conv3_5
I0129 17:58:17.596734 30839 net.cpp:122] Setting up conv3_5
I0129 17:58:17.596760 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.596765 30839 net.cpp:137] Memory required for data: 3644328960
I0129 17:58:17.596772 30839 layer_factory.hpp:77] Creating layer relu3_5
I0129 17:58:17.596778 30839 net.cpp:84] Creating Layer relu3_5
I0129 17:58:17.596782 30839 net.cpp:406] relu3_5 <- conv3_5
I0129 17:58:17.596787 30839 net.cpp:367] relu3_5 -> conv3_5 (in-place)
I0129 17:58:17.596941 30839 net.cpp:122] Setting up relu3_5
I0129 17:58:17.596951 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.596954 30839 net.cpp:137] Memory required for data: 3688369152
I0129 17:58:17.596959 30839 layer_factory.hpp:77] Creating layer res3_5
I0129 17:58:17.596967 30839 net.cpp:84] Creating Layer res3_5
I0129 17:58:17.596983 30839 net.cpp:406] res3_5 <- res3_3_res3_3_0_split_1
I0129 17:58:17.596988 30839 net.cpp:406] res3_5 <- conv3_5
I0129 17:58:17.596994 30839 net.cpp:380] res3_5 -> res3_5
I0129 17:58:17.597025 30839 net.cpp:122] Setting up res3_5
I0129 17:58:17.597033 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.597038 30839 net.cpp:137] Memory required for data: 3732409344
I0129 17:58:17.597043 30839 layer_factory.hpp:77] Creating layer res3_5_res3_5_0_split
I0129 17:58:17.597048 30839 net.cpp:84] Creating Layer res3_5_res3_5_0_split
I0129 17:58:17.597051 30839 net.cpp:406] res3_5_res3_5_0_split <- res3_5
I0129 17:58:17.597059 30839 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_0
I0129 17:58:17.597076 30839 net.cpp:380] res3_5_res3_5_0_split -> res3_5_res3_5_0_split_1
I0129 17:58:17.597117 30839 net.cpp:122] Setting up res3_5_res3_5_0_split
I0129 17:58:17.597126 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.597129 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.597132 30839 net.cpp:137] Memory required for data: 3820489728
I0129 17:58:17.597136 30839 layer_factory.hpp:77] Creating layer conv3_6
I0129 17:58:17.597148 30839 net.cpp:84] Creating Layer conv3_6
I0129 17:58:17.597153 30839 net.cpp:406] conv3_6 <- res3_5_res3_5_0_split_0
I0129 17:58:17.597160 30839 net.cpp:380] conv3_6 -> conv3_6
I0129 17:58:17.608578 30839 net.cpp:122] Setting up conv3_6
I0129 17:58:17.608605 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.608609 30839 net.cpp:137] Memory required for data: 3864529920
I0129 17:58:17.608615 30839 layer_factory.hpp:77] Creating layer relu3_6
I0129 17:58:17.608628 30839 net.cpp:84] Creating Layer relu3_6
I0129 17:58:17.608631 30839 net.cpp:406] relu3_6 <- conv3_6
I0129 17:58:17.608636 30839 net.cpp:367] relu3_6 -> conv3_6 (in-place)
I0129 17:58:17.608783 30839 net.cpp:122] Setting up relu3_6
I0129 17:58:17.608798 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.608803 30839 net.cpp:137] Memory required for data: 3908570112
I0129 17:58:17.608808 30839 layer_factory.hpp:77] Creating layer conv3_7
I0129 17:58:17.608819 30839 net.cpp:84] Creating Layer conv3_7
I0129 17:58:17.608824 30839 net.cpp:406] conv3_7 <- conv3_6
I0129 17:58:17.608832 30839 net.cpp:380] conv3_7 -> conv3_7
I0129 17:58:17.618763 30839 net.cpp:122] Setting up conv3_7
I0129 17:58:17.618778 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.618793 30839 net.cpp:137] Memory required for data: 3952610304
I0129 17:58:17.618799 30839 layer_factory.hpp:77] Creating layer relu3_7
I0129 17:58:17.618808 30839 net.cpp:84] Creating Layer relu3_7
I0129 17:58:17.618813 30839 net.cpp:406] relu3_7 <- conv3_7
I0129 17:58:17.618818 30839 net.cpp:367] relu3_7 -> conv3_7 (in-place)
I0129 17:58:17.618980 30839 net.cpp:122] Setting up relu3_7
I0129 17:58:17.618991 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.618994 30839 net.cpp:137] Memory required for data: 3996650496
I0129 17:58:17.618999 30839 layer_factory.hpp:77] Creating layer res3_7
I0129 17:58:17.619005 30839 net.cpp:84] Creating Layer res3_7
I0129 17:58:17.619009 30839 net.cpp:406] res3_7 <- res3_5_res3_5_0_split_1
I0129 17:58:17.619014 30839 net.cpp:406] res3_7 <- conv3_7
I0129 17:58:17.619020 30839 net.cpp:380] res3_7 -> res3_7
I0129 17:58:17.619048 30839 net.cpp:122] Setting up res3_7
I0129 17:58:17.619056 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.619060 30839 net.cpp:137] Memory required for data: 4040690688
I0129 17:58:17.619065 30839 layer_factory.hpp:77] Creating layer res3_7_res3_7_0_split
I0129 17:58:17.619072 30839 net.cpp:84] Creating Layer res3_7_res3_7_0_split
I0129 17:58:17.619076 30839 net.cpp:406] res3_7_res3_7_0_split <- res3_7
I0129 17:58:17.619083 30839 net.cpp:380] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_0
I0129 17:58:17.619091 30839 net.cpp:380] res3_7_res3_7_0_split -> res3_7_res3_7_0_split_1
I0129 17:58:17.619128 30839 net.cpp:122] Setting up res3_7_res3_7_0_split
I0129 17:58:17.619150 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.619155 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.619158 30839 net.cpp:137] Memory required for data: 4128771072
I0129 17:58:17.619161 30839 layer_factory.hpp:77] Creating layer conv3_8
I0129 17:58:17.619173 30839 net.cpp:84] Creating Layer conv3_8
I0129 17:58:17.619176 30839 net.cpp:406] conv3_8 <- res3_7_res3_7_0_split_0
I0129 17:58:17.619184 30839 net.cpp:380] conv3_8 -> conv3_8
I0129 17:58:17.631810 30839 net.cpp:122] Setting up conv3_8
I0129 17:58:17.631837 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.631841 30839 net.cpp:137] Memory required for data: 4172811264
I0129 17:58:17.631847 30839 layer_factory.hpp:77] Creating layer relu3_8
I0129 17:58:17.631857 30839 net.cpp:84] Creating Layer relu3_8
I0129 17:58:17.631861 30839 net.cpp:406] relu3_8 <- conv3_8
I0129 17:58:17.631866 30839 net.cpp:367] relu3_8 -> conv3_8 (in-place)
I0129 17:58:17.632027 30839 net.cpp:122] Setting up relu3_8
I0129 17:58:17.632036 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.632040 30839 net.cpp:137] Memory required for data: 4216851456
I0129 17:58:17.632047 30839 layer_factory.hpp:77] Creating layer conv3_9
I0129 17:58:17.632058 30839 net.cpp:84] Creating Layer conv3_9
I0129 17:58:17.632063 30839 net.cpp:406] conv3_9 <- conv3_8
I0129 17:58:17.632071 30839 net.cpp:380] conv3_9 -> conv3_9
I0129 17:58:17.643364 30839 net.cpp:122] Setting up conv3_9
I0129 17:58:17.643390 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.643393 30839 net.cpp:137] Memory required for data: 4260891648
I0129 17:58:17.643411 30839 layer_factory.hpp:77] Creating layer relu3_9
I0129 17:58:17.643419 30839 net.cpp:84] Creating Layer relu3_9
I0129 17:58:17.643424 30839 net.cpp:406] relu3_9 <- conv3_9
I0129 17:58:17.643429 30839 net.cpp:367] relu3_9 -> conv3_9 (in-place)
I0129 17:58:17.643592 30839 net.cpp:122] Setting up relu3_9
I0129 17:58:17.643601 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.643605 30839 net.cpp:137] Memory required for data: 4304931840
I0129 17:58:17.643610 30839 layer_factory.hpp:77] Creating layer res3_9
I0129 17:58:17.643616 30839 net.cpp:84] Creating Layer res3_9
I0129 17:58:17.643620 30839 net.cpp:406] res3_9 <- res3_7_res3_7_0_split_1
I0129 17:58:17.643625 30839 net.cpp:406] res3_9 <- conv3_9
I0129 17:58:17.643631 30839 net.cpp:380] res3_9 -> res3_9
I0129 17:58:17.643661 30839 net.cpp:122] Setting up res3_9
I0129 17:58:17.643669 30839 net.cpp:129] Top shape: 256 256 14 12 (11010048)
I0129 17:58:17.643672 30839 net.cpp:137] Memory required for data: 4348972032
I0129 17:58:17.643678 30839 layer_factory.hpp:77] Creating layer conv4_1
I0129 17:58:17.643689 30839 net.cpp:84] Creating Layer conv4_1
I0129 17:58:17.643694 30839 net.cpp:406] conv4_1 <- res3_9
I0129 17:58:17.643702 30839 net.cpp:380] conv4_1 -> conv4_1
I0129 17:58:17.656486 30839 net.cpp:122] Setting up conv4_1
I0129 17:58:17.656513 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.656517 30839 net.cpp:137] Memory required for data: 4370992128
I0129 17:58:17.656524 30839 layer_factory.hpp:77] Creating layer relu4_1
I0129 17:58:17.656530 30839 net.cpp:84] Creating Layer relu4_1
I0129 17:58:17.656534 30839 net.cpp:406] relu4_1 <- conv4_1
I0129 17:58:17.656541 30839 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0129 17:58:17.656682 30839 net.cpp:122] Setting up relu4_1
I0129 17:58:17.656692 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.656695 30839 net.cpp:137] Memory required for data: 4393012224
I0129 17:58:17.656700 30839 layer_factory.hpp:77] Creating layer conv4_1_relu4_1_0_split
I0129 17:58:17.656708 30839 net.cpp:84] Creating Layer conv4_1_relu4_1_0_split
I0129 17:58:17.656713 30839 net.cpp:406] conv4_1_relu4_1_0_split <- conv4_1
I0129 17:58:17.656718 30839 net.cpp:380] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_0
I0129 17:58:17.656724 30839 net.cpp:380] conv4_1_relu4_1_0_split -> conv4_1_relu4_1_0_split_1
I0129 17:58:17.656769 30839 net.cpp:122] Setting up conv4_1_relu4_1_0_split
I0129 17:58:17.656790 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.656795 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.656797 30839 net.cpp:137] Memory required for data: 4437052416
I0129 17:58:17.656800 30839 layer_factory.hpp:77] Creating layer conv4_2
I0129 17:58:17.656813 30839 net.cpp:84] Creating Layer conv4_2
I0129 17:58:17.656818 30839 net.cpp:406] conv4_2 <- conv4_1_relu4_1_0_split_0
I0129 17:58:17.656826 30839 net.cpp:380] conv4_2 -> conv4_2
I0129 17:58:17.688616 30839 net.cpp:122] Setting up conv4_2
I0129 17:58:17.688642 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.688645 30839 net.cpp:137] Memory required for data: 4459072512
I0129 17:58:17.688652 30839 layer_factory.hpp:77] Creating layer relu4_2
I0129 17:58:17.688658 30839 net.cpp:84] Creating Layer relu4_2
I0129 17:58:17.688663 30839 net.cpp:406] relu4_2 <- conv4_2
I0129 17:58:17.688669 30839 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0129 17:58:17.688805 30839 net.cpp:122] Setting up relu4_2
I0129 17:58:17.688822 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.688824 30839 net.cpp:137] Memory required for data: 4481092608
I0129 17:58:17.688829 30839 layer_factory.hpp:77] Creating layer conv4_3
I0129 17:58:17.688839 30839 net.cpp:84] Creating Layer conv4_3
I0129 17:58:17.688843 30839 net.cpp:406] conv4_3 <- conv4_2
I0129 17:58:17.688851 30839 net.cpp:380] conv4_3 -> conv4_3
I0129 17:58:17.718802 30839 net.cpp:122] Setting up conv4_3
I0129 17:58:17.718830 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.718835 30839 net.cpp:137] Memory required for data: 4503112704
I0129 17:58:17.718843 30839 layer_factory.hpp:77] Creating layer relu4_3
I0129 17:58:17.718850 30839 net.cpp:84] Creating Layer relu4_3
I0129 17:58:17.718854 30839 net.cpp:406] relu4_3 <- conv4_3
I0129 17:58:17.718859 30839 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0129 17:58:17.720177 30839 net.cpp:122] Setting up relu4_3
I0129 17:58:17.720191 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.720206 30839 net.cpp:137] Memory required for data: 4525132800
I0129 17:58:17.720211 30839 layer_factory.hpp:77] Creating layer res4_3
I0129 17:58:17.720221 30839 net.cpp:84] Creating Layer res4_3
I0129 17:58:17.720226 30839 net.cpp:406] res4_3 <- conv4_1_relu4_1_0_split_1
I0129 17:58:17.720230 30839 net.cpp:406] res4_3 <- conv4_3
I0129 17:58:17.720235 30839 net.cpp:380] res4_3 -> res4_3
I0129 17:58:17.720280 30839 net.cpp:122] Setting up res4_3
I0129 17:58:17.720288 30839 net.cpp:129] Top shape: 256 512 7 6 (5505024)
I0129 17:58:17.720291 30839 net.cpp:137] Memory required for data: 4547152896
I0129 17:58:17.720294 30839 layer_factory.hpp:77] Creating layer fc5
I0129 17:58:17.720306 30839 net.cpp:84] Creating Layer fc5
I0129 17:58:17.720310 30839 net.cpp:406] fc5 <- res4_3
I0129 17:58:17.720319 30839 net.cpp:380] fc5 -> fc5
I0129 17:58:17.808136 30839 net.cpp:122] Setting up fc5
I0129 17:58:17.808202 30839 net.cpp:129] Top shape: 256 512 (131072)
I0129 17:58:17.808207 30839 net.cpp:137] Memory required for data: 4547677184
I0129 17:58:17.808239 30839 layer_factory.hpp:77] Creating layer norm1
I0129 17:58:17.808255 30839 net.cpp:84] Creating Layer norm1
I0129 17:58:17.808269 30839 net.cpp:406] norm1 <- fc5
I0129 17:58:17.808295 30839 net.cpp:380] norm1 -> norm1
I0129 17:58:17.808426 30839 net.cpp:122] Setting up norm1
I0129 17:58:17.808441 30839 net.cpp:129] Top shape: 256 512 1 1 (131072)
I0129 17:58:17.808446 30839 net.cpp:137] Memory required for data: 4548201472
I0129 17:58:17.808450 30839 layer_factory.hpp:77] Creating layer fc6_l2
I0129 17:58:17.808460 30839 net.cpp:84] Creating Layer fc6_l2
I0129 17:58:17.808465 30839 net.cpp:406] fc6_l2 <- norm1
I0129 17:58:17.808471 30839 net.cpp:380] fc6_l2 -> fc6
I0129 17:58:17.841192 30839 net.cpp:122] Setting up fc6_l2
I0129 17:58:17.841225 30839 net.cpp:129] Top shape: 256 9131 (2337536)
I0129 17:58:17.841230 30839 net.cpp:137] Memory required for data: 4557551616
I0129 17:58:17.841238 30839 layer_factory.hpp:77] Creating layer label_Margin
I0129 17:58:17.841274 30839 net.cpp:84] Creating Layer label_Margin
I0129 17:58:17.841279 30839 net.cpp:406] label_Margin <- fc6
I0129 17:58:17.841286 30839 net.cpp:406] label_Margin <- label_data_1_split_0
I0129 17:58:17.841295 30839 net.cpp:380] label_Margin -> fc6_margin
I0129 17:58:17.841344 30839 net.cpp:122] Setting up label_Margin
I0129 17:58:17.841354 30839 net.cpp:129] Top shape: 256 9131 1 1 (2337536)
I0129 17:58:17.841357 30839 net.cpp:137] Memory required for data: 4566901760
I0129 17:58:17.841361 30839 layer_factory.hpp:77] Creating layer fc6_margin_scale
I0129 17:58:17.841374 30839 net.cpp:84] Creating Layer fc6_margin_scale
I0129 17:58:17.841378 30839 net.cpp:406] fc6_margin_scale <- fc6_margin
I0129 17:58:17.841384 30839 net.cpp:380] fc6_margin_scale -> fc6_margin_scale
I0129 17:58:17.841603 30839 net.cpp:122] Setting up fc6_margin_scale
I0129 17:58:17.841614 30839 net.cpp:129] Top shape: 256 9131 1 1 (2337536)
I0129 17:58:17.841617 30839 net.cpp:137] Memory required for data: 4576251904
I0129 17:58:17.841622 30839 layer_factory.hpp:77] Creating layer softmax_loss
I0129 17:58:17.841629 30839 net.cpp:84] Creating Layer softmax_loss
I0129 17:58:17.841634 30839 net.cpp:406] softmax_loss <- fc6_margin_scale
I0129 17:58:17.841637 30839 net.cpp:406] softmax_loss <- label_data_1_split_1
I0129 17:58:17.841650 30839 net.cpp:380] softmax_loss -> softmax_loss
I0129 17:58:17.841660 30839 layer_factory.hpp:77] Creating layer softmax_loss
I0129 17:58:17.854449 30839 net.cpp:122] Setting up softmax_loss
I0129 17:58:17.854466 30839 net.cpp:129] Top shape: (1)
I0129 17:58:17.854470 30839 net.cpp:132]     with loss weight 1
I0129 17:58:17.854506 30839 net.cpp:137] Memory required for data: 4576251908
I0129 17:58:17.854509 30839 net.cpp:198] softmax_loss needs backward computation.
I0129 17:58:17.854529 30839 net.cpp:198] fc6_margin_scale needs backward computation.
I0129 17:58:17.854534 30839 net.cpp:198] label_Margin needs backward computation.
I0129 17:58:17.854538 30839 net.cpp:198] fc6_l2 needs backward computation.
I0129 17:58:17.854542 30839 net.cpp:198] norm1 needs backward computation.
I0129 17:58:17.854545 30839 net.cpp:198] fc5 needs backward computation.
I0129 17:58:17.854548 30839 net.cpp:198] res4_3 needs backward computation.
I0129 17:58:17.854552 30839 net.cpp:198] relu4_3 needs backward computation.
I0129 17:58:17.854559 30839 net.cpp:198] conv4_3 needs backward computation.
I0129 17:58:17.854568 30839 net.cpp:198] relu4_2 needs backward computation.
I0129 17:58:17.854571 30839 net.cpp:198] conv4_2 needs backward computation.
I0129 17:58:17.854581 30839 net.cpp:198] conv4_1_relu4_1_0_split needs backward computation.
I0129 17:58:17.854585 30839 net.cpp:198] relu4_1 needs backward computation.
I0129 17:58:17.854593 30839 net.cpp:198] conv4_1 needs backward computation.
I0129 17:58:17.854596 30839 net.cpp:198] res3_9 needs backward computation.
I0129 17:58:17.854600 30839 net.cpp:198] relu3_9 needs backward computation.
I0129 17:58:17.854609 30839 net.cpp:198] conv3_9 needs backward computation.
I0129 17:58:17.854616 30839 net.cpp:198] relu3_8 needs backward computation.
I0129 17:58:17.854624 30839 net.cpp:198] conv3_8 needs backward computation.
I0129 17:58:17.854629 30839 net.cpp:198] res3_7_res3_7_0_split needs backward computation.
I0129 17:58:17.854636 30839 net.cpp:198] res3_7 needs backward computation.
I0129 17:58:17.854645 30839 net.cpp:198] relu3_7 needs backward computation.
I0129 17:58:17.854650 30839 net.cpp:198] conv3_7 needs backward computation.
I0129 17:58:17.854652 30839 net.cpp:198] relu3_6 needs backward computation.
I0129 17:58:17.854656 30839 net.cpp:198] conv3_6 needs backward computation.
I0129 17:58:17.854672 30839 net.cpp:198] res3_5_res3_5_0_split needs backward computation.
I0129 17:58:17.854677 30839 net.cpp:198] res3_5 needs backward computation.
I0129 17:58:17.854691 30839 net.cpp:198] relu3_5 needs backward computation.
I0129 17:58:17.854693 30839 net.cpp:198] conv3_5 needs backward computation.
I0129 17:58:17.854697 30839 net.cpp:198] relu3_4 needs backward computation.
I0129 17:58:17.854715 30839 net.cpp:198] conv3_4 needs backward computation.
I0129 17:58:17.854725 30839 net.cpp:198] res3_3_res3_3_0_split needs backward computation.
I0129 17:58:17.854729 30839 net.cpp:198] res3_3 needs backward computation.
I0129 17:58:17.854742 30839 net.cpp:198] relu3_3 needs backward computation.
I0129 17:58:17.854750 30839 net.cpp:198] conv3_3 needs backward computation.
I0129 17:58:17.854754 30839 net.cpp:198] relu3_2 needs backward computation.
I0129 17:58:17.854763 30839 net.cpp:198] conv3_2 needs backward computation.
I0129 17:58:17.854770 30839 net.cpp:198] conv3_1_relu3_1_0_split needs backward computation.
I0129 17:58:17.854784 30839 net.cpp:198] relu3_1 needs backward computation.
I0129 17:58:17.854789 30839 net.cpp:198] conv3_1 needs backward computation.
I0129 17:58:17.854796 30839 net.cpp:198] res2_5 needs backward computation.
I0129 17:58:17.854810 30839 net.cpp:198] relu2_5 needs backward computation.
I0129 17:58:17.854820 30839 net.cpp:198] conv2_5 needs backward computation.
I0129 17:58:17.854827 30839 net.cpp:198] relu2_4 needs backward computation.
I0129 17:58:17.854835 30839 net.cpp:198] conv2_4 needs backward computation.
I0129 17:58:17.854843 30839 net.cpp:198] res2_3_res2_3_0_split needs backward computation.
I0129 17:58:17.854852 30839 net.cpp:198] res2_3 needs backward computation.
I0129 17:58:17.854858 30839 net.cpp:198] relu2_3 needs backward computation.
I0129 17:58:17.854873 30839 net.cpp:198] conv2_3 needs backward computation.
I0129 17:58:17.854887 30839 net.cpp:198] relu2_2 needs backward computation.
I0129 17:58:17.854897 30839 net.cpp:198] conv2_2 needs backward computation.
I0129 17:58:17.854900 30839 net.cpp:198] conv2_1_relu2_1_0_split needs backward computation.
I0129 17:58:17.854908 30839 net.cpp:198] relu2_1 needs backward computation.
I0129 17:58:17.854917 30839 net.cpp:198] conv2_1 needs backward computation.
I0129 17:58:17.854920 30839 net.cpp:198] res1_3 needs backward computation.
I0129 17:58:17.854929 30839 net.cpp:198] relu1_3 needs backward computation.
I0129 17:58:17.854933 30839 net.cpp:198] conv1_3 needs backward computation.
I0129 17:58:17.854940 30839 net.cpp:198] relu1_2 needs backward computation.
I0129 17:58:17.854952 30839 net.cpp:198] conv1_2 needs backward computation.
I0129 17:58:17.854959 30839 net.cpp:198] conv1_1_relu1_1_0_split needs backward computation.
I0129 17:58:17.854965 30839 net.cpp:198] relu1_1 needs backward computation.
I0129 17:58:17.854969 30839 net.cpp:198] conv1_1 needs backward computation.
I0129 17:58:17.854974 30839 net.cpp:200] label_data_1_split does not need backward computation.
I0129 17:58:17.854979 30839 net.cpp:200] data does not need backward computation.
I0129 17:58:17.854981 30839 net.cpp:242] This network produces output softmax_loss
I0129 17:58:17.855036 30839 net.cpp:255] Network initialization done.
I0129 17:58:17.855327 30839 solver.cpp:56] Solver scaffolding done.
I0129 17:58:17.857897 30839 caffe.cpp:248] Starting Optimization
I0129 17:58:17.857905 30839 solver.cpp:272] Solving Face-ResNet
I0129 17:58:17.857908 30839 solver.cpp:273] Learning Rate Policy: multistep
I0129 17:58:18.600318 30839 solver.cpp:218] Iteration 0 (2.21648e+25 iter/s, 0.741338s/100 iters), loss = 13.1015
I0129 17:58:18.600363 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.1015 (* 1 = 13.1015 loss)
I0129 17:58:18.600380 30839 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0129 17:58:35.702780 30839 blocking_queue.cpp:49] Waiting for data
I0129 17:59:17.126168 30839 solver.cpp:218] Iteration 100 (1.70872 iter/s, 58.5233s/100 iters), loss = 16.0189
I0129 17:59:17.131305 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.0189 (* 1 = 16.0189 loss)
I0129 17:59:17.131327 30839 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0129 18:00:16.474031 30839 solver.cpp:218] Iteration 200 (1.68513 iter/s, 59.3425s/100 iters), loss = 16.7008
I0129 18:00:16.479120 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.7008 (* 1 = 16.7008 loss)
I0129 18:00:16.479140 30839 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0129 18:01:15.911772 30839 solver.cpp:218] Iteration 300 (1.68258 iter/s, 59.4324s/100 iters), loss = 16.6977
I0129 18:01:15.916854 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.6977 (* 1 = 16.6977 loss)
I0129 18:01:15.916877 30839 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0129 18:02:15.028825 30839 solver.cpp:218] Iteration 400 (1.69171 iter/s, 59.1117s/100 iters), loss = 16.1619
I0129 18:02:15.034101 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.1619 (* 1 = 16.1619 loss)
I0129 18:02:15.034132 30839 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0129 18:03:14.539975 30839 solver.cpp:218] Iteration 500 (1.68051 iter/s, 59.5056s/100 iters), loss = 16.1763
I0129 18:03:14.545034 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.1763 (* 1 = 16.1763 loss)
I0129 18:03:14.545053 30839 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0129 18:03:54.665205 30839 solver.cpp:218] Iteration 600 (2.49252 iter/s, 40.12s/100 iters), loss = 15.936
I0129 18:03:54.665400 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.936 (* 1 = 15.936 loss)
I0129 18:03:54.665412 30839 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0129 18:04:31.323257 30839 solver.cpp:218] Iteration 700 (2.72795 iter/s, 36.6576s/100 iters), loss = 15.4923
I0129 18:04:31.323529 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.4923 (* 1 = 15.4923 loss)
I0129 18:04:31.323550 30839 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0129 18:05:08.210958 30839 solver.cpp:218] Iteration 800 (2.71096 iter/s, 36.8872s/100 iters), loss = 15.0024
I0129 18:05:08.211192 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.0024 (* 1 = 15.0024 loss)
I0129 18:05:08.211215 30839 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0129 18:05:45.215890 30839 solver.cpp:218] Iteration 900 (2.70237 iter/s, 37.0045s/100 iters), loss = 14.7089
I0129 18:05:45.221307 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.7089 (* 1 = 14.7089 loss)
I0129 18:05:45.221325 30839 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0129 18:06:22.093320 30839 solver.cpp:218] Iteration 1000 (2.7121 iter/s, 36.8718s/100 iters), loss = 15.3046
I0129 18:06:22.098790 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.3046 (* 1 = 15.3046 loss)
I0129 18:06:22.098831 30839 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0129 18:06:58.908777 30839 solver.cpp:218] Iteration 1100 (2.71667 iter/s, 36.8098s/100 iters), loss = 16.2979
I0129 18:06:58.914230 30839 solver.cpp:237]     Train net output #0: softmax_loss = 16.2979 (* 1 = 16.2979 loss)
I0129 18:06:58.914274 30839 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0129 18:07:35.795681 30839 solver.cpp:218] Iteration 1200 (2.7114 iter/s, 36.8813s/100 iters), loss = 15.4441
I0129 18:07:35.801141 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.4441 (* 1 = 15.4441 loss)
I0129 18:07:35.801163 30839 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0129 18:08:12.698711 30839 solver.cpp:218] Iteration 1300 (2.71022 iter/s, 36.8974s/100 iters), loss = 14.455
I0129 18:08:12.699010 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.455 (* 1 = 14.455 loss)
I0129 18:08:12.699059 30839 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0129 18:08:49.475188 30839 solver.cpp:218] Iteration 1400 (2.71916 iter/s, 36.776s/100 iters), loss = 14.4776
I0129 18:08:49.481281 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.4776 (* 1 = 14.4776 loss)
I0129 18:08:49.481324 30839 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0129 18:09:26.277386 30839 solver.cpp:218] Iteration 1500 (2.71769 iter/s, 36.7959s/100 iters), loss = 14.1926
I0129 18:09:26.277644 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.1926 (* 1 = 14.1926 loss)
I0129 18:09:26.277676 30839 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0129 18:10:04.659026 30839 solver.cpp:218] Iteration 1600 (2.60544 iter/s, 38.3812s/100 iters), loss = 14.3463
I0129 18:10:04.664455 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.3463 (* 1 = 14.3463 loss)
I0129 18:10:04.664479 30839 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0129 18:10:41.393227 30839 solver.cpp:218] Iteration 1700 (2.72268 iter/s, 36.7286s/100 iters), loss = 14.5822
I0129 18:10:41.398679 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.5822 (* 1 = 14.5822 loss)
I0129 18:10:41.398705 30839 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0129 18:11:18.227689 30839 solver.cpp:218] Iteration 1800 (2.71526 iter/s, 36.8288s/100 iters), loss = 13.6169
I0129 18:11:18.233342 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.6169 (* 1 = 13.6169 loss)
I0129 18:11:18.233384 30839 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0129 18:11:55.047827 30839 solver.cpp:218] Iteration 1900 (2.71633 iter/s, 36.8143s/100 iters), loss = 15.3468
I0129 18:11:55.048137 30839 solver.cpp:237]     Train net output #0: softmax_loss = 15.3468 (* 1 = 15.3468 loss)
I0129 18:11:55.048176 30839 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0129 18:12:31.825225 30839 solver.cpp:218] Iteration 2000 (2.7191 iter/s, 36.7769s/100 iters), loss = 14.5907
I0129 18:12:31.825495 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.5907 (* 1 = 14.5907 loss)
I0129 18:12:31.825527 30839 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0129 18:13:08.527869 30839 solver.cpp:218] Iteration 2100 (2.72463 iter/s, 36.7022s/100 iters), loss = 14.7513
I0129 18:13:08.533243 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.7513 (* 1 = 14.7513 loss)
I0129 18:13:08.533260 30839 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0129 18:13:45.241926 30839 solver.cpp:218] Iteration 2200 (2.72416 iter/s, 36.7085s/100 iters), loss = 13.345
I0129 18:13:45.249492 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.345 (* 1 = 13.345 loss)
I0129 18:13:45.249562 30839 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0129 18:14:21.926730 30839 solver.cpp:218] Iteration 2300 (2.7265 iter/s, 36.6771s/100 iters), loss = 14.1513
I0129 18:14:21.932181 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.1513 (* 1 = 14.1513 loss)
I0129 18:14:21.932252 30839 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0129 18:14:58.526604 30839 solver.cpp:218] Iteration 2400 (2.73267 iter/s, 36.5942s/100 iters), loss = 14.2134
I0129 18:14:58.526849 30839 solver.cpp:237]     Train net output #0: softmax_loss = 14.2134 (* 1 = 14.2134 loss)
I0129 18:14:58.526875 30839 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0129 18:15:35.182113 30839 solver.cpp:218] Iteration 2500 (2.72814 iter/s, 36.6551s/100 iters), loss = 12.7885
I0129 18:15:35.182322 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.7885 (* 1 = 12.7885 loss)
I0129 18:15:35.182345 30839 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0129 18:16:11.835331 30839 solver.cpp:218] Iteration 2600 (2.7283 iter/s, 36.6528s/100 iters), loss = 12.7118
I0129 18:16:11.835551 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.7118 (* 1 = 12.7118 loss)
I0129 18:16:11.835570 30839 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0129 18:16:48.461043 30839 solver.cpp:218] Iteration 2700 (2.73035 iter/s, 36.6253s/100 iters), loss = 12.445
I0129 18:16:48.466454 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.445 (* 1 = 12.445 loss)
I0129 18:16:48.466481 30839 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0129 18:17:24.986886 30839 solver.cpp:218] Iteration 2800 (2.73819 iter/s, 36.5205s/100 iters), loss = 13.0545
I0129 18:17:24.987148 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.0545 (* 1 = 13.0545 loss)
I0129 18:17:24.987198 30839 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0129 18:18:01.514678 30839 solver.cpp:218] Iteration 2900 (2.73766 iter/s, 36.5276s/100 iters), loss = 13.0063
I0129 18:18:01.520097 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.0063 (* 1 = 13.0063 loss)
I0129 18:18:01.520110 30839 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0129 18:18:38.112121 30839 solver.cpp:218] Iteration 3000 (2.73284 iter/s, 36.592s/100 iters), loss = 13.7548
I0129 18:18:38.117516 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.7548 (* 1 = 13.7548 loss)
I0129 18:18:38.117543 30839 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0129 18:19:14.717196 30839 solver.cpp:218] Iteration 3100 (2.73226 iter/s, 36.5997s/100 iters), loss = 13.095
I0129 18:19:14.722751 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.095 (* 1 = 13.095 loss)
I0129 18:19:14.722787 30839 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0129 18:19:51.283205 30839 solver.cpp:218] Iteration 3200 (2.73519 iter/s, 36.5605s/100 iters), loss = 13.1243
I0129 18:19:51.288622 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.1243 (* 1 = 13.1243 loss)
I0129 18:19:51.288638 30839 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0129 18:20:27.804953 30839 solver.cpp:218] Iteration 3300 (2.7385 iter/s, 36.5163s/100 iters), loss = 13.3879
I0129 18:20:27.810443 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.3879 (* 1 = 13.3879 loss)
I0129 18:20:27.810482 30839 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0129 18:21:04.343286 30839 solver.cpp:218] Iteration 3400 (2.73726 iter/s, 36.5328s/100 iters), loss = 11.5753
I0129 18:21:04.348656 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.5753 (* 1 = 11.5753 loss)
I0129 18:21:04.348673 30839 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0129 18:21:40.817641 30839 solver.cpp:218] Iteration 3500 (2.74206 iter/s, 36.4689s/100 iters), loss = 12.0131
I0129 18:21:40.817951 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.0131 (* 1 = 12.0131 loss)
I0129 18:21:40.817984 30839 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0129 18:22:17.347754 30839 solver.cpp:218] Iteration 3600 (2.73749 iter/s, 36.5298s/100 iters), loss = 11.8546
I0129 18:22:17.353207 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.8546 (* 1 = 11.8546 loss)
I0129 18:22:17.353242 30839 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0129 18:22:53.885246 30839 solver.cpp:218] Iteration 3700 (2.73733 iter/s, 36.532s/100 iters), loss = 13.4602
I0129 18:22:53.890738 30839 solver.cpp:237]     Train net output #0: softmax_loss = 13.4602 (* 1 = 13.4602 loss)
I0129 18:22:53.890779 30839 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0129 18:23:31.913419 30839 solver.cpp:218] Iteration 3800 (2.63001 iter/s, 38.0226s/100 iters), loss = 11.6006
I0129 18:23:31.918887 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.6006 (* 1 = 11.6006 loss)
I0129 18:23:31.918931 30839 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0129 18:24:08.422134 30839 solver.cpp:218] Iteration 3900 (2.73949 iter/s, 36.5032s/100 iters), loss = 11.8116
I0129 18:24:08.427584 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.8116 (* 1 = 11.8116 loss)
I0129 18:24:08.427609 30839 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0129 18:24:44.968551 30839 solver.cpp:218] Iteration 4000 (2.73666 iter/s, 36.5409s/100 iters), loss = 12.3716
I0129 18:24:44.968819 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.3716 (* 1 = 12.3716 loss)
I0129 18:24:44.968855 30839 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0129 18:25:21.487249 30839 solver.cpp:218] Iteration 4100 (2.73835 iter/s, 36.5184s/100 iters), loss = 12.4
I0129 18:25:21.487510 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.4 (* 1 = 12.4 loss)
I0129 18:25:21.487562 30839 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0129 18:25:57.903926 30839 solver.cpp:218] Iteration 4200 (2.74602 iter/s, 36.4163s/100 iters), loss = 11.9674
I0129 18:25:57.904196 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.9674 (* 1 = 11.9674 loss)
I0129 18:25:57.904232 30839 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0129 18:26:34.400041 30839 solver.cpp:218] Iteration 4300 (2.74004 iter/s, 36.4958s/100 iters), loss = 12.4477
I0129 18:26:34.405483 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.4477 (* 1 = 12.4477 loss)
I0129 18:26:34.405501 30839 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0129 18:27:10.912793 30839 solver.cpp:218] Iteration 4400 (2.73919 iter/s, 36.5072s/100 iters), loss = 12.239
I0129 18:27:10.918061 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.239 (* 1 = 12.239 loss)
I0129 18:27:10.918102 30839 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0129 18:27:47.408416 30839 solver.cpp:218] Iteration 4500 (2.74046 iter/s, 36.4903s/100 iters), loss = 12.1424
I0129 18:27:47.408720 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.1424 (* 1 = 12.1424 loss)
I0129 18:27:47.408752 30839 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0129 18:28:23.844265 30839 solver.cpp:218] Iteration 4600 (2.74458 iter/s, 36.4354s/100 iters), loss = 11.7793
I0129 18:28:23.849709 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.7793 (* 1 = 11.7793 loss)
I0129 18:28:23.849728 30839 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0129 18:29:00.319897 30839 solver.cpp:218] Iteration 4700 (2.74197 iter/s, 36.4701s/100 iters), loss = 12.5148
I0129 18:29:00.325314 30839 solver.cpp:237]     Train net output #0: softmax_loss = 12.5148 (* 1 = 12.5148 loss)
I0129 18:29:00.325335 30839 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0129 18:29:36.772017 30839 solver.cpp:218] Iteration 4800 (2.74374 iter/s, 36.4466s/100 iters), loss = 11.3384
I0129 18:29:36.777484 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.3384 (* 1 = 11.3384 loss)
I0129 18:29:36.777518 30839 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0129 18:30:13.217296 30839 solver.cpp:218] Iteration 4900 (2.74426 iter/s, 36.4397s/100 iters), loss = 11.1876
I0129 18:30:13.223126 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.1876 (* 1 = 11.1876 loss)
I0129 18:30:13.223173 30839 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0129 18:30:49.086145 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_5000.caffemodel
I0129 18:30:49.952358 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_5000.solverstate
I0129 18:30:50.472390 30839 solver.cpp:218] Iteration 5000 (2.68462 iter/s, 37.2492s/100 iters), loss = 11.3061
I0129 18:30:50.472450 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.3061 (* 1 = 11.3061 loss)
I0129 18:30:50.472460 30839 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I0129 18:31:26.919358 30839 solver.cpp:218] Iteration 5100 (2.74373 iter/s, 36.4467s/100 iters), loss = 10.7332
I0129 18:31:26.919647 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.7332 (* 1 = 10.7332 loss)
I0129 18:31:26.919680 30839 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I0129 18:32:03.435961 30839 solver.cpp:218] Iteration 5200 (2.73851 iter/s, 36.5162s/100 iters), loss = 11.105
I0129 18:32:03.436178 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.105 (* 1 = 11.105 loss)
I0129 18:32:03.436195 30839 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I0129 18:32:25.844115 30839 blocking_queue.cpp:49] Waiting for data
I0129 18:32:39.950000 30839 solver.cpp:218] Iteration 5300 (2.7387 iter/s, 36.5136s/100 iters), loss = 10.9833
I0129 18:32:39.955514 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.9833 (* 1 = 10.9833 loss)
I0129 18:32:39.955554 30839 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I0129 18:33:16.437299 30839 solver.cpp:218] Iteration 5400 (2.7411 iter/s, 36.4817s/100 iters), loss = 11.469
I0129 18:33:16.442775 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.469 (* 1 = 11.469 loss)
I0129 18:33:16.442811 30839 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I0129 18:33:52.899538 30839 solver.cpp:218] Iteration 5500 (2.74299 iter/s, 36.4566s/100 iters), loss = 10.8697
I0129 18:33:52.905012 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.8697 (* 1 = 10.8697 loss)
I0129 18:33:52.905047 30839 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I0129 18:34:29.401206 30839 solver.cpp:218] Iteration 5600 (2.74002 iter/s, 36.4961s/100 iters), loss = 11.0305
I0129 18:34:29.408234 30839 solver.cpp:237]     Train net output #0: softmax_loss = 11.0305 (* 1 = 11.0305 loss)
I0129 18:34:29.408255 30839 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I0129 18:35:05.965873 30839 solver.cpp:218] Iteration 5700 (2.73542 iter/s, 36.5575s/100 iters), loss = 10.2239
I0129 18:35:05.971360 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.2239 (* 1 = 10.2239 loss)
I0129 18:35:05.971398 30839 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I0129 18:35:42.480808 30839 solver.cpp:218] Iteration 5800 (2.73903 iter/s, 36.5093s/100 iters), loss = 10.9356
I0129 18:35:42.481030 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.9356 (* 1 = 10.9356 loss)
I0129 18:35:42.481055 30839 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I0129 18:36:18.992754 30839 solver.cpp:218] Iteration 5900 (2.73886 iter/s, 36.5115s/100 iters), loss = 10.0436
I0129 18:36:18.993041 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.0436 (* 1 = 10.0436 loss)
I0129 18:36:18.993073 30839 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I0129 18:36:55.506142 30839 solver.cpp:218] Iteration 6000 (2.73875 iter/s, 36.513s/100 iters), loss = 10.6278
I0129 18:36:55.511618 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.6278 (* 1 = 10.6278 loss)
I0129 18:36:55.511658 30839 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I0129 18:37:33.479228 30839 solver.cpp:218] Iteration 6100 (2.63383 iter/s, 37.9675s/100 iters), loss = 9.58405
I0129 18:37:33.484650 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.58405 (* 1 = 9.58405 loss)
I0129 18:37:33.484668 30839 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I0129 18:38:09.963896 30839 solver.cpp:218] Iteration 6200 (2.7413 iter/s, 36.4791s/100 iters), loss = 9.32817
I0129 18:38:09.964174 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.32817 (* 1 = 9.32817 loss)
I0129 18:38:09.964203 30839 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I0129 18:38:46.437405 30839 solver.cpp:218] Iteration 6300 (2.74175 iter/s, 36.4731s/100 iters), loss = 9.93162
I0129 18:38:46.437691 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.93162 (* 1 = 9.93162 loss)
I0129 18:38:46.437729 30839 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I0129 18:39:22.965349 30839 solver.cpp:218] Iteration 6400 (2.73766 iter/s, 36.5275s/100 iters), loss = 10.394
I0129 18:39:22.970988 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.394 (* 1 = 10.394 loss)
I0129 18:39:22.971030 30839 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I0129 18:39:59.442301 30839 solver.cpp:218] Iteration 6500 (2.74189 iter/s, 36.4711s/100 iters), loss = 8.68591
I0129 18:39:59.442589 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.68591 (* 1 = 8.68591 loss)
I0129 18:39:59.442622 30839 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I0129 18:40:35.973067 30839 solver.cpp:218] Iteration 6600 (2.73745 iter/s, 36.5303s/100 iters), loss = 9.44334
I0129 18:40:35.978482 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.44334 (* 1 = 9.44334 loss)
I0129 18:40:35.978502 30839 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I0129 18:41:12.479418 30839 solver.cpp:218] Iteration 6700 (2.73967 iter/s, 36.5008s/100 iters), loss = 8.98396
I0129 18:41:12.484818 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.98396 (* 1 = 8.98396 loss)
I0129 18:41:12.484834 30839 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I0129 18:41:48.965793 30839 solver.cpp:218] Iteration 6800 (2.74117 iter/s, 36.4808s/100 iters), loss = 9.01424
I0129 18:41:48.971297 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.01424 (* 1 = 9.01424 loss)
I0129 18:41:48.971345 30839 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I0129 18:42:25.439129 30839 solver.cpp:218] Iteration 6900 (2.74216 iter/s, 36.4676s/100 iters), loss = 9.24761
I0129 18:42:25.445006 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.24761 (* 1 = 9.24761 loss)
I0129 18:42:25.445050 30839 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I0129 18:43:01.924276 30839 solver.cpp:218] Iteration 7000 (2.74129 iter/s, 36.4791s/100 iters), loss = 9.75444
I0129 18:43:01.924582 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.75444 (* 1 = 9.75444 loss)
I0129 18:43:01.924618 30839 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I0129 18:43:38.387081 30839 solver.cpp:218] Iteration 7100 (2.74256 iter/s, 36.4623s/100 iters), loss = 10.0778
I0129 18:43:38.392168 30839 solver.cpp:237]     Train net output #0: softmax_loss = 10.0778 (* 1 = 10.0778 loss)
I0129 18:43:38.392211 30839 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I0129 18:44:14.887440 30839 solver.cpp:218] Iteration 7200 (2.74009 iter/s, 36.4951s/100 iters), loss = 8.91091
I0129 18:44:14.892941 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.91091 (* 1 = 8.91091 loss)
I0129 18:44:14.892987 30839 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I0129 18:44:51.408632 30839 solver.cpp:218] Iteration 7300 (2.73856 iter/s, 36.5155s/100 iters), loss = 8.4955
I0129 18:44:51.408833 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.4955 (* 1 = 8.4955 loss)
I0129 18:44:51.408854 30839 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I0129 18:45:27.868129 30839 solver.cpp:218] Iteration 7400 (2.7428 iter/s, 36.4591s/100 iters), loss = 9.24842
I0129 18:45:27.873631 30839 solver.cpp:237]     Train net output #0: softmax_loss = 9.24842 (* 1 = 9.24842 loss)
I0129 18:45:27.873667 30839 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I0129 18:46:04.370262 30839 solver.cpp:218] Iteration 7500 (2.73999 iter/s, 36.4965s/100 iters), loss = 8.90494
I0129 18:46:04.376332 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.90494 (* 1 = 8.90494 loss)
I0129 18:46:04.376368 30839 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I0129 18:46:40.806027 30839 solver.cpp:218] Iteration 7600 (2.74503 iter/s, 36.4295s/100 iters), loss = 8.73477
I0129 18:46:40.806324 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.73477 (* 1 = 8.73477 loss)
I0129 18:46:40.806358 30839 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I0129 18:47:17.292845 30839 solver.cpp:218] Iteration 7700 (2.74075 iter/s, 36.4864s/100 iters), loss = 7.77825
I0129 18:47:17.297889 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.77825 (* 1 = 7.77825 loss)
I0129 18:47:17.297906 30839 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I0129 18:47:53.763823 30839 solver.cpp:218] Iteration 7800 (2.7423 iter/s, 36.4657s/100 iters), loss = 8.34129
I0129 18:47:53.764061 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.34129 (* 1 = 8.34129 loss)
I0129 18:47:53.764083 30839 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I0129 18:48:30.286653 30839 solver.cpp:218] Iteration 7900 (2.73805 iter/s, 36.5224s/100 iters), loss = 8.82268
I0129 18:48:30.286931 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.82268 (* 1 = 8.82268 loss)
I0129 18:48:30.286962 30839 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I0129 18:49:06.747818 30839 solver.cpp:218] Iteration 8000 (2.74268 iter/s, 36.4607s/100 iters), loss = 8.52709
I0129 18:49:06.753319 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.52709 (* 1 = 8.52709 loss)
I0129 18:49:06.753365 30839 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I0129 18:49:43.193761 30839 solver.cpp:218] Iteration 8100 (2.74422 iter/s, 36.4403s/100 iters), loss = 8.73542
I0129 18:49:43.199209 30839 solver.cpp:237]     Train net output #0: softmax_loss = 8.73542 (* 1 = 8.73542 loss)
I0129 18:49:43.199252 30839 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I0129 18:50:19.661660 30839 solver.cpp:218] Iteration 8200 (2.74256 iter/s, 36.4623s/100 iters), loss = 7.86861
I0129 18:50:19.667138 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.86861 (* 1 = 7.86861 loss)
I0129 18:50:19.667151 30839 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I0129 18:50:57.890039 30839 solver.cpp:218] Iteration 8300 (2.61625 iter/s, 38.2227s/100 iters), loss = 7.76503
I0129 18:50:57.890280 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.76503 (* 1 = 7.76503 loss)
I0129 18:50:57.890300 30839 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I0129 18:51:34.368733 30839 solver.cpp:218] Iteration 8400 (2.74133 iter/s, 36.4786s/100 iters), loss = 7.6427
I0129 18:51:34.374220 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.6427 (* 1 = 7.6427 loss)
I0129 18:51:34.374277 30839 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I0129 18:52:10.871642 30839 solver.cpp:218] Iteration 8500 (2.7399 iter/s, 36.4976s/100 iters), loss = 7.57344
I0129 18:52:10.877066 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.57344 (* 1 = 7.57344 loss)
I0129 18:52:10.877082 30839 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I0129 18:52:47.309675 30839 solver.cpp:218] Iteration 8600 (2.74478 iter/s, 36.4328s/100 iters), loss = 7.0289
I0129 18:52:47.315078 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.0289 (* 1 = 7.0289 loss)
I0129 18:52:47.315090 30839 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I0129 18:53:23.843729 30839 solver.cpp:218] Iteration 8700 (2.73757 iter/s, 36.5288s/100 iters), loss = 7.92931
I0129 18:53:23.844028 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.92931 (* 1 = 7.92931 loss)
I0129 18:53:23.844068 30839 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I0129 18:54:00.349081 30839 solver.cpp:218] Iteration 8800 (2.73934 iter/s, 36.5052s/100 iters), loss = 6.90327
I0129 18:54:00.354161 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.90327 (* 1 = 6.90327 loss)
I0129 18:54:00.354183 30839 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I0129 18:54:36.900992 30839 solver.cpp:218] Iteration 8900 (2.73621 iter/s, 36.5469s/100 iters), loss = 7.07801
I0129 18:54:36.906486 30839 solver.cpp:237]     Train net output #0: softmax_loss = 7.07801 (* 1 = 7.07801 loss)
I0129 18:54:36.906525 30839 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I0129 18:55:13.417490 30839 solver.cpp:218] Iteration 9000 (2.73889 iter/s, 36.5111s/100 iters), loss = 6.96748
I0129 18:55:13.417784 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.96748 (* 1 = 6.96748 loss)
I0129 18:55:13.417816 30839 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I0129 18:55:49.910025 30839 solver.cpp:218] Iteration 9100 (2.7403 iter/s, 36.4923s/100 iters), loss = 6.2948
I0129 18:55:49.915400 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.2948 (* 1 = 6.2948 loss)
I0129 18:55:49.915433 30839 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I0129 18:56:26.471153 30839 solver.cpp:218] Iteration 9200 (2.73554 iter/s, 36.5558s/100 iters), loss = 6.26347
I0129 18:56:26.476627 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.26347 (* 1 = 6.26347 loss)
I0129 18:56:26.476667 30839 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I0129 18:57:02.999583 30839 solver.cpp:218] Iteration 9300 (2.738 iter/s, 36.523s/100 iters), loss = 5.75296
I0129 18:57:02.999866 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.75296 (* 1 = 5.75296 loss)
I0129 18:57:02.999907 30839 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I0129 18:57:39.557891 30839 solver.cpp:218] Iteration 9400 (2.73537 iter/s, 36.5581s/100 iters), loss = 6.96319
I0129 18:57:39.563376 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.96319 (* 1 = 6.96319 loss)
I0129 18:57:39.563417 30839 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I0129 18:58:16.143271 30839 solver.cpp:218] Iteration 9500 (2.73374 iter/s, 36.5799s/100 iters), loss = 6.10868
I0129 18:58:16.143532 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.10868 (* 1 = 6.10868 loss)
I0129 18:58:16.143558 30839 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I0129 18:58:23.951202 30839 blocking_queue.cpp:49] Waiting for data
I0129 18:58:52.648388 30839 solver.cpp:218] Iteration 9600 (2.73936 iter/s, 36.5049s/100 iters), loss = 5.96375
I0129 18:58:52.653803 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.96375 (* 1 = 5.96375 loss)
I0129 18:58:52.653821 30839 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I0129 18:59:29.234163 30839 solver.cpp:218] Iteration 9700 (2.73371 iter/s, 36.5804s/100 iters), loss = 6.19038
I0129 18:59:29.239987 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.19038 (* 1 = 6.19038 loss)
I0129 18:59:29.240027 30839 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I0129 19:00:05.825753 30839 solver.cpp:218] Iteration 9800 (2.7333 iter/s, 36.5858s/100 iters), loss = 6.20835
I0129 19:00:05.831178 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.20835 (* 1 = 6.20835 loss)
I0129 19:00:05.831198 30839 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I0129 19:00:42.364209 30839 solver.cpp:218] Iteration 9900 (2.73725 iter/s, 36.533s/100 iters), loss = 6.67795
I0129 19:00:42.369653 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.67795 (* 1 = 6.67795 loss)
I0129 19:00:42.369702 30839 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I0129 19:01:18.344646 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_10000.caffemodel
I0129 19:01:19.161998 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_10000.solverstate
I0129 19:01:19.734647 30839 solver.cpp:218] Iteration 10000 (2.6763 iter/s, 37.365s/100 iters), loss = 5.65012
I0129 19:01:19.734704 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.65012 (* 1 = 5.65012 loss)
I0129 19:01:19.734714 30839 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I0129 19:01:56.257848 30839 solver.cpp:218] Iteration 10100 (2.73799 iter/s, 36.5231s/100 iters), loss = 6.2234
I0129 19:01:56.263239 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.2234 (* 1 = 6.2234 loss)
I0129 19:01:56.263258 30839 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I0129 19:02:32.817852 30839 solver.cpp:218] Iteration 10200 (2.73563 iter/s, 36.5546s/100 iters), loss = 6.4323
I0129 19:02:32.823791 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.4323 (* 1 = 6.4323 loss)
I0129 19:02:32.823833 30839 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I0129 19:03:09.398311 30839 solver.cpp:218] Iteration 10300 (2.73416 iter/s, 36.5744s/100 iters), loss = 6.52204
I0129 19:03:09.398569 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.52204 (* 1 = 6.52204 loss)
I0129 19:03:09.398602 30839 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I0129 19:03:45.954792 30839 solver.cpp:218] Iteration 10400 (2.73551 iter/s, 36.5562s/100 iters), loss = 6.19728
I0129 19:03:45.960187 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.19728 (* 1 = 6.19728 loss)
I0129 19:03:45.960204 30839 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I0129 19:04:24.006678 30839 solver.cpp:218] Iteration 10500 (2.62837 iter/s, 38.0464s/100 iters), loss = 5.57493
I0129 19:04:24.012006 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.57493 (* 1 = 5.57493 loss)
I0129 19:04:24.012028 30839 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I0129 19:05:00.581699 30839 solver.cpp:218] Iteration 10600 (2.73451 iter/s, 36.5696s/100 iters), loss = 6.01449
I0129 19:05:00.581935 30839 solver.cpp:237]     Train net output #0: softmax_loss = 6.01449 (* 1 = 6.01449 loss)
I0129 19:05:00.581956 30839 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I0129 19:05:37.182569 30839 solver.cpp:218] Iteration 10700 (2.7322 iter/s, 36.6006s/100 iters), loss = 5.7647
I0129 19:05:37.187995 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.7647 (* 1 = 5.7647 loss)
I0129 19:05:37.188014 30839 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I0129 19:06:13.889459 30839 solver.cpp:218] Iteration 10800 (2.72469 iter/s, 36.7014s/100 iters), loss = 5.56741
I0129 19:06:13.894878 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.56741 (* 1 = 5.56741 loss)
I0129 19:06:13.894894 30839 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I0129 19:06:50.533020 30839 solver.cpp:218] Iteration 10900 (2.7294 iter/s, 36.6381s/100 iters), loss = 5.51484
I0129 19:06:50.538450 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.51484 (* 1 = 5.51484 loss)
I0129 19:06:50.538466 30839 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I0129 19:07:27.147007 30839 solver.cpp:218] Iteration 11000 (2.73161 iter/s, 36.6085s/100 iters), loss = 4.77062
I0129 19:07:27.152489 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.77062 (* 1 = 4.77062 loss)
I0129 19:07:27.152529 30839 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I0129 19:08:03.754225 30839 solver.cpp:218] Iteration 11100 (2.73212 iter/s, 36.6017s/100 iters), loss = 5.848
I0129 19:08:03.760082 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.848 (* 1 = 5.848 loss)
I0129 19:08:03.760118 30839 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I0129 19:08:40.371830 30839 solver.cpp:218] Iteration 11200 (2.73137 iter/s, 36.6117s/100 iters), loss = 5.08336
I0129 19:08:40.377238 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.08336 (* 1 = 5.08336 loss)
I0129 19:08:40.377255 30839 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I0129 19:09:17.105933 30839 solver.cpp:218] Iteration 11300 (2.72267 iter/s, 36.7286s/100 iters), loss = 5.28597
I0129 19:09:17.111363 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.28597 (* 1 = 5.28597 loss)
I0129 19:09:17.111385 30839 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I0129 19:09:53.745368 30839 solver.cpp:218] Iteration 11400 (2.72971 iter/s, 36.6339s/100 iters), loss = 5.53833
I0129 19:09:53.750835 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.53833 (* 1 = 5.53833 loss)
I0129 19:09:53.750874 30839 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I0129 19:10:30.455070 30839 solver.cpp:218] Iteration 11500 (2.72448 iter/s, 36.7042s/100 iters), loss = 5.02794
I0129 19:10:30.460570 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.02794 (* 1 = 5.02794 loss)
I0129 19:10:30.460613 30839 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I0129 19:11:07.169056 30839 solver.cpp:218] Iteration 11600 (2.72417 iter/s, 36.7084s/100 iters), loss = 5.29569
I0129 19:11:07.169369 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.29569 (* 1 = 5.29569 loss)
I0129 19:11:07.169405 30839 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I0129 19:11:43.906602 30839 solver.cpp:218] Iteration 11700 (2.72204 iter/s, 36.7372s/100 iters), loss = 5.17414
I0129 19:11:43.906862 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.17414 (* 1 = 5.17414 loss)
I0129 19:11:43.906893 30839 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I0129 19:12:20.542659 30839 solver.cpp:218] Iteration 11800 (2.72957 iter/s, 36.6357s/100 iters), loss = 5.72021
I0129 19:12:20.548108 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.72021 (* 1 = 5.72021 loss)
I0129 19:12:20.548153 30839 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I0129 19:12:57.177867 30839 solver.cpp:218] Iteration 11900 (2.73002 iter/s, 36.6297s/100 iters), loss = 5.01217
I0129 19:12:57.178167 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.01217 (* 1 = 5.01217 loss)
I0129 19:12:57.178200 30839 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I0129 19:13:33.839797 30839 solver.cpp:218] Iteration 12000 (2.72765 iter/s, 36.6615s/100 iters), loss = 4.84981
I0129 19:13:33.845280 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.84981 (* 1 = 4.84981 loss)
I0129 19:13:33.845319 30839 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I0129 19:14:10.535149 30839 solver.cpp:218] Iteration 12100 (2.72555 iter/s, 36.6898s/100 iters), loss = 5.08168
I0129 19:14:10.535423 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.08168 (* 1 = 5.08168 loss)
I0129 19:14:10.535470 30839 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I0129 19:14:47.273378 30839 solver.cpp:218] Iteration 12200 (2.72199 iter/s, 36.7379s/100 iters), loss = 5.33051
I0129 19:14:47.273694 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.33051 (* 1 = 5.33051 loss)
I0129 19:14:47.273727 30839 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I0129 19:15:23.980571 30839 solver.cpp:218] Iteration 12300 (2.72429 iter/s, 36.7068s/100 iters), loss = 5.32024
I0129 19:15:23.986093 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.32024 (* 1 = 5.32024 loss)
I0129 19:15:23.986140 30839 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I0129 19:16:00.692610 30839 solver.cpp:218] Iteration 12400 (2.72431 iter/s, 36.7065s/100 iters), loss = 5.57238
I0129 19:16:00.692880 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.57238 (* 1 = 5.57238 loss)
I0129 19:16:00.692901 30839 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I0129 19:16:37.401048 30839 solver.cpp:218] Iteration 12500 (2.7242 iter/s, 36.7081s/100 iters), loss = 5.254
I0129 19:16:37.401340 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.254 (* 1 = 5.254 loss)
I0129 19:16:37.401376 30839 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I0129 19:17:14.208469 30839 solver.cpp:218] Iteration 12600 (2.71687 iter/s, 36.8071s/100 iters), loss = 4.41753
I0129 19:17:14.208747 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.41753 (* 1 = 4.41753 loss)
I0129 19:17:14.208780 30839 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I0129 19:17:52.567586 30839 solver.cpp:218] Iteration 12700 (2.60697 iter/s, 38.3587s/100 iters), loss = 4.34842
I0129 19:17:52.573035 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.34842 (* 1 = 4.34842 loss)
I0129 19:17:52.573063 30839 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I0129 19:18:29.183612 30839 solver.cpp:218] Iteration 12800 (2.73146 iter/s, 36.6105s/100 iters), loss = 5.2115
I0129 19:18:29.183833 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.2115 (* 1 = 5.2115 loss)
I0129 19:18:29.183853 30839 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I0129 19:19:05.877426 30839 solver.cpp:218] Iteration 12900 (2.72528 iter/s, 36.6935s/100 iters), loss = 4.67948
I0129 19:19:05.882874 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.67948 (* 1 = 4.67948 loss)
I0129 19:19:05.882899 30839 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I0129 19:19:44.060675 30839 solver.cpp:218] Iteration 13000 (2.61933 iter/s, 38.1777s/100 iters), loss = 5.01505
I0129 19:19:44.066232 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.01505 (* 1 = 5.01505 loss)
I0129 19:19:44.066263 30839 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I0129 19:20:20.733067 30839 solver.cpp:218] Iteration 13100 (2.72727 iter/s, 36.6666s/100 iters), loss = 4.78625
I0129 19:20:20.733443 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.78625 (* 1 = 4.78625 loss)
I0129 19:20:20.733527 30839 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I0129 19:20:57.439462 30839 solver.cpp:218] Iteration 13200 (2.72435 iter/s, 36.706s/100 iters), loss = 4.17294
I0129 19:20:57.445088 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.17294 (* 1 = 4.17294 loss)
I0129 19:20:57.445127 30839 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I0129 19:21:34.179404 30839 solver.cpp:218] Iteration 13300 (2.72226 iter/s, 36.7342s/100 iters), loss = 4.84534
I0129 19:21:34.179661 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.84534 (* 1 = 4.84534 loss)
I0129 19:21:34.179702 30839 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I0129 19:22:10.897106 30839 solver.cpp:218] Iteration 13400 (2.72351 iter/s, 36.7174s/100 iters), loss = 4.80555
I0129 19:22:10.897399 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.80555 (* 1 = 4.80555 loss)
I0129 19:22:10.897435 30839 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I0129 19:22:47.658666 30839 solver.cpp:218] Iteration 13500 (2.72026 iter/s, 36.7612s/100 iters), loss = 4.8456
I0129 19:22:47.658905 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.8456 (* 1 = 4.8456 loss)
I0129 19:22:47.658947 30839 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I0129 19:23:24.344558 30839 solver.cpp:218] Iteration 13600 (2.72587 iter/s, 36.6856s/100 iters), loss = 4.24592
I0129 19:23:24.350189 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.24592 (* 1 = 4.24592 loss)
I0129 19:23:24.350229 30839 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I0129 19:24:01.150987 30839 solver.cpp:218] Iteration 13700 (2.71734 iter/s, 36.8007s/100 iters), loss = 4.27399
I0129 19:24:01.156610 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.27399 (* 1 = 4.27399 loss)
I0129 19:24:01.156649 30839 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I0129 19:24:37.862905 30839 solver.cpp:218] Iteration 13800 (2.72433 iter/s, 36.7062s/100 iters), loss = 5.46792
I0129 19:24:37.868422 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.46792 (* 1 = 5.46792 loss)
I0129 19:24:37.868448 30839 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I0129 19:25:14.641798 30839 solver.cpp:218] Iteration 13900 (2.71936 iter/s, 36.7733s/100 iters), loss = 4.05733
I0129 19:25:14.642127 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.05733 (* 1 = 4.05733 loss)
I0129 19:25:14.642156 30839 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I0129 19:25:51.381383 30839 solver.cpp:218] Iteration 14000 (2.7219 iter/s, 36.7391s/100 iters), loss = 4.59139
I0129 19:25:51.387012 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.59139 (* 1 = 4.59139 loss)
I0129 19:25:51.387046 30839 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I0129 19:26:28.153460 30839 solver.cpp:218] Iteration 14100 (2.7199 iter/s, 36.766s/100 iters), loss = 4.76946
I0129 19:26:28.159080 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.76946 (* 1 = 4.76946 loss)
I0129 19:26:28.159119 30839 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I0129 19:27:04.919535 30839 solver.cpp:218] Iteration 14200 (2.72034 iter/s, 36.7601s/100 iters), loss = 4.16223
I0129 19:27:04.925601 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.16223 (* 1 = 4.16223 loss)
I0129 19:27:04.925624 30839 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I0129 19:27:41.671119 30839 solver.cpp:218] Iteration 14300 (2.72145 iter/s, 36.7451s/100 iters), loss = 4.524
I0129 19:27:41.676755 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.524 (* 1 = 4.524 loss)
I0129 19:27:41.676791 30839 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I0129 19:28:18.386250 30839 solver.cpp:218] Iteration 14400 (2.72412 iter/s, 36.7091s/100 iters), loss = 4.38417
I0129 19:28:18.391939 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.38417 (* 1 = 4.38417 loss)
I0129 19:28:18.391973 30839 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I0129 19:28:55.111771 30839 solver.cpp:218] Iteration 14500 (2.72335 iter/s, 36.7195s/100 iters), loss = 3.8266
I0129 19:28:55.117384 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.8266 (* 1 = 3.8266 loss)
I0129 19:28:55.117424 30839 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I0129 19:29:31.849083 30839 solver.cpp:218] Iteration 14600 (2.72247 iter/s, 36.7313s/100 iters), loss = 4.11335
I0129 19:29:31.849413 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.11335 (* 1 = 4.11335 loss)
I0129 19:29:31.849455 30839 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I0129 19:30:08.619875 30839 solver.cpp:218] Iteration 14700 (2.7196 iter/s, 36.7702s/100 iters), loss = 4.15332
I0129 19:30:08.625366 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.15332 (* 1 = 4.15332 loss)
I0129 19:30:08.625411 30839 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I0129 19:30:45.418282 30839 solver.cpp:218] Iteration 14800 (2.71794 iter/s, 36.7926s/100 iters), loss = 4.78333
I0129 19:30:45.424088 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.78333 (* 1 = 4.78333 loss)
I0129 19:30:45.424125 30839 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I0129 19:30:50.717283 30839 blocking_queue.cpp:49] Waiting for data
I0129 19:31:22.230286 30839 solver.cpp:218] Iteration 14900 (2.71696 iter/s, 36.8059s/100 iters), loss = 5.12925
I0129 19:31:22.235791 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.12925 (* 1 = 5.12925 loss)
I0129 19:31:22.235810 30839 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I0129 19:31:58.690908 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_15000.caffemodel
I0129 19:31:59.297479 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_15000.solverstate
I0129 19:31:59.872726 30839 solver.cpp:218] Iteration 15000 (2.65698 iter/s, 37.6366s/100 iters), loss = 4.52099
I0129 19:31:59.872799 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.52099 (* 1 = 4.52099 loss)
I0129 19:31:59.872812 30839 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I0129 19:32:36.702276 30839 solver.cpp:218] Iteration 15100 (2.71524 iter/s, 36.8292s/100 iters), loss = 3.73449
I0129 19:32:36.702605 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.73449 (* 1 = 3.73449 loss)
I0129 19:32:36.702639 30839 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I0129 19:33:13.545763 30839 solver.cpp:218] Iteration 15200 (2.71423 iter/s, 36.8428s/100 iters), loss = 4.79529
I0129 19:33:13.546128 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.79529 (* 1 = 4.79529 loss)
I0129 19:33:13.546164 30839 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I0129 19:33:50.427114 30839 solver.cpp:218] Iteration 15300 (2.71144 iter/s, 36.8807s/100 iters), loss = 3.68787
I0129 19:33:50.427464 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.68787 (* 1 = 3.68787 loss)
I0129 19:33:50.427495 30839 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I0129 19:34:27.376849 30839 solver.cpp:218] Iteration 15400 (2.70642 iter/s, 36.9492s/100 iters), loss = 4.52829
I0129 19:34:27.377084 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.52829 (* 1 = 4.52829 loss)
I0129 19:34:27.377101 30839 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I0129 19:35:04.261620 30839 solver.cpp:218] Iteration 15500 (2.71118 iter/s, 36.8843s/100 iters), loss = 3.72821
I0129 19:35:04.261914 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.72821 (* 1 = 3.72821 loss)
I0129 19:35:04.261946 30839 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I0129 19:35:41.077886 30839 solver.cpp:218] Iteration 15600 (2.71623 iter/s, 36.8157s/100 iters), loss = 4.1224
I0129 19:35:41.083361 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.1224 (* 1 = 4.1224 loss)
I0129 19:35:41.083400 30839 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I0129 19:36:17.996508 30839 solver.cpp:218] Iteration 15700 (2.70908 iter/s, 36.9129s/100 iters), loss = 3.64018
I0129 19:36:18.001929 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.64018 (* 1 = 3.64018 loss)
I0129 19:36:18.001951 30839 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I0129 19:36:54.908705 30839 solver.cpp:218] Iteration 15800 (2.70955 iter/s, 36.9065s/100 iters), loss = 4.55637
I0129 19:36:54.914124 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.55637 (* 1 = 4.55637 loss)
I0129 19:36:54.914136 30839 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I0129 19:37:31.764092 30839 solver.cpp:218] Iteration 15900 (2.71372 iter/s, 36.8497s/100 iters), loss = 5.04849
I0129 19:37:31.764432 30839 solver.cpp:237]     Train net output #0: softmax_loss = 5.04849 (* 1 = 5.04849 loss)
I0129 19:37:31.764483 30839 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I0129 19:38:08.586582 30839 solver.cpp:218] Iteration 16000 (2.71577 iter/s, 36.822s/100 iters), loss = 4.17811
I0129 19:38:08.586894 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.17811 (* 1 = 4.17811 loss)
I0129 19:38:08.586937 30839 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I0129 19:38:45.403864 30839 solver.cpp:218] Iteration 16100 (2.71615 iter/s, 36.8168s/100 iters), loss = 3.81226
I0129 19:38:45.404068 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.81226 (* 1 = 3.81226 loss)
I0129 19:38:45.404083 30839 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I0129 19:39:22.320816 30839 solver.cpp:218] Iteration 16200 (2.70881 iter/s, 36.9165s/100 iters), loss = 4.40567
I0129 19:39:22.326231 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.40567 (* 1 = 4.40567 loss)
I0129 19:39:22.326247 30839 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I0129 19:39:59.071609 30839 solver.cpp:218] Iteration 16300 (2.72145 iter/s, 36.7452s/100 iters), loss = 4.41864
I0129 19:39:59.077052 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.41864 (* 1 = 4.41864 loss)
I0129 19:39:59.077098 30839 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I0129 19:40:35.909018 30839 solver.cpp:218] Iteration 16400 (2.71505 iter/s, 36.8318s/100 iters), loss = 4.88962
I0129 19:40:35.914491 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.88962 (* 1 = 4.88962 loss)
I0129 19:40:35.914535 30839 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I0129 19:41:12.716449 30839 solver.cpp:218] Iteration 16500 (2.71726 iter/s, 36.8018s/100 iters), loss = 4.1125
I0129 19:41:12.721871 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.1125 (* 1 = 4.1125 loss)
I0129 19:41:12.721889 30839 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I0129 19:41:49.452409 30839 solver.cpp:218] Iteration 16600 (2.72254 iter/s, 36.7303s/100 iters), loss = 4.23081
I0129 19:41:49.457895 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.23081 (* 1 = 4.23081 loss)
I0129 19:41:49.457952 30839 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I0129 19:42:26.277940 30839 solver.cpp:218] Iteration 16700 (2.71593 iter/s, 36.8199s/100 iters), loss = 3.90934
I0129 19:42:26.283433 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.90934 (* 1 = 3.90934 loss)
I0129 19:42:26.283479 30839 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I0129 19:43:03.093451 30839 solver.cpp:218] Iteration 16800 (2.71666 iter/s, 36.8099s/100 iters), loss = 4.40761
I0129 19:43:03.101155 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.40761 (* 1 = 4.40761 loss)
I0129 19:43:03.101172 30839 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I0129 19:43:39.869453 30839 solver.cpp:218] Iteration 16900 (2.71975 iter/s, 36.7681s/100 iters), loss = 4.33137
I0129 19:43:39.874982 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.33137 (* 1 = 4.33137 loss)
I0129 19:43:39.874997 30839 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I0129 19:44:16.763010 30839 solver.cpp:218] Iteration 17000 (2.71092 iter/s, 36.8878s/100 iters), loss = 4.33698
I0129 19:44:16.768445 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.33698 (* 1 = 4.33698 loss)
I0129 19:44:16.768463 30839 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I0129 19:44:53.676715 30839 solver.cpp:218] Iteration 17100 (2.70943 iter/s, 36.9081s/100 iters), loss = 4.13309
I0129 19:44:53.684444 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.13309 (* 1 = 4.13309 loss)
I0129 19:44:53.684463 30839 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I0129 19:45:30.502032 30839 solver.cpp:218] Iteration 17200 (2.71611 iter/s, 36.8174s/100 iters), loss = 4.31482
I0129 19:45:30.509703 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.31482 (* 1 = 4.31482 loss)
I0129 19:45:30.509717 30839 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I0129 19:46:07.466243 30839 solver.cpp:218] Iteration 17300 (2.70589 iter/s, 36.9564s/100 iters), loss = 4.54675
I0129 19:46:07.471348 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.54675 (* 1 = 4.54675 loss)
I0129 19:46:07.471400 30839 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I0129 19:46:44.358389 30839 solver.cpp:218] Iteration 17400 (2.71099 iter/s, 36.8869s/100 iters), loss = 3.77807
I0129 19:46:44.363869 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.77807 (* 1 = 3.77807 loss)
I0129 19:46:44.363919 30839 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I0129 19:47:21.245928 30839 solver.cpp:218] Iteration 17500 (2.71136 iter/s, 36.8819s/100 iters), loss = 4.42715
I0129 19:47:21.251404 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.42715 (* 1 = 4.42715 loss)
I0129 19:47:21.251442 30839 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I0129 19:47:58.147079 30839 solver.cpp:218] Iteration 17600 (2.71036 iter/s, 36.8955s/100 iters), loss = 3.70523
I0129 19:47:58.152523 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.70523 (* 1 = 3.70523 loss)
I0129 19:47:58.152545 30839 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I0129 19:48:35.222993 30839 solver.cpp:218] Iteration 17700 (2.69758 iter/s, 37.0703s/100 iters), loss = 3.75371
I0129 19:48:35.228427 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.75371 (* 1 = 3.75371 loss)
I0129 19:48:35.228463 30839 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I0129 19:49:12.154974 30839 solver.cpp:218] Iteration 17800 (2.70809 iter/s, 36.9264s/100 iters), loss = 3.33334
I0129 19:49:12.160334 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33334 (* 1 = 3.33334 loss)
I0129 19:49:12.160352 30839 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I0129 19:49:49.083387 30839 solver.cpp:218] Iteration 17900 (2.70835 iter/s, 36.9229s/100 iters), loss = 4.08208
I0129 19:49:49.083592 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.08208 (* 1 = 4.08208 loss)
I0129 19:49:49.083609 30839 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I0129 19:50:26.186834 30839 solver.cpp:218] Iteration 18000 (2.6952 iter/s, 37.1031s/100 iters), loss = 3.55076
I0129 19:50:26.192297 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55076 (* 1 = 3.55076 loss)
I0129 19:50:26.192339 30839 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I0129 19:51:03.110632 30839 solver.cpp:218] Iteration 18100 (2.70869 iter/s, 36.9182s/100 iters), loss = 3.91197
I0129 19:51:03.110842 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.91197 (* 1 = 3.91197 loss)
I0129 19:51:03.110860 30839 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I0129 19:51:39.974150 30839 solver.cpp:218] Iteration 18200 (2.71274 iter/s, 36.8631s/100 iters), loss = 3.54109
I0129 19:51:39.979755 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.54109 (* 1 = 3.54109 loss)
I0129 19:51:39.979800 30839 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I0129 19:52:16.848358 30839 solver.cpp:218] Iteration 18300 (2.71234 iter/s, 36.8685s/100 iters), loss = 4.04379
I0129 19:52:16.853484 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.04379 (* 1 = 4.04379 loss)
I0129 19:52:16.853526 30839 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I0129 19:52:53.677605 30839 solver.cpp:218] Iteration 18400 (2.71562 iter/s, 36.824s/100 iters), loss = 4.28933
I0129 19:52:53.683035 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.28933 (* 1 = 4.28933 loss)
I0129 19:52:53.683054 30839 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I0129 19:53:30.614400 30839 solver.cpp:218] Iteration 18500 (2.70774 iter/s, 36.9312s/100 iters), loss = 4.03938
I0129 19:53:30.619820 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.03938 (* 1 = 4.03938 loss)
I0129 19:53:30.619834 30839 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I0129 19:54:07.612984 30839 solver.cpp:218] Iteration 18600 (2.70321 iter/s, 36.993s/100 iters), loss = 3.66842
I0129 19:54:07.618122 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.66842 (* 1 = 3.66842 loss)
I0129 19:54:07.618166 30839 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I0129 19:54:44.558329 30839 solver.cpp:218] Iteration 18700 (2.70709 iter/s, 36.9401s/100 iters), loss = 4.04274
I0129 19:54:44.563829 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.04274 (* 1 = 4.04274 loss)
I0129 19:54:44.563868 30839 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I0129 19:55:21.429921 30839 solver.cpp:218] Iteration 18800 (2.71253 iter/s, 36.866s/100 iters), loss = 3.6012
I0129 19:55:21.430205 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.6012 (* 1 = 3.6012 loss)
I0129 19:55:21.430238 30839 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I0129 19:55:58.326874 30839 solver.cpp:218] Iteration 18900 (2.71028 iter/s, 36.8965s/100 iters), loss = 3.62856
I0129 19:55:58.332362 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.62856 (* 1 = 3.62856 loss)
I0129 19:55:58.332401 30839 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I0129 19:56:35.185122 30839 solver.cpp:218] Iteration 19000 (2.71351 iter/s, 36.8526s/100 iters), loss = 4.31145
I0129 19:56:35.190459 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.31145 (* 1 = 4.31145 loss)
I0129 19:56:35.190482 30839 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I0129 19:57:12.204066 30839 solver.cpp:218] Iteration 19100 (2.70172 iter/s, 37.0135s/100 iters), loss = 3.82929
I0129 19:57:12.209547 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.82929 (* 1 = 3.82929 loss)
I0129 19:57:12.209583 30839 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I0129 19:57:49.043088 30839 solver.cpp:218] Iteration 19200 (2.71493 iter/s, 36.8334s/100 iters), loss = 3.98353
I0129 19:57:49.048578 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.98353 (* 1 = 3.98353 loss)
I0129 19:57:49.048622 30839 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I0129 19:58:26.050923 30839 solver.cpp:218] Iteration 19300 (2.70254 iter/s, 37.0022s/100 iters), loss = 4.02084
I0129 19:58:26.056367 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.02084 (* 1 = 4.02084 loss)
I0129 19:58:26.056396 30839 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I0129 19:59:02.865142 30839 solver.cpp:218] Iteration 19400 (2.71675 iter/s, 36.8086s/100 iters), loss = 3.95422
I0129 19:59:02.865416 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.95422 (* 1 = 3.95422 loss)
I0129 19:59:02.865447 30839 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I0129 19:59:39.808980 30839 solver.cpp:218] Iteration 19500 (2.70684 iter/s, 36.9434s/100 iters), loss = 4.02182
I0129 19:59:39.814396 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.02182 (* 1 = 4.02182 loss)
I0129 19:59:39.814414 30839 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I0129 20:00:17.827960 30839 solver.cpp:218] Iteration 19600 (2.63059 iter/s, 38.0142s/100 iters), loss = 4.95677
I0129 20:00:17.835525 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.95677 (* 1 = 4.95677 loss)
I0129 20:00:17.835543 30839 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I0129 20:00:55.936147 30839 solver.cpp:218] Iteration 19700 (2.62457 iter/s, 38.1016s/100 iters), loss = 3.9482
I0129 20:00:55.941617 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.9482 (* 1 = 3.9482 loss)
I0129 20:00:55.941654 30839 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I0129 20:01:32.864236 30839 solver.cpp:218] Iteration 19800 (2.7083 iter/s, 36.9235s/100 iters), loss = 2.9673
I0129 20:01:32.869599 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.9673 (* 1 = 2.9673 loss)
I0129 20:01:32.869616 30839 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I0129 20:02:09.955569 30839 solver.cpp:218] Iteration 19900 (2.69638 iter/s, 37.0868s/100 iters), loss = 3.85113
I0129 20:02:09.961009 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.85113 (* 1 = 3.85113 loss)
I0129 20:02:09.961035 30839 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I0129 20:02:46.566143 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_20000.caffemodel
I0129 20:02:47.151597 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_20000.solverstate
I0129 20:02:47.736168 30839 solver.cpp:218] Iteration 20000 (2.64719 iter/s, 37.7759s/100 iters), loss = 3.66226
I0129 20:02:47.736240 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.66226 (* 1 = 3.66226 loss)
I0129 20:02:47.736256 30839 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I0129 20:03:24.648540 30839 solver.cpp:218] Iteration 20100 (2.70908 iter/s, 36.913s/100 iters), loss = 3.97695
I0129 20:03:24.654008 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.97695 (* 1 = 3.97695 loss)
I0129 20:03:24.654096 30839 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I0129 20:04:01.669816 30839 solver.cpp:218] Iteration 20200 (2.7015 iter/s, 37.0165s/100 iters), loss = 3.55601
I0129 20:04:01.670081 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55601 (* 1 = 3.55601 loss)
I0129 20:04:01.670110 30839 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I0129 20:04:38.839308 30839 solver.cpp:218] Iteration 20300 (2.69035 iter/s, 37.1698s/100 iters), loss = 4.08436
I0129 20:04:38.844343 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.08436 (* 1 = 4.08436 loss)
I0129 20:04:38.844362 30839 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I0129 20:05:15.904481 30839 solver.cpp:218] Iteration 20400 (2.69828 iter/s, 37.0607s/100 iters), loss = 4.08176
I0129 20:05:15.909965 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.08176 (* 1 = 4.08176 loss)
I0129 20:05:15.910002 30839 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I0129 20:05:52.895624 30839 solver.cpp:218] Iteration 20500 (2.70371 iter/s, 36.9862s/100 iters), loss = 3.63098
I0129 20:05:52.901089 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.63098 (* 1 = 3.63098 loss)
I0129 20:05:52.901109 30839 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I0129 20:06:29.948815 30839 solver.cpp:218] Iteration 20600 (2.69919 iter/s, 37.0482s/100 iters), loss = 3.18156
I0129 20:06:29.954242 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.18156 (* 1 = 3.18156 loss)
I0129 20:06:29.954258 30839 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I0129 20:07:06.931839 30839 solver.cpp:218] Iteration 20700 (2.70431 iter/s, 36.978s/100 iters), loss = 3.92549
I0129 20:07:06.937341 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.92549 (* 1 = 3.92549 loss)
I0129 20:07:06.937393 30839 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I0129 20:07:43.938498 30839 solver.cpp:218] Iteration 20800 (2.70258 iter/s, 37.0016s/100 iters), loss = 3.23082
I0129 20:07:43.943915 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.23082 (* 1 = 3.23082 loss)
I0129 20:07:43.943929 30839 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I0129 20:08:20.889463 30839 solver.cpp:218] Iteration 20900 (2.70666 iter/s, 36.9459s/100 iters), loss = 3.34778
I0129 20:08:20.895571 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.34778 (* 1 = 3.34778 loss)
I0129 20:08:20.895612 30839 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I0129 20:08:57.813308 30839 solver.cpp:218] Iteration 21000 (2.7087 iter/s, 36.9181s/100 iters), loss = 3.33812
I0129 20:08:57.818794 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33812 (* 1 = 3.33812 loss)
I0129 20:08:57.818806 30839 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I0129 20:09:34.977452 30839 solver.cpp:218] Iteration 21100 (2.69114 iter/s, 37.159s/100 iters), loss = 4.21516
I0129 20:09:34.982925 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.21516 (* 1 = 4.21516 loss)
I0129 20:09:34.982964 30839 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I0129 20:10:12.071220 30839 solver.cpp:218] Iteration 21200 (2.69625 iter/s, 37.0886s/100 iters), loss = 3.07071
I0129 20:10:12.076716 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.07071 (* 1 = 3.07071 loss)
I0129 20:10:12.076763 30839 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I0129 20:10:49.062095 30839 solver.cpp:218] Iteration 21300 (2.70375 iter/s, 36.9857s/100 iters), loss = 3.33875
I0129 20:10:49.067582 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33875 (* 1 = 3.33875 loss)
I0129 20:10:49.067634 30839 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I0129 20:11:26.058532 30839 solver.cpp:218] Iteration 21400 (2.70334 iter/s, 36.9912s/100 iters), loss = 3.55108
I0129 20:11:26.066359 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55108 (* 1 = 3.55108 loss)
I0129 20:11:26.066398 30839 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I0129 20:12:03.021530 30839 solver.cpp:218] Iteration 21500 (2.70596 iter/s, 36.9554s/100 iters), loss = 2.99954
I0129 20:12:03.026849 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.99954 (* 1 = 2.99954 loss)
I0129 20:12:03.026871 30839 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I0129 20:12:40.023694 30839 solver.cpp:218] Iteration 21600 (2.70292 iter/s, 36.997s/100 iters), loss = 4.39114
I0129 20:12:40.024009 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.39114 (* 1 = 4.39114 loss)
I0129 20:12:40.024049 30839 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I0129 20:13:17.019937 30839 solver.cpp:218] Iteration 21700 (2.70298 iter/s, 36.9962s/100 iters), loss = 3.901
I0129 20:13:17.020153 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.901 (* 1 = 3.901 loss)
I0129 20:13:17.020176 30839 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I0129 20:13:54.072156 30839 solver.cpp:218] Iteration 21800 (2.6989 iter/s, 37.0522s/100 iters), loss = 3.44195
I0129 20:13:54.077651 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.44195 (* 1 = 3.44195 loss)
I0129 20:13:54.077688 30839 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I0129 20:14:31.151669 30839 solver.cpp:218] Iteration 21900 (2.69729 iter/s, 37.0742s/100 iters), loss = 3.70257
I0129 20:14:31.151954 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.70257 (* 1 = 3.70257 loss)
I0129 20:14:31.151985 30839 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I0129 20:15:08.271924 30839 solver.cpp:218] Iteration 22000 (2.69395 iter/s, 37.1201s/100 iters), loss = 4.1523
I0129 20:15:08.277400 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.1523 (* 1 = 4.1523 loss)
I0129 20:15:08.277439 30839 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I0129 20:15:45.265358 30839 solver.cpp:218] Iteration 22100 (2.70357 iter/s, 36.9881s/100 iters), loss = 3.51741
I0129 20:15:45.270474 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.51741 (* 1 = 3.51741 loss)
I0129 20:15:45.270516 30839 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I0129 20:16:22.349222 30839 solver.cpp:218] Iteration 22200 (2.69695 iter/s, 37.0789s/100 iters), loss = 3.49484
I0129 20:16:22.354576 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.49484 (* 1 = 3.49484 loss)
I0129 20:16:22.354598 30839 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I0129 20:16:59.349927 30839 solver.cpp:218] Iteration 22300 (2.70303 iter/s, 36.9955s/100 iters), loss = 4.30344
I0129 20:16:59.355409 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.30344 (* 1 = 4.30344 loss)
I0129 20:16:59.355448 30839 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I0129 20:17:36.319561 30839 solver.cpp:218] Iteration 22400 (2.70531 iter/s, 36.9643s/100 iters), loss = 3.68792
I0129 20:17:36.325000 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.68792 (* 1 = 3.68792 loss)
I0129 20:17:36.325016 30839 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I0129 20:18:13.435485 30839 solver.cpp:218] Iteration 22500 (2.69465 iter/s, 37.1106s/100 iters), loss = 4.11651
I0129 20:18:13.441545 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.11651 (* 1 = 4.11651 loss)
I0129 20:18:13.441589 30839 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I0129 20:18:50.422394 30839 solver.cpp:218] Iteration 22600 (2.70409 iter/s, 36.981s/100 iters), loss = 3.95063
I0129 20:18:50.422668 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.95063 (* 1 = 3.95063 loss)
I0129 20:18:50.422699 30839 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I0129 20:19:27.562305 30839 solver.cpp:218] Iteration 22700 (2.69253 iter/s, 37.1397s/100 iters), loss = 3.52251
I0129 20:19:27.562585 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.52251 (* 1 = 3.52251 loss)
I0129 20:19:27.562625 30839 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I0129 20:20:04.629097 30839 solver.cpp:218] Iteration 22800 (2.69785 iter/s, 37.0666s/100 iters), loss = 4.10916
I0129 20:20:04.634583 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.10916 (* 1 = 4.10916 loss)
I0129 20:20:04.634629 30839 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I0129 20:20:41.612726 30839 solver.cpp:218] Iteration 22900 (2.70429 iter/s, 36.9782s/100 iters), loss = 3.36512
I0129 20:20:41.618158 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.36512 (* 1 = 3.36512 loss)
I0129 20:20:41.618173 30839 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I0129 20:21:18.673382 30839 solver.cpp:218] Iteration 23000 (2.69867 iter/s, 37.0553s/100 iters), loss = 3.70319
I0129 20:21:18.678787 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.70319 (* 1 = 3.70319 loss)
I0129 20:21:18.678812 30839 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I0129 20:21:55.715618 30839 solver.cpp:218] Iteration 23100 (2.70001 iter/s, 37.0369s/100 iters), loss = 3.4371
I0129 20:21:55.715943 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.4371 (* 1 = 3.4371 loss)
I0129 20:21:55.715975 30839 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I0129 20:22:32.792240 30839 solver.cpp:218] Iteration 23200 (2.69713 iter/s, 37.0764s/100 iters), loss = 3.4603
I0129 20:22:32.797312 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.4603 (* 1 = 3.4603 loss)
I0129 20:22:32.797334 30839 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I0129 20:23:09.870751 30839 solver.cpp:218] Iteration 23300 (2.69735 iter/s, 37.0735s/100 iters), loss = 3.63462
I0129 20:23:09.871037 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.63462 (* 1 = 3.63462 loss)
I0129 20:23:09.871068 30839 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I0129 20:23:46.860735 30839 solver.cpp:218] Iteration 23400 (2.70345 iter/s, 36.9898s/100 iters), loss = 3.46501
I0129 20:23:46.866165 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.46501 (* 1 = 3.46501 loss)
I0129 20:23:46.866194 30839 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I0129 20:24:23.956305 30839 solver.cpp:218] Iteration 23500 (2.69613 iter/s, 37.0902s/100 iters), loss = 3.45803
I0129 20:24:23.961732 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.45803 (* 1 = 3.45803 loss)
I0129 20:24:23.961747 30839 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I0129 20:25:01.018873 30839 solver.cpp:218] Iteration 23600 (2.69853 iter/s, 37.0572s/100 iters), loss = 3.01442
I0129 20:25:01.024315 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.01442 (* 1 = 3.01442 loss)
I0129 20:25:01.024329 30839 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I0129 20:25:38.099835 30839 solver.cpp:218] Iteration 23700 (2.69719 iter/s, 37.0756s/100 iters), loss = 3.38941
I0129 20:25:38.105257 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.38941 (* 1 = 3.38941 loss)
I0129 20:25:38.105276 30839 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I0129 20:26:15.121017 30839 solver.cpp:218] Iteration 23800 (2.70155 iter/s, 37.0158s/100 iters), loss = 3.6829
I0129 20:26:15.126431 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.6829 (* 1 = 3.6829 loss)
I0129 20:26:15.126451 30839 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I0129 20:26:52.167104 30839 solver.cpp:218] Iteration 23900 (2.69973 iter/s, 37.0407s/100 iters), loss = 3.43868
I0129 20:26:52.167390 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.43868 (* 1 = 3.43868 loss)
I0129 20:26:52.167423 30839 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I0129 20:27:29.277942 30839 solver.cpp:218] Iteration 24000 (2.69465 iter/s, 37.1106s/100 iters), loss = 3.1664
I0129 20:27:29.283358 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.1664 (* 1 = 3.1664 loss)
I0129 20:27:29.283375 30839 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I0129 20:28:06.362336 30839 solver.cpp:218] Iteration 24100 (2.69694 iter/s, 37.079s/100 iters), loss = 3.75702
I0129 20:28:06.362555 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.75702 (* 1 = 3.75702 loss)
I0129 20:28:06.362576 30839 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I0129 20:28:43.337044 30839 solver.cpp:218] Iteration 24200 (2.70457 iter/s, 36.9745s/100 iters), loss = 3.55024
I0129 20:28:43.342403 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55024 (* 1 = 3.55024 loss)
I0129 20:28:43.342424 30839 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I0129 20:29:20.435071 30839 solver.cpp:218] Iteration 24300 (2.69595 iter/s, 37.0927s/100 iters), loss = 3.612
I0129 20:29:20.435365 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.612 (* 1 = 3.612 loss)
I0129 20:29:20.435397 30839 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I0129 20:29:57.510519 30839 solver.cpp:218] Iteration 24400 (2.69722 iter/s, 37.0752s/100 iters), loss = 2.9942
I0129 20:29:57.515956 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.9942 (* 1 = 2.9942 loss)
I0129 20:29:57.515972 30839 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I0129 20:30:34.488591 30839 solver.cpp:218] Iteration 24500 (2.7047 iter/s, 36.9726s/100 iters), loss = 3.93445
I0129 20:30:34.494087 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.93445 (* 1 = 3.93445 loss)
I0129 20:30:34.494125 30839 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I0129 20:31:11.497879 30839 solver.cpp:218] Iteration 24600 (2.70242 iter/s, 37.0038s/100 iters), loss = 3.44626
I0129 20:31:11.503301 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.44626 (* 1 = 3.44626 loss)
I0129 20:31:11.503319 30839 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I0129 20:31:48.519351 30839 solver.cpp:218] Iteration 24700 (2.70153 iter/s, 37.0161s/100 iters), loss = 3.47063
I0129 20:31:48.524794 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.47063 (* 1 = 3.47063 loss)
I0129 20:31:48.524822 30839 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I0129 20:32:25.679958 30839 solver.cpp:218] Iteration 24800 (2.69141 iter/s, 37.1552s/100 iters), loss = 3.46436
I0129 20:32:25.685446 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.46436 (* 1 = 3.46436 loss)
I0129 20:32:25.685477 30839 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I0129 20:33:02.731201 30839 solver.cpp:218] Iteration 24900 (2.69936 iter/s, 37.0458s/100 iters), loss = 4.05305
I0129 20:33:02.736694 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.05305 (* 1 = 4.05305 loss)
I0129 20:33:02.736708 30839 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I0129 20:33:39.345187 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_25000.caffemodel
I0129 20:33:40.034399 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_25000.solverstate
I0129 20:33:40.637531 30839 solver.cpp:218] Iteration 25000 (2.63846 iter/s, 37.9008s/100 iters), loss = 3.86494
I0129 20:33:40.637588 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.86494 (* 1 = 3.86494 loss)
I0129 20:33:40.637600 30839 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I0129 20:34:17.513252 30839 solver.cpp:218] Iteration 25100 (2.71179 iter/s, 36.876s/100 iters), loss = 3.94083
I0129 20:34:17.518664 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.94083 (* 1 = 3.94083 loss)
I0129 20:34:17.518678 30839 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I0129 20:34:54.502316 30839 solver.cpp:218] Iteration 25200 (2.70385 iter/s, 36.9843s/100 iters), loss = 3.3713
I0129 20:34:54.507812 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.3713 (* 1 = 3.3713 loss)
I0129 20:34:54.507853 30839 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I0129 20:35:31.502885 30839 solver.cpp:218] Iteration 25300 (2.70302 iter/s, 36.9957s/100 iters), loss = 3.61206
I0129 20:35:31.508299 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.61206 (* 1 = 3.61206 loss)
I0129 20:35:31.508318 30839 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I0129 20:35:49.059185 30839 blocking_queue.cpp:49] Waiting for data
I0129 20:36:08.546864 30839 solver.cpp:218] Iteration 25400 (2.69985 iter/s, 37.0391s/100 iters), loss = 3.38185
I0129 20:36:08.547094 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.38185 (* 1 = 3.38185 loss)
I0129 20:36:08.547117 30839 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I0129 20:36:45.565989 30839 solver.cpp:218] Iteration 25500 (2.70128 iter/s, 37.0194s/100 iters), loss = 3.28822
I0129 20:36:45.573748 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.28822 (* 1 = 3.28822 loss)
I0129 20:36:45.573761 30839 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I0129 20:37:22.686877 30839 solver.cpp:218] Iteration 25600 (2.69443 iter/s, 37.1136s/100 iters), loss = 3.13166
I0129 20:37:22.692488 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.13166 (* 1 = 3.13166 loss)
I0129 20:37:22.692524 30839 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I0129 20:37:59.775871 30839 solver.cpp:218] Iteration 25700 (2.69659 iter/s, 37.0839s/100 iters), loss = 3.62753
I0129 20:37:59.776159 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.62753 (* 1 = 3.62753 loss)
I0129 20:37:59.776198 30839 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I0129 20:38:36.811360 30839 solver.cpp:218] Iteration 25800 (2.7001 iter/s, 37.0357s/100 iters), loss = 3.29497
I0129 20:38:36.811695 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.29497 (* 1 = 3.29497 loss)
I0129 20:38:36.811738 30839 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I0129 20:39:14.732430 30839 solver.cpp:218] Iteration 25900 (2.63705 iter/s, 37.9212s/100 iters), loss = 3.17768
I0129 20:39:14.732707 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.17768 (* 1 = 3.17768 loss)
I0129 20:39:14.732745 30839 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I0129 20:39:51.763350 30839 solver.cpp:218] Iteration 26000 (2.70044 iter/s, 37.031s/100 iters), loss = 3.4485
I0129 20:39:51.763559 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.4485 (* 1 = 3.4485 loss)
I0129 20:39:51.763586 30839 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I0129 20:40:28.751855 30839 solver.cpp:218] Iteration 26100 (2.70353 iter/s, 36.9887s/100 iters), loss = 3.32127
I0129 20:40:28.757410 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.32127 (* 1 = 3.32127 loss)
I0129 20:40:28.757426 30839 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I0129 20:41:05.708781 30839 solver.cpp:218] Iteration 26200 (2.70623 iter/s, 36.9517s/100 iters), loss = 2.93773
I0129 20:41:05.709044 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.93773 (* 1 = 2.93773 loss)
I0129 20:41:05.709079 30839 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I0129 20:41:42.686277 30839 solver.cpp:218] Iteration 26300 (2.70434 iter/s, 36.9776s/100 iters), loss = 3.82964
I0129 20:41:42.691692 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.82964 (* 1 = 3.82964 loss)
I0129 20:41:42.691709 30839 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I0129 20:42:19.676375 30839 solver.cpp:218] Iteration 26400 (2.7038 iter/s, 36.985s/100 iters), loss = 3.51913
I0129 20:42:19.681813 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.51913 (* 1 = 3.51913 loss)
I0129 20:42:19.681826 30839 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I0129 20:42:56.767374 30839 solver.cpp:218] Iteration 26500 (2.69645 iter/s, 37.0859s/100 iters), loss = 3.04684
I0129 20:42:56.772779 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.04684 (* 1 = 3.04684 loss)
I0129 20:42:56.772797 30839 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I0129 20:43:33.847864 30839 solver.cpp:218] Iteration 26600 (2.69721 iter/s, 37.0754s/100 iters), loss = 3.43676
I0129 20:43:33.848067 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.43676 (* 1 = 3.43676 loss)
I0129 20:43:33.848081 30839 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I0129 20:44:10.811722 30839 solver.cpp:218] Iteration 26700 (2.70534 iter/s, 36.9639s/100 iters), loss = 3.25165
I0129 20:44:10.817224 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.25165 (* 1 = 3.25165 loss)
I0129 20:44:10.817265 30839 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I0129 20:44:47.976240 30839 solver.cpp:218] Iteration 26800 (2.69111 iter/s, 37.1593s/100 iters), loss = 3.8276
I0129 20:44:47.981678 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.8276 (* 1 = 3.8276 loss)
I0129 20:44:47.981696 30839 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I0129 20:45:25.052678 30839 solver.cpp:218] Iteration 26900 (2.69751 iter/s, 37.0713s/100 iters), loss = 3.18356
I0129 20:45:25.052893 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.18356 (* 1 = 3.18356 loss)
I0129 20:45:25.052912 30839 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I0129 20:46:01.973522 30839 solver.cpp:218] Iteration 27000 (2.7085 iter/s, 36.9209s/100 iters), loss = 3.21133
I0129 20:46:01.978971 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.21133 (* 1 = 3.21133 loss)
I0129 20:46:01.978996 30839 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I0129 20:46:39.036310 30839 solver.cpp:218] Iteration 27100 (2.6985 iter/s, 37.0576s/100 iters), loss = 3.27987
I0129 20:46:39.041697 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.27987 (* 1 = 3.27987 loss)
I0129 20:46:39.041723 30839 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I0129 20:47:16.051786 30839 solver.cpp:218] Iteration 27200 (2.70195 iter/s, 37.0103s/100 iters), loss = 3.34813
I0129 20:47:16.057224 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.34813 (* 1 = 3.34813 loss)
I0129 20:47:16.057250 30839 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I0129 20:47:53.177920 30839 solver.cpp:218] Iteration 27300 (2.6939 iter/s, 37.1209s/100 iters), loss = 3.59809
I0129 20:47:53.178131 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.59809 (* 1 = 3.59809 loss)
I0129 20:47:53.178151 30839 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I0129 20:48:30.273164 30839 solver.cpp:218] Iteration 27400 (2.69577 iter/s, 37.0952s/100 iters), loss = 3.28206
I0129 20:48:30.278605 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.28206 (* 1 = 3.28206 loss)
I0129 20:48:30.278641 30839 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I0129 20:49:07.425837 30839 solver.cpp:218] Iteration 27500 (2.69198 iter/s, 37.1474s/100 iters), loss = 3.35155
I0129 20:49:07.431305 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.35155 (* 1 = 3.35155 loss)
I0129 20:49:07.431329 30839 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I0129 20:49:44.489094 30839 solver.cpp:218] Iteration 27600 (2.69847 iter/s, 37.058s/100 iters), loss = 3.89538
I0129 20:49:44.494556 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.89538 (* 1 = 3.89538 loss)
I0129 20:49:44.494604 30839 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I0129 20:50:21.444787 30839 solver.cpp:218] Iteration 27700 (2.70633 iter/s, 36.9505s/100 iters), loss = 3.27363
I0129 20:50:21.450268 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.27363 (* 1 = 3.27363 loss)
I0129 20:50:21.450306 30839 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I0129 20:50:58.513670 30839 solver.cpp:218] Iteration 27800 (2.69806 iter/s, 37.0636s/100 iters), loss = 3.33198
I0129 20:50:58.519165 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33198 (* 1 = 3.33198 loss)
I0129 20:50:58.519183 30839 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I0129 20:51:35.564788 30839 solver.cpp:218] Iteration 27900 (2.69936 iter/s, 37.0458s/100 iters), loss = 3.53907
I0129 20:51:35.570214 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.53907 (* 1 = 3.53907 loss)
I0129 20:51:35.570231 30839 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I0129 20:52:12.622069 30839 solver.cpp:218] Iteration 28000 (2.69891 iter/s, 37.052s/100 iters), loss = 3.55533
I0129 20:52:12.627549 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55533 (* 1 = 3.55533 loss)
I0129 20:52:12.627601 30839 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I0129 20:52:49.757899 30839 solver.cpp:218] Iteration 28100 (2.6932 iter/s, 37.1305s/100 iters), loss = 3.20306
I0129 20:52:49.758118 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.20306 (* 1 = 3.20306 loss)
I0129 20:52:49.758141 30839 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I0129 20:53:26.807713 30839 solver.cpp:218] Iteration 28200 (2.69907 iter/s, 37.0498s/100 iters), loss = 3.72615
I0129 20:53:26.813132 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.72615 (* 1 = 3.72615 loss)
I0129 20:53:26.813145 30839 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I0129 20:54:03.757344 30839 solver.cpp:218] Iteration 28300 (2.70677 iter/s, 36.9444s/100 iters), loss = 3.68378
I0129 20:54:03.762846 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.68378 (* 1 = 3.68378 loss)
I0129 20:54:03.762884 30839 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I0129 20:54:40.848562 30839 solver.cpp:218] Iteration 28400 (2.69644 iter/s, 37.0859s/100 iters), loss = 3.32522
I0129 20:54:40.848801 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.32522 (* 1 = 3.32522 loss)
I0129 20:54:40.848834 30839 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I0129 20:55:17.941828 30839 solver.cpp:218] Iteration 28500 (2.69591 iter/s, 37.0932s/100 iters), loss = 3.23125
I0129 20:55:17.942102 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.23125 (* 1 = 3.23125 loss)
I0129 20:55:17.942122 30839 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I0129 20:55:55.080013 30839 solver.cpp:218] Iteration 28600 (2.69266 iter/s, 37.1381s/100 iters), loss = 3.68434
I0129 20:55:55.085470 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.68434 (* 1 = 3.68434 loss)
I0129 20:55:55.085491 30839 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I0129 20:56:32.108992 30839 solver.cpp:218] Iteration 28700 (2.70098 iter/s, 37.0237s/100 iters), loss = 4.01077
I0129 20:56:32.109290 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.01077 (* 1 = 4.01077 loss)
I0129 20:56:32.109340 30839 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I0129 20:57:09.265800 30839 solver.cpp:218] Iteration 28800 (2.69131 iter/s, 37.1567s/100 iters), loss = 3.70862
I0129 20:57:09.271256 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.70862 (* 1 = 3.70862 loss)
I0129 20:57:09.271286 30839 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I0129 20:57:46.256952 30839 solver.cpp:218] Iteration 28900 (2.70374 iter/s, 36.9858s/100 iters), loss = 3.04412
I0129 20:57:46.262375 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.04412 (* 1 = 3.04412 loss)
I0129 20:57:46.262389 30839 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I0129 20:58:23.317623 30839 solver.cpp:218] Iteration 29000 (2.69866 iter/s, 37.0554s/100 iters), loss = 3.77119
I0129 20:58:23.323043 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.77119 (* 1 = 3.77119 loss)
I0129 20:58:23.323062 30839 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I0129 20:59:00.561012 30839 solver.cpp:218] Iteration 29100 (2.68542 iter/s, 37.2381s/100 iters), loss = 3.49223
I0129 20:59:00.566586 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.49223 (* 1 = 3.49223 loss)
I0129 20:59:00.566607 30839 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I0129 20:59:37.669034 30839 solver.cpp:218] Iteration 29200 (2.69523 iter/s, 37.1026s/100 iters), loss = 3.72408
I0129 20:59:37.669356 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.72408 (* 1 = 3.72408 loss)
I0129 20:59:37.669384 30839 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I0129 21:00:14.627908 30839 solver.cpp:218] Iteration 29300 (2.70572 iter/s, 36.9587s/100 iters), loss = 3.5708
I0129 21:00:14.633332 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.5708 (* 1 = 3.5708 loss)
I0129 21:00:14.633352 30839 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I0129 21:00:51.828579 30839 solver.cpp:218] Iteration 29400 (2.68851 iter/s, 37.1954s/100 iters), loss = 3.26334
I0129 21:00:51.834067 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.26334 (* 1 = 3.26334 loss)
I0129 21:00:51.834107 30839 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I0129 21:01:29.523490 30839 solver.cpp:218] Iteration 29500 (2.65325 iter/s, 37.6896s/100 iters), loss = 3.26382
I0129 21:01:29.524658 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.26382 (* 1 = 3.26382 loss)
I0129 21:01:29.524701 30839 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I0129 21:02:07.050580 30839 solver.cpp:218] Iteration 29600 (2.66481 iter/s, 37.5261s/100 iters), loss = 3.3048
I0129 21:02:07.050830 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.3048 (* 1 = 3.3048 loss)
I0129 21:02:07.050848 30839 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I0129 21:02:44.543709 30839 solver.cpp:218] Iteration 29700 (2.66717 iter/s, 37.493s/100 iters), loss = 3.67738
I0129 21:02:44.544036 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.67738 (* 1 = 3.67738 loss)
I0129 21:02:44.544075 30839 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I0129 21:03:21.854331 30839 solver.cpp:218] Iteration 29800 (2.68022 iter/s, 37.3104s/100 iters), loss = 3.57477
I0129 21:03:21.854540 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.57477 (* 1 = 3.57477 loss)
I0129 21:03:21.854560 30839 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I0129 21:03:58.750818 30839 solver.cpp:218] Iteration 29900 (2.71029 iter/s, 36.8964s/100 iters), loss = 3.86024
I0129 21:03:58.756284 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.86024 (* 1 = 3.86024 loss)
I0129 21:03:58.756317 30839 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I0129 21:04:35.130939 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_30000.caffemodel
I0129 21:04:35.840761 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_30000.solverstate
I0129 21:04:36.421087 30839 solver.cpp:218] Iteration 30000 (2.65499 iter/s, 37.6649s/100 iters), loss = 3.64965
I0129 21:04:36.421156 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.64965 (* 1 = 3.64965 loss)
I0129 21:04:36.421169 30839 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I0129 21:05:13.323819 30839 solver.cpp:218] Iteration 30100 (2.70983 iter/s, 36.9027s/100 iters), loss = 4.15192
I0129 21:05:13.324024 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.15192 (* 1 = 4.15192 loss)
I0129 21:05:13.324044 30839 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I0129 21:05:50.412681 30839 solver.cpp:218] Iteration 30200 (2.69624 iter/s, 37.0888s/100 iters), loss = 3.57417
I0129 21:05:50.418079 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.57417 (* 1 = 3.57417 loss)
I0129 21:05:50.418092 30839 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I0129 21:06:27.306285 30839 solver.cpp:218] Iteration 30300 (2.71089 iter/s, 36.8883s/100 iters), loss = 3.70563
I0129 21:06:27.311704 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.70563 (* 1 = 3.70563 loss)
I0129 21:06:27.311718 30839 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I0129 21:07:04.445801 30839 solver.cpp:218] Iteration 30400 (2.69294 iter/s, 37.1342s/100 iters), loss = 2.8194
I0129 21:07:04.451292 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.8194 (* 1 = 2.8194 loss)
I0129 21:07:04.451333 30839 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I0129 21:07:42.161324 30839 solver.cpp:218] Iteration 30500 (2.6518 iter/s, 37.7102s/100 iters), loss = 3.37326
I0129 21:07:42.161654 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.37326 (* 1 = 3.37326 loss)
I0129 21:07:42.161689 30839 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I0129 21:08:19.292109 30839 solver.cpp:218] Iteration 30600 (2.6932 iter/s, 37.1305s/100 iters), loss = 3.49383
I0129 21:08:19.297567 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.49383 (* 1 = 3.49383 loss)
I0129 21:08:19.297583 30839 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I0129 21:08:56.350653 30839 solver.cpp:218] Iteration 30700 (2.69882 iter/s, 37.0532s/100 iters), loss = 3.51801
I0129 21:08:56.350934 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.51801 (* 1 = 3.51801 loss)
I0129 21:08:56.350963 30839 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I0129 21:09:33.479807 30839 solver.cpp:218] Iteration 30800 (2.69331 iter/s, 37.129s/100 iters), loss = 2.83467
I0129 21:09:33.485260 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.83467 (* 1 = 2.83467 loss)
I0129 21:09:33.485296 30839 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I0129 21:10:10.599901 30839 solver.cpp:218] Iteration 30900 (2.69435 iter/s, 37.1147s/100 iters), loss = 3.46966
I0129 21:10:10.600149 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.46966 (* 1 = 3.46966 loss)
I0129 21:10:10.600173 30839 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I0129 21:10:47.839534 30839 solver.cpp:218] Iteration 31000 (2.68532 iter/s, 37.2395s/100 iters), loss = 3.30279
I0129 21:10:47.845012 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.30279 (* 1 = 3.30279 loss)
I0129 21:10:47.845067 30839 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I0129 21:11:24.871449 30839 solver.cpp:218] Iteration 31100 (2.70076 iter/s, 37.0265s/100 iters), loss = 3.95761
I0129 21:11:24.871804 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.95761 (* 1 = 3.95761 loss)
I0129 21:11:24.871840 30839 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I0129 21:12:02.029372 30839 solver.cpp:218] Iteration 31200 (2.69123 iter/s, 37.1577s/100 iters), loss = 3.33663
I0129 21:12:02.034876 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33663 (* 1 = 3.33663 loss)
I0129 21:12:02.034906 30839 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I0129 21:12:39.111603 30839 solver.cpp:218] Iteration 31300 (2.6971 iter/s, 37.0768s/100 iters), loss = 2.86533
I0129 21:12:39.117131 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.86533 (* 1 = 2.86533 loss)
I0129 21:12:39.117146 30839 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I0129 21:13:16.192301 30839 solver.cpp:218] Iteration 31400 (2.69722 iter/s, 37.0753s/100 iters), loss = 2.8853
I0129 21:13:16.197742 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.8853 (* 1 = 2.8853 loss)
I0129 21:13:16.197765 30839 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I0129 21:13:53.308878 30839 solver.cpp:218] Iteration 31500 (2.6946 iter/s, 37.1112s/100 iters), loss = 3.85249
I0129 21:13:53.314286 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.85249 (* 1 = 3.85249 loss)
I0129 21:13:53.314301 30839 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I0129 21:14:30.366827 30839 solver.cpp:218] Iteration 31600 (2.69886 iter/s, 37.0526s/100 iters), loss = 3.51052
I0129 21:14:30.372262 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.51052 (* 1 = 3.51052 loss)
I0129 21:14:30.372289 30839 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I0129 21:15:07.394109 30839 solver.cpp:218] Iteration 31700 (2.7011 iter/s, 37.0219s/100 iters), loss = 3.20249
I0129 21:15:07.399669 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.20249 (* 1 = 3.20249 loss)
I0129 21:15:07.399699 30839 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I0129 21:15:44.439260 30839 solver.cpp:218] Iteration 31800 (2.69981 iter/s, 37.0397s/100 iters), loss = 2.60564
I0129 21:15:44.444742 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.60564 (* 1 = 2.60564 loss)
I0129 21:15:44.444766 30839 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I0129 21:16:21.456825 30839 solver.cpp:218] Iteration 31900 (2.70181 iter/s, 37.0122s/100 iters), loss = 3.23941
I0129 21:16:21.462424 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.23941 (* 1 = 3.23941 loss)
I0129 21:16:21.462460 30839 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I0129 21:16:58.551679 30839 solver.cpp:218] Iteration 32000 (2.69619 iter/s, 37.0894s/100 iters), loss = 3.03824
I0129 21:16:58.551954 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.03824 (* 1 = 3.03824 loss)
I0129 21:16:58.551987 30839 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I0129 21:17:35.663249 30839 solver.cpp:218] Iteration 32100 (2.69459 iter/s, 37.1114s/100 iters), loss = 2.70103
I0129 21:17:35.663511 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.70103 (* 1 = 2.70103 loss)
I0129 21:17:35.663547 30839 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I0129 21:18:12.719918 30839 solver.cpp:218] Iteration 32200 (2.69858 iter/s, 37.0565s/100 iters), loss = 3.14958
I0129 21:18:12.727654 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.14958 (* 1 = 3.14958 loss)
I0129 21:18:12.727674 30839 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I0129 21:18:49.806725 30839 solver.cpp:218] Iteration 32300 (2.69693 iter/s, 37.0792s/100 iters), loss = 2.81543
I0129 21:18:49.812178 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.81543 (* 1 = 2.81543 loss)
I0129 21:18:49.812216 30839 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I0129 21:19:26.862143 30839 solver.cpp:218] Iteration 32400 (2.69905 iter/s, 37.0501s/100 iters), loss = 3.36657
I0129 21:19:26.867571 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.36657 (* 1 = 3.36657 loss)
I0129 21:19:26.867588 30839 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I0129 21:20:03.881577 30839 solver.cpp:218] Iteration 32500 (2.70167 iter/s, 37.0141s/100 iters), loss = 3.60448
I0129 21:20:03.887631 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.60448 (* 1 = 3.60448 loss)
I0129 21:20:03.887670 30839 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I0129 21:20:40.957476 30839 solver.cpp:218] Iteration 32600 (2.6976 iter/s, 37.07s/100 iters), loss = 3.21482
I0129 21:20:40.962913 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.21482 (* 1 = 3.21482 loss)
I0129 21:20:40.962926 30839 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I0129 21:21:18.004194 30839 solver.cpp:218] Iteration 32700 (2.69968 iter/s, 37.0414s/100 iters), loss = 3.61738
I0129 21:21:18.009675 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.61738 (* 1 = 3.61738 loss)
I0129 21:21:18.009713 30839 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I0129 21:21:55.016322 30839 solver.cpp:218] Iteration 32800 (2.70221 iter/s, 37.0067s/100 iters), loss = 3.17309
I0129 21:21:55.021700 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.17309 (* 1 = 3.17309 loss)
I0129 21:21:55.021723 30839 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I0129 21:22:32.101191 30839 solver.cpp:218] Iteration 32900 (2.6969 iter/s, 37.0796s/100 iters), loss = 3.34006
I0129 21:22:32.106700 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.34006 (* 1 = 3.34006 loss)
I0129 21:22:32.106719 30839 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I0129 21:23:09.076916 30839 solver.cpp:218] Iteration 33000 (2.70487 iter/s, 36.9703s/100 iters), loss = 2.97232
I0129 21:23:09.077157 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.97232 (* 1 = 2.97232 loss)
I0129 21:23:09.077193 30839 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I0129 21:23:46.047706 30839 solver.cpp:218] Iteration 33100 (2.70485 iter/s, 36.9707s/100 iters), loss = 2.98329
I0129 21:23:46.053289 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.98329 (* 1 = 2.98329 loss)
I0129 21:23:46.053308 30839 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I0129 21:24:23.075788 30839 solver.cpp:218] Iteration 33200 (2.70105 iter/s, 37.0226s/100 iters), loss = 3.42209
I0129 21:24:23.076038 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.42209 (* 1 = 3.42209 loss)
I0129 21:24:23.076074 30839 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I0129 21:24:59.987447 30839 solver.cpp:218] Iteration 33300 (2.70918 iter/s, 36.9115s/100 iters), loss = 3.49547
I0129 21:24:59.987726 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.49547 (* 1 = 3.49547 loss)
I0129 21:24:59.987759 30839 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I0129 21:25:36.982416 30839 solver.cpp:218] Iteration 33400 (2.70308 iter/s, 36.9948s/100 iters), loss = 2.58884
I0129 21:25:36.987854 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.58884 (* 1 = 2.58884 loss)
I0129 21:25:36.987869 30839 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I0129 21:26:13.855756 30839 solver.cpp:218] Iteration 33500 (2.71238 iter/s, 36.868s/100 iters), loss = 2.98083
I0129 21:26:13.855962 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.98083 (* 1 = 2.98083 loss)
I0129 21:26:13.855981 30839 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I0129 21:26:50.728626 30839 solver.cpp:218] Iteration 33600 (2.71203 iter/s, 36.8728s/100 iters), loss = 3.25158
I0129 21:26:50.733767 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.25158 (* 1 = 3.25158 loss)
I0129 21:26:50.733789 30839 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I0129 21:27:27.723204 30839 solver.cpp:218] Iteration 33700 (2.70347 iter/s, 36.9895s/100 iters), loss = 2.71894
I0129 21:27:27.728688 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.71894 (* 1 = 2.71894 loss)
I0129 21:27:27.728727 30839 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I0129 21:28:04.698644 30839 solver.cpp:218] Iteration 33800 (2.70489 iter/s, 36.9701s/100 iters), loss = 3.52403
I0129 21:28:04.698863 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.52403 (* 1 = 3.52403 loss)
I0129 21:28:04.698895 30839 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I0129 21:28:41.701529 30839 solver.cpp:218] Iteration 33900 (2.70251 iter/s, 37.0027s/100 iters), loss = 2.93966
I0129 21:28:41.706544 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.93966 (* 1 = 2.93966 loss)
I0129 21:28:41.706586 30839 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I0129 21:29:18.662667 30839 solver.cpp:218] Iteration 34000 (2.7059 iter/s, 36.9562s/100 iters), loss = 3.55926
I0129 21:29:18.668126 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.55926 (* 1 = 3.55926 loss)
I0129 21:29:18.668162 30839 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I0129 21:29:55.626819 30839 solver.cpp:218] Iteration 34100 (2.70572 iter/s, 36.9588s/100 iters), loss = 2.76574
I0129 21:29:55.627070 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.76574 (* 1 = 2.76574 loss)
I0129 21:29:55.627100 30839 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I0129 21:30:32.552829 30839 solver.cpp:218] Iteration 34200 (2.70813 iter/s, 36.9258s/100 iters), loss = 3.21617
I0129 21:30:32.558205 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.21617 (* 1 = 3.21617 loss)
I0129 21:30:32.558224 30839 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I0129 21:31:09.597175 30839 solver.cpp:218] Iteration 34300 (2.69985 iter/s, 37.0391s/100 iters), loss = 3.52911
I0129 21:31:09.597491 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.52911 (* 1 = 3.52911 loss)
I0129 21:31:09.597525 30839 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I0129 21:31:46.722620 30839 solver.cpp:218] Iteration 34400 (2.69359 iter/s, 37.1252s/100 iters), loss = 2.88312
I0129 21:31:46.722879 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.88312 (* 1 = 2.88312 loss)
I0129 21:31:46.722913 30839 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I0129 21:32:23.701812 30839 solver.cpp:218] Iteration 34500 (2.70423 iter/s, 36.979s/100 iters), loss = 3.58845
I0129 21:32:23.707291 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.58845 (* 1 = 3.58845 loss)
I0129 21:32:23.707336 30839 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I0129 21:33:00.746775 30839 solver.cpp:218] Iteration 34600 (2.69981 iter/s, 37.0396s/100 iters), loss = 3.98823
I0129 21:33:00.752248 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.98823 (* 1 = 3.98823 loss)
I0129 21:33:00.752288 30839 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I0129 21:33:37.847415 30839 solver.cpp:218] Iteration 34700 (2.69576 iter/s, 37.0953s/100 iters), loss = 3.33522
I0129 21:33:37.852808 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.33522 (* 1 = 3.33522 loss)
I0129 21:33:37.852833 30839 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I0129 21:34:14.856446 30839 solver.cpp:218] Iteration 34800 (2.70243 iter/s, 37.0037s/100 iters), loss = 3.17515
I0129 21:34:14.862429 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.17515 (* 1 = 3.17515 loss)
I0129 21:34:14.862468 30839 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I0129 21:34:51.808812 30839 solver.cpp:218] Iteration 34900 (2.70662 iter/s, 36.9465s/100 iters), loss = 3.28875
I0129 21:34:51.814182 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.28875 (* 1 = 3.28875 loss)
I0129 21:34:51.814203 30839 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I0129 21:35:28.172577 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_35000.caffemodel
I0129 21:35:29.012090 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_35000.solverstate
I0129 21:35:29.596707 30839 solver.cpp:218] Iteration 35000 (2.64672 iter/s, 37.7826s/100 iters), loss = 3.19125
I0129 21:35:29.596791 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.19125 (* 1 = 3.19125 loss)
I0129 21:35:29.596806 30839 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I0129 21:36:06.575973 30839 solver.cpp:218] Iteration 35100 (2.70422 iter/s, 36.9793s/100 iters), loss = 3.162
I0129 21:36:06.581481 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.162 (* 1 = 3.162 loss)
I0129 21:36:06.581528 30839 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I0129 21:36:43.719231 30839 solver.cpp:218] Iteration 35200 (2.69267 iter/s, 37.1379s/100 iters), loss = 3.50574
I0129 21:36:43.724651 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.50574 (* 1 = 3.50574 loss)
I0129 21:36:43.724678 30839 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I0129 21:37:20.676318 30839 solver.cpp:218] Iteration 35300 (2.70623 iter/s, 36.9518s/100 iters), loss = 2.74651
I0129 21:37:20.681799 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.74651 (* 1 = 2.74651 loss)
I0129 21:37:20.681838 30839 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I0129 21:37:57.821378 30839 solver.cpp:218] Iteration 35400 (2.69254 iter/s, 37.1397s/100 iters), loss = 4.01433
I0129 21:37:57.826745 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.01433 (* 1 = 4.01433 loss)
I0129 21:37:57.826763 30839 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I0129 21:38:34.805990 30839 solver.cpp:218] Iteration 35500 (2.70421 iter/s, 36.9793s/100 iters), loss = 3.27494
I0129 21:38:34.811342 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.27494 (* 1 = 3.27494 loss)
I0129 21:38:34.811362 30839 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I0129 21:39:11.802477 30839 solver.cpp:218] Iteration 35600 (2.70334 iter/s, 36.9912s/100 iters), loss = 3.856
I0129 21:39:11.807948 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.856 (* 1 = 3.856 loss)
I0129 21:39:11.807992 30839 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I0129 21:39:48.887197 30839 solver.cpp:218] Iteration 35700 (2.69692 iter/s, 37.0794s/100 iters), loss = 2.24827
I0129 21:39:48.892590 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.24827 (* 1 = 2.24827 loss)
I0129 21:39:48.892616 30839 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I0129 21:40:25.862521 30839 solver.cpp:218] Iteration 35800 (2.70489 iter/s, 36.97s/100 iters), loss = 3.78031
I0129 21:40:25.867884 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.78031 (* 1 = 3.78031 loss)
I0129 21:40:25.867905 30839 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I0129 21:41:03.046043 30839 solver.cpp:218] Iteration 35900 (2.68974 iter/s, 37.1782s/100 iters), loss = 2.95507
I0129 21:41:03.046248 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.95507 (* 1 = 2.95507 loss)
I0129 21:41:03.046272 30839 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I0129 21:41:40.059933 30839 solver.cpp:218] Iteration 36000 (2.7017 iter/s, 37.0137s/100 iters), loss = 2.95828
I0129 21:41:40.065304 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.95828 (* 1 = 2.95828 loss)
I0129 21:41:40.065320 30839 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I0129 21:42:17.099516 30839 solver.cpp:218] Iteration 36100 (2.7002 iter/s, 37.0343s/100 iters), loss = 3.24968
I0129 21:42:17.099793 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.24968 (* 1 = 3.24968 loss)
I0129 21:42:17.099824 30839 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I0129 21:42:54.171144 30839 solver.cpp:218] Iteration 36200 (2.69782 iter/s, 37.067s/100 iters), loss = 2.29146
I0129 21:42:54.176508 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.29146 (* 1 = 2.29146 loss)
I0129 21:42:54.176542 30839 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I0129 21:43:31.294615 30839 solver.cpp:218] Iteration 36300 (2.6944 iter/s, 37.114s/100 iters), loss = 3.00499
I0129 21:43:31.299937 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.00499 (* 1 = 3.00499 loss)
I0129 21:43:31.299959 30839 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I0129 21:44:08.305985 30839 solver.cpp:218] Iteration 36400 (2.70254 iter/s, 37.0022s/100 iters), loss = 2.82459
I0129 21:44:08.311466 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.82459 (* 1 = 2.82459 loss)
I0129 21:44:08.311507 30839 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I0129 21:44:45.387886 30839 solver.cpp:218] Iteration 36500 (2.69739 iter/s, 37.0728s/100 iters), loss = 2.70041
I0129 21:44:45.388141 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.70041 (* 1 = 2.70041 loss)
I0129 21:44:45.388162 30839 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I0129 21:45:22.373970 30839 solver.cpp:218] Iteration 36600 (2.70399 iter/s, 36.9824s/100 iters), loss = 3.27489
I0129 21:45:22.379432 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.27489 (* 1 = 3.27489 loss)
I0129 21:45:22.379470 30839 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I0129 21:45:59.314879 30839 solver.cpp:218] Iteration 36700 (2.70766 iter/s, 36.9322s/100 iters), loss = 3.24739
I0129 21:45:59.320235 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.24739 (* 1 = 3.24739 loss)
I0129 21:45:59.320255 30839 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I0129 21:46:36.480684 30839 solver.cpp:218] Iteration 36800 (2.69125 iter/s, 37.1574s/100 iters), loss = 2.8396
I0129 21:46:36.486078 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.8396 (* 1 = 2.8396 loss)
I0129 21:46:36.486114 30839 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I0129 21:47:13.531114 30839 solver.cpp:218] Iteration 36900 (2.69962 iter/s, 37.0422s/100 iters), loss = 3.56379
I0129 21:47:13.537055 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.56379 (* 1 = 3.56379 loss)
I0129 21:47:13.537099 30839 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I0129 21:47:50.667233 30839 solver.cpp:218] Iteration 37000 (2.69342 iter/s, 37.1275s/100 iters), loss = 3.23491
I0129 21:47:50.672605 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.23491 (* 1 = 3.23491 loss)
I0129 21:47:50.672622 30839 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I0129 21:48:27.779418 30839 solver.cpp:218] Iteration 37100 (2.69511 iter/s, 37.1043s/100 iters), loss = 3.01903
I0129 21:48:27.784910 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.01903 (* 1 = 3.01903 loss)
I0129 21:48:27.784946 30839 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I0129 21:49:04.735730 30839 solver.cpp:218] Iteration 37200 (2.70647 iter/s, 36.9485s/100 iters), loss = 2.92738
I0129 21:49:04.735893 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.92738 (* 1 = 2.92738 loss)
I0129 21:49:04.735908 30839 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I0129 21:49:41.687224 30839 solver.cpp:218] Iteration 37300 (2.70643 iter/s, 36.9491s/100 iters), loss = 3.04188
I0129 21:49:41.687476 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.04188 (* 1 = 3.04188 loss)
I0129 21:49:41.687511 30839 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I0129 21:50:18.819010 30839 solver.cpp:218] Iteration 37400 (2.69328 iter/s, 37.1294s/100 iters), loss = 3.04985
I0129 21:50:18.824481 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.04985 (* 1 = 3.04985 loss)
I0129 21:50:18.824522 30839 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I0129 21:50:55.847107 30839 solver.cpp:218] Iteration 37500 (2.7012 iter/s, 37.0206s/100 iters), loss = 3.30744
I0129 21:50:55.852473 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.30744 (* 1 = 3.30744 loss)
I0129 21:50:55.852495 30839 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I0129 21:51:32.932910 30839 solver.cpp:218] Iteration 37600 (2.69698 iter/s, 37.0785s/100 iters), loss = 2.53815
I0129 21:51:32.938359 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.53815 (* 1 = 2.53815 loss)
I0129 21:51:32.938387 30839 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I0129 21:52:09.965631 30839 solver.cpp:218] Iteration 37700 (2.70084 iter/s, 37.0255s/100 iters), loss = 3.28799
I0129 21:52:09.971081 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.28799 (* 1 = 3.28799 loss)
I0129 21:52:09.971109 30839 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I0129 21:52:46.863975 30839 solver.cpp:218] Iteration 37800 (2.71068 iter/s, 36.8912s/100 iters), loss = 3.26063
I0129 21:52:46.869364 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.26063 (* 1 = 3.26063 loss)
I0129 21:52:46.869393 30839 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I0129 21:53:23.714570 30839 solver.cpp:218] Iteration 37900 (2.71418 iter/s, 36.8435s/100 iters), loss = 4.04939
I0129 21:53:23.719940 30839 solver.cpp:237]     Train net output #0: softmax_loss = 4.04939 (* 1 = 4.04939 loss)
I0129 21:53:23.719982 30839 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I0129 21:54:00.510998 30839 solver.cpp:218] Iteration 38000 (2.71817 iter/s, 36.7895s/100 iters), loss = 3.14023
I0129 21:54:00.511220 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.14023 (* 1 = 3.14023 loss)
I0129 21:54:00.511253 30839 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I0129 21:54:37.442863 30839 solver.cpp:218] Iteration 38100 (2.70781 iter/s, 36.9301s/100 iters), loss = 3.19313
I0129 21:54:37.448221 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.19313 (* 1 = 3.19313 loss)
I0129 21:54:37.448242 30839 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I0129 21:54:37.580569 30839 blocking_queue.cpp:49] Waiting for data
I0129 21:55:14.485954 30839 solver.cpp:218] Iteration 38200 (2.70005 iter/s, 37.0363s/100 iters), loss = 3.43129
I0129 21:55:14.491888 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.43129 (* 1 = 3.43129 loss)
I0129 21:55:14.491907 30839 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I0129 21:55:51.640925 30839 solver.cpp:218] Iteration 38300 (2.69196 iter/s, 37.1477s/100 iters), loss = 3.12239
I0129 21:55:51.646312 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.12239 (* 1 = 3.12239 loss)
I0129 21:55:51.646335 30839 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I0129 21:56:28.475823 30839 solver.cpp:218] Iteration 38400 (2.71531 iter/s, 36.8282s/100 iters), loss = 3.46042
I0129 21:56:28.481196 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.46042 (* 1 = 3.46042 loss)
I0129 21:56:28.481220 30839 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I0129 21:57:05.596639 30839 solver.cpp:218] Iteration 38500 (2.69439 iter/s, 37.1142s/100 iters), loss = 2.55846
I0129 21:57:05.596810 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.55846 (* 1 = 2.55846 loss)
I0129 21:57:05.596828 30839 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I0129 21:57:42.679813 30839 solver.cpp:218] Iteration 38600 (2.69675 iter/s, 37.0817s/100 iters), loss = 3.57977
I0129 21:57:42.680105 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.57977 (* 1 = 3.57977 loss)
I0129 21:57:42.680140 30839 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I0129 21:58:19.712373 30839 solver.cpp:218] Iteration 38700 (2.70043 iter/s, 37.0311s/100 iters), loss = 3.04365
I0129 21:58:19.717761 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.04365 (* 1 = 3.04365 loss)
I0129 21:58:19.717787 30839 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I0129 21:58:57.593986 30839 solver.cpp:218] Iteration 38800 (2.64026 iter/s, 37.8751s/100 iters), loss = 2.7161
I0129 21:58:57.594200 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.7161 (* 1 = 2.7161 loss)
I0129 21:58:57.594228 30839 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I0129 21:59:34.561830 30839 solver.cpp:218] Iteration 38900 (2.70515 iter/s, 36.9665s/100 iters), loss = 3.16598
I0129 21:59:34.567284 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.16598 (* 1 = 3.16598 loss)
I0129 21:59:34.567333 30839 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I0129 22:00:11.625742 30839 solver.cpp:218] Iteration 39000 (2.69851 iter/s, 37.0575s/100 iters), loss = 3.50092
I0129 22:00:11.631227 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.50092 (* 1 = 3.50092 loss)
I0129 22:00:11.631270 30839 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I0129 22:00:48.627813 30839 solver.cpp:218] Iteration 39100 (2.70302 iter/s, 36.9956s/100 iters), loss = 3.41723
I0129 22:00:48.633270 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.41723 (* 1 = 3.41723 loss)
I0129 22:00:48.633325 30839 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I0129 22:01:25.709172 30839 solver.cpp:218] Iteration 39200 (2.69724 iter/s, 37.0749s/100 iters), loss = 2.87616
I0129 22:01:25.714476 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.87616 (* 1 = 2.87616 loss)
I0129 22:01:25.714495 30839 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I0129 22:02:02.809588 30839 solver.cpp:218] Iteration 39300 (2.69584 iter/s, 37.0942s/100 iters), loss = 2.80475
I0129 22:02:02.814945 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.80475 (* 1 = 2.80475 loss)
I0129 22:02:02.814965 30839 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I0129 22:02:39.873216 30839 solver.cpp:218] Iteration 39400 (2.69852 iter/s, 37.0574s/100 iters), loss = 3.19172
I0129 22:02:39.873446 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.19172 (* 1 = 3.19172 loss)
I0129 22:02:39.873478 30839 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I0129 22:03:17.006573 30839 solver.cpp:218] Iteration 39500 (2.69308 iter/s, 37.1322s/100 iters), loss = 3.17266
I0129 22:03:17.011999 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.17266 (* 1 = 3.17266 loss)
I0129 22:03:17.012033 30839 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I0129 22:03:53.895548 30839 solver.cpp:218] Iteration 39600 (2.7113 iter/s, 36.8827s/100 iters), loss = 3.96726
I0129 22:03:53.901034 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.96726 (* 1 = 3.96726 loss)
I0129 22:03:53.901079 30839 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I0129 22:04:30.949403 30839 solver.cpp:218] Iteration 39700 (2.69923 iter/s, 37.0476s/100 iters), loss = 3.09493
I0129 22:04:30.954864 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.09493 (* 1 = 3.09493 loss)
I0129 22:04:30.954910 30839 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I0129 22:05:08.016515 30839 solver.cpp:218] Iteration 39800 (2.69826 iter/s, 37.0609s/100 iters), loss = 3.23912
I0129 22:05:08.021970 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.23912 (* 1 = 3.23912 loss)
I0129 22:05:08.022029 30839 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I0129 22:05:45.069180 30839 solver.cpp:218] Iteration 39900 (2.69932 iter/s, 37.0464s/100 iters), loss = 3.53136
I0129 22:05:45.069437 30839 solver.cpp:237]     Train net output #0: softmax_loss = 3.53136 (* 1 = 3.53136 loss)
I0129 22:05:45.069475 30839 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I0129 22:06:21.690687 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_40000.caffemodel
I0129 22:06:22.346119 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_40000.solverstate
I0129 22:06:22.928720 30839 solver.cpp:218] Iteration 40000 (2.64141 iter/s, 37.8585s/100 iters), loss = 2.71738
I0129 22:06:22.928794 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.71738 (* 1 = 2.71738 loss)
I0129 22:06:22.928805 30839 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I0129 22:06:22.928812 30839 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0129 22:06:59.769346 30839 solver.cpp:218] Iteration 40100 (2.71446 iter/s, 36.8398s/100 iters), loss = 2.10899
I0129 22:06:59.774708 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.10899 (* 1 = 2.10899 loss)
I0129 22:06:59.774724 30839 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I0129 22:07:36.782073 30839 solver.cpp:218] Iteration 40200 (2.70222 iter/s, 37.0066s/100 iters), loss = 2.01811
I0129 22:07:36.782295 30839 solver.cpp:237]     Train net output #0: softmax_loss = 2.01811 (* 1 = 2.01811 loss)
I0129 22:07:36.782320 30839 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I0129 22:08:13.813760 30839 solver.cpp:218] Iteration 40300 (2.70046 iter/s, 37.0307s/100 iters), loss = 1.73545
I0129 22:08:13.819224 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.73545 (* 1 = 1.73545 loss)
I0129 22:08:13.819262 30839 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I0129 22:08:50.930225 30839 solver.cpp:218] Iteration 40400 (2.69467 iter/s, 37.1103s/100 iters), loss = 1.78704
I0129 22:08:50.935703 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.78704 (* 1 = 1.78704 loss)
I0129 22:08:50.935753 30839 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I0129 22:09:28.091435 30839 solver.cpp:218] Iteration 40500 (2.69142 iter/s, 37.155s/100 iters), loss = 1.60824
I0129 22:09:28.091768 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.60824 (* 1 = 1.60824 loss)
I0129 22:09:28.091805 30839 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I0129 22:10:05.179503 30839 solver.cpp:218] Iteration 40600 (2.69636 iter/s, 37.087s/100 iters), loss = 1.59642
I0129 22:10:05.184908 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.59642 (* 1 = 1.59642 loss)
I0129 22:10:05.184933 30839 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I0129 22:10:42.236292 30839 solver.cpp:218] Iteration 40700 (2.699 iter/s, 37.0507s/100 iters), loss = 1.18922
I0129 22:10:42.241783 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.18922 (* 1 = 1.18922 loss)
I0129 22:10:42.241822 30839 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I0129 22:11:19.345293 30839 solver.cpp:218] Iteration 40800 (2.69531 iter/s, 37.1015s/100 iters), loss = 1.4098
I0129 22:11:19.345587 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.4098 (* 1 = 1.4098 loss)
I0129 22:11:19.345620 30839 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I0129 22:11:56.614410 30839 solver.cpp:218] Iteration 40900 (2.68325 iter/s, 37.2682s/100 iters), loss = 1.03816
I0129 22:11:56.614603 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.03816 (* 1 = 1.03816 loss)
I0129 22:11:56.614619 30839 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I0129 22:12:33.610957 30839 solver.cpp:218] Iteration 41000 (2.70302 iter/s, 36.9957s/100 iters), loss = 1.12714
I0129 22:12:33.611196 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.12714 (* 1 = 1.12714 loss)
I0129 22:12:33.611222 30839 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I0129 22:13:10.635299 30839 solver.cpp:218] Iteration 41100 (2.70099 iter/s, 37.0235s/100 iters), loss = 1.38794
I0129 22:13:10.641002 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.38794 (* 1 = 1.38794 loss)
I0129 22:13:10.641044 30839 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I0129 22:13:47.582437 30839 solver.cpp:218] Iteration 41200 (2.70703 iter/s, 36.9408s/100 iters), loss = 1.47398
I0129 22:13:47.587870 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.47398 (* 1 = 1.47398 loss)
I0129 22:13:47.587896 30839 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I0129 22:14:24.598256 30839 solver.cpp:218] Iteration 41300 (2.70199 iter/s, 37.0098s/100 iters), loss = 1.37221
I0129 22:14:24.598475 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.37221 (* 1 = 1.37221 loss)
I0129 22:14:24.598500 30839 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I0129 22:15:01.820463 30839 solver.cpp:218] Iteration 41400 (2.68663 iter/s, 37.2214s/100 iters), loss = 1.26765
I0129 22:15:01.820746 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.26765 (* 1 = 1.26765 loss)
I0129 22:15:01.820778 30839 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I0129 22:15:38.820314 30839 solver.cpp:218] Iteration 41500 (2.70278 iter/s, 36.999s/100 iters), loss = 0.991918
I0129 22:15:38.825738 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.991918 (* 1 = 0.991918 loss)
I0129 22:15:38.825762 30839 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I0129 22:16:15.939126 30839 solver.cpp:218] Iteration 41600 (2.69449 iter/s, 37.1128s/100 iters), loss = 0.999263
I0129 22:16:15.944617 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.999263 (* 1 = 0.999263 loss)
I0129 22:16:15.944658 30839 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I0129 22:16:52.982157 30839 solver.cpp:218] Iteration 41700 (2.69991 iter/s, 37.0382s/100 iters), loss = 1.43289
I0129 22:16:52.982439 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.43289 (* 1 = 1.43289 loss)
I0129 22:16:52.982471 30839 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I0129 22:17:30.075811 30839 solver.cpp:218] Iteration 41800 (2.69583 iter/s, 37.0943s/100 iters), loss = 0.900704
I0129 22:17:30.076109 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.900704 (* 1 = 0.900704 loss)
I0129 22:17:30.076143 30839 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I0129 22:18:07.241971 30839 solver.cpp:218] Iteration 41900 (2.69058 iter/s, 37.1667s/100 iters), loss = 1.02097
I0129 22:18:07.242267 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.02097 (* 1 = 1.02097 loss)
I0129 22:18:07.242308 30839 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I0129 22:18:44.316509 30839 solver.cpp:218] Iteration 42000 (2.69723 iter/s, 37.075s/100 iters), loss = 1.01982
I0129 22:18:44.316714 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.01982 (* 1 = 1.01982 loss)
I0129 22:18:44.316740 30839 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I0129 22:19:21.362839 30839 solver.cpp:218] Iteration 42100 (2.69929 iter/s, 37.0468s/100 iters), loss = 0.974518
I0129 22:19:21.368224 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.974518 (* 1 = 0.974518 loss)
I0129 22:19:21.368254 30839 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I0129 22:19:58.375370 30839 solver.cpp:218] Iteration 42200 (2.70213 iter/s, 37.0078s/100 iters), loss = 1.13829
I0129 22:19:58.380843 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.13829 (* 1 = 1.13829 loss)
I0129 22:19:58.380882 30839 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I0129 22:20:35.544564 30839 solver.cpp:218] Iteration 42300 (2.69076 iter/s, 37.1642s/100 iters), loss = 1.09803
I0129 22:20:35.544865 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.09803 (* 1 = 1.09803 loss)
I0129 22:20:35.544894 30839 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I0129 22:21:12.563666 30839 solver.cpp:218] Iteration 42400 (2.70129 iter/s, 37.0193s/100 iters), loss = 0.933236
I0129 22:21:12.569166 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.933236 (* 1 = 0.933236 loss)
I0129 22:21:12.569206 30839 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I0129 22:21:49.692508 30839 solver.cpp:218] Iteration 42500 (2.69369 iter/s, 37.1238s/100 iters), loss = 0.978001
I0129 22:21:49.692761 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.978001 (* 1 = 0.978001 loss)
I0129 22:21:49.692792 30839 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I0129 22:22:26.673683 30839 solver.cpp:218] Iteration 42600 (2.70407 iter/s, 36.9813s/100 iters), loss = 1.32191
I0129 22:22:26.679162 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.32191 (* 1 = 1.32191 loss)
I0129 22:22:26.679200 30839 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I0129 22:23:03.706600 30839 solver.cpp:218] Iteration 42700 (2.70068 iter/s, 37.0278s/100 iters), loss = 0.725366
I0129 22:23:03.706799 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.725366 (* 1 = 0.725366 loss)
I0129 22:23:03.706827 30839 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I0129 22:23:40.636451 30839 solver.cpp:218] Iteration 42800 (2.70783 iter/s, 36.9299s/100 iters), loss = 0.851867
I0129 22:23:40.641763 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.851867 (* 1 = 0.851867 loss)
I0129 22:23:40.641783 30839 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I0129 22:24:17.738133 30839 solver.cpp:218] Iteration 42900 (2.69566 iter/s, 37.0966s/100 iters), loss = 0.939632
I0129 22:24:17.744138 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.939632 (* 1 = 0.939632 loss)
I0129 22:24:17.744179 30839 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I0129 22:24:54.918613 30839 solver.cpp:218] Iteration 43000 (2.69001 iter/s, 37.1747s/100 iters), loss = 1.07149
I0129 22:24:54.924041 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.07149 (* 1 = 1.07149 loss)
I0129 22:24:54.924083 30839 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I0129 22:25:32.053500 30839 solver.cpp:218] Iteration 43100 (2.69326 iter/s, 37.1297s/100 iters), loss = 1.00877
I0129 22:25:32.053771 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.00877 (* 1 = 1.00877 loss)
I0129 22:25:32.053807 30839 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I0129 22:26:08.943262 30839 solver.cpp:218] Iteration 43200 (2.71079 iter/s, 36.8896s/100 iters), loss = 0.828075
I0129 22:26:08.948621 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.828075 (* 1 = 0.828075 loss)
I0129 22:26:08.948644 30839 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I0129 22:26:45.914489 30839 solver.cpp:218] Iteration 43300 (2.70519 iter/s, 36.9659s/100 iters), loss = 0.876193
I0129 22:26:45.919800 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.876193 (* 1 = 0.876193 loss)
I0129 22:26:45.919822 30839 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I0129 22:27:22.992486 30839 solver.cpp:218] Iteration 43400 (2.6974 iter/s, 37.0728s/100 iters), loss = 0.931969
I0129 22:27:22.997961 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.931969 (* 1 = 0.931969 loss)
I0129 22:27:22.997997 30839 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I0129 22:28:00.121032 30839 solver.cpp:218] Iteration 43500 (2.69374 iter/s, 37.1231s/100 iters), loss = 1.01777
I0129 22:28:00.126418 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.01777 (* 1 = 1.01777 loss)
I0129 22:28:00.126457 30839 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I0129 22:28:37.182942 30839 solver.cpp:218] Iteration 43600 (2.69858 iter/s, 37.0565s/100 iters), loss = 0.9605
I0129 22:28:37.183207 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.9605 (* 1 = 0.9605 loss)
I0129 22:28:37.183246 30839 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I0129 22:29:14.354316 30839 solver.cpp:218] Iteration 43700 (2.69026 iter/s, 37.1711s/100 iters), loss = 0.980233
I0129 22:29:14.354559 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.980233 (* 1 = 0.980233 loss)
I0129 22:29:14.354590 30839 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I0129 22:29:51.450299 30839 solver.cpp:218] Iteration 43800 (2.69573 iter/s, 37.0957s/100 iters), loss = 0.716435
I0129 22:29:51.450445 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.716435 (* 1 = 0.716435 loss)
I0129 22:29:51.450461 30839 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I0129 22:30:28.447904 30839 solver.cpp:218] Iteration 43900 (2.70289 iter/s, 36.9974s/100 iters), loss = 1.02202
I0129 22:30:28.448169 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.02202 (* 1 = 1.02202 loss)
I0129 22:30:28.448199 30839 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I0129 22:31:05.408892 30839 solver.cpp:218] Iteration 44000 (2.70558 iter/s, 36.9607s/100 iters), loss = 0.827371
I0129 22:31:05.414283 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.827371 (* 1 = 0.827371 loss)
I0129 22:31:05.414309 30839 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I0129 22:31:42.338194 30839 solver.cpp:218] Iteration 44100 (2.70828 iter/s, 36.9238s/100 iters), loss = 0.618464
I0129 22:31:42.345268 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.618464 (* 1 = 0.618464 loss)
I0129 22:31:42.345297 30839 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I0129 22:32:19.498083 30839 solver.cpp:218] Iteration 44200 (2.69159 iter/s, 37.1527s/100 iters), loss = 0.847149
I0129 22:32:19.498291 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.847149 (* 1 = 0.847149 loss)
I0129 22:32:19.498322 30839 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I0129 22:32:56.593313 30839 solver.cpp:218] Iteration 44300 (2.69579 iter/s, 37.0949s/100 iters), loss = 1.05491
I0129 22:32:56.593583 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.05491 (* 1 = 1.05491 loss)
I0129 22:32:56.593619 30839 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I0129 22:33:33.480832 30839 solver.cpp:218] Iteration 44400 (2.71097 iter/s, 36.8871s/100 iters), loss = 0.947512
I0129 22:33:33.486196 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.947512 (* 1 = 0.947512 loss)
I0129 22:33:33.486217 30839 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I0129 22:34:10.476125 30839 solver.cpp:218] Iteration 44500 (2.70345 iter/s, 36.9898s/100 iters), loss = 1.13196
I0129 22:34:10.476454 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.13196 (* 1 = 1.13196 loss)
I0129 22:34:10.476483 30839 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I0129 22:34:47.532475 30839 solver.cpp:218] Iteration 44600 (2.69863 iter/s, 37.0559s/100 iters), loss = 0.633887
I0129 22:34:47.537860 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.633887 (* 1 = 0.633887 loss)
I0129 22:34:47.537886 30839 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I0129 22:35:24.616552 30839 solver.cpp:218] Iteration 44700 (2.69698 iter/s, 37.0785s/100 iters), loss = 1.0194
I0129 22:35:24.622053 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.0194 (* 1 = 1.0194 loss)
I0129 22:35:24.622093 30839 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I0129 22:36:01.680224 30839 solver.cpp:218] Iteration 44800 (2.69847 iter/s, 37.058s/100 iters), loss = 1.01798
I0129 22:36:01.685662 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.01798 (* 1 = 1.01798 loss)
I0129 22:36:01.685685 30839 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I0129 22:36:38.658646 30839 solver.cpp:218] Iteration 44900 (2.70469 iter/s, 36.9728s/100 iters), loss = 0.775074
I0129 22:36:38.664067 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.775074 (* 1 = 0.775074 loss)
I0129 22:36:38.664108 30839 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I0129 22:37:15.247200 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_45000.caffemodel
I0129 22:37:15.928609 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_45000.solverstate
I0129 22:37:16.518798 30839 solver.cpp:218] Iteration 45000 (2.64169 iter/s, 37.8545s/100 iters), loss = 1.28801
I0129 22:37:16.518875 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.28801 (* 1 = 1.28801 loss)
I0129 22:37:16.518894 30839 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I0129 22:37:53.637929 30839 solver.cpp:218] Iteration 45100 (2.69405 iter/s, 37.1188s/100 iters), loss = 0.888581
I0129 22:37:53.643360 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.888581 (* 1 = 0.888581 loss)
I0129 22:37:53.643378 30839 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I0129 22:38:30.707074 30839 solver.cpp:218] Iteration 45200 (2.69807 iter/s, 37.0635s/100 iters), loss = 0.774573
I0129 22:38:30.712466 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.774573 (* 1 = 0.774573 loss)
I0129 22:38:30.712494 30839 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I0129 22:39:07.800067 30839 solver.cpp:218] Iteration 45300 (2.69634 iter/s, 37.0873s/100 iters), loss = 0.686968
I0129 22:39:07.800349 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.686968 (* 1 = 0.686968 loss)
I0129 22:39:07.800371 30839 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I0129 22:39:44.932005 30839 solver.cpp:218] Iteration 45400 (2.69314 iter/s, 37.1314s/100 iters), loss = 1.06178
I0129 22:39:44.932219 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.06178 (* 1 = 1.06178 loss)
I0129 22:39:44.932240 30839 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I0129 22:40:22.033447 30839 solver.cpp:218] Iteration 45500 (2.69535 iter/s, 37.1009s/100 iters), loss = 0.712888
I0129 22:40:22.033804 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.712888 (* 1 = 0.712888 loss)
I0129 22:40:22.033846 30839 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I0129 22:40:59.275812 30839 solver.cpp:218] Iteration 45600 (2.68516 iter/s, 37.2418s/100 iters), loss = 1.01088
I0129 22:40:59.281198 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.01088 (* 1 = 1.01088 loss)
I0129 22:40:59.281220 30839 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I0129 22:41:36.277514 30839 solver.cpp:218] Iteration 45700 (2.70299 iter/s, 36.9961s/100 iters), loss = 1.02638
I0129 22:41:36.277793 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.02638 (* 1 = 1.02638 loss)
I0129 22:41:36.277822 30839 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I0129 22:42:13.268963 30839 solver.cpp:218] Iteration 45800 (2.70337 iter/s, 36.9909s/100 iters), loss = 1.05155
I0129 22:42:13.274325 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.05155 (* 1 = 1.05155 loss)
I0129 22:42:13.274353 30839 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I0129 22:42:50.390060 30839 solver.cpp:218] Iteration 45900 (2.6943 iter/s, 37.1155s/100 iters), loss = 0.674835
I0129 22:42:50.395536 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.674835 (* 1 = 0.674835 loss)
I0129 22:42:50.395576 30839 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I0129 22:43:27.390486 30839 solver.cpp:218] Iteration 46000 (2.70309 iter/s, 36.9947s/100 iters), loss = 0.84768
I0129 22:43:27.395838 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.84768 (* 1 = 0.84768 loss)
I0129 22:43:27.395851 30839 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I0129 22:44:04.537367 30839 solver.cpp:218] Iteration 46100 (2.69243 iter/s, 37.1412s/100 iters), loss = 0.713455
I0129 22:44:04.542846 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.713455 (* 1 = 0.713455 loss)
I0129 22:44:04.542886 30839 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I0129 22:44:41.551928 30839 solver.cpp:218] Iteration 46200 (2.70206 iter/s, 37.0088s/100 iters), loss = 0.801365
I0129 22:44:41.552129 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.801365 (* 1 = 0.801365 loss)
I0129 22:44:41.552146 30839 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I0129 22:45:18.701061 30839 solver.cpp:218] Iteration 46300 (2.69189 iter/s, 37.1486s/100 iters), loss = 0.793686
I0129 22:45:18.706543 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.793686 (* 1 = 0.793686 loss)
I0129 22:45:18.706583 30839 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I0129 22:45:55.733319 30839 solver.cpp:218] Iteration 46400 (2.70077 iter/s, 37.0265s/100 iters), loss = 0.827617
I0129 22:45:55.738814 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.827617 (* 1 = 0.827617 loss)
I0129 22:45:55.738863 30839 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I0129 22:46:32.684315 30839 solver.cpp:218] Iteration 46500 (2.70671 iter/s, 36.9452s/100 iters), loss = 0.699389
I0129 22:46:32.689677 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.699389 (* 1 = 0.699389 loss)
I0129 22:46:32.689699 30839 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I0129 22:47:09.771234 30839 solver.cpp:218] Iteration 46600 (2.69678 iter/s, 37.0812s/100 iters), loss = 0.418559
I0129 22:47:09.771484 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.418559 (* 1 = 0.418559 loss)
I0129 22:47:09.771515 30839 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I0129 22:47:46.913198 30839 solver.cpp:218] Iteration 46700 (2.69241 iter/s, 37.1414s/100 iters), loss = 0.962169
I0129 22:47:46.918653 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.962169 (* 1 = 0.962169 loss)
I0129 22:47:46.918689 30839 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I0129 22:48:23.879923 30839 solver.cpp:218] Iteration 46800 (2.70556 iter/s, 36.961s/100 iters), loss = 1.22863
I0129 22:48:23.880219 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.22863 (* 1 = 1.22863 loss)
I0129 22:48:23.880245 30839 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I0129 22:49:00.900499 30839 solver.cpp:218] Iteration 46900 (2.70125 iter/s, 37.0199s/100 iters), loss = 0.812436
I0129 22:49:00.900672 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.812436 (* 1 = 0.812436 loss)
I0129 22:49:00.900689 30839 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I0129 22:49:37.882231 30839 solver.cpp:218] Iteration 47000 (2.70408 iter/s, 36.9812s/100 iters), loss = 0.850253
I0129 22:49:37.887548 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.850253 (* 1 = 0.850253 loss)
I0129 22:49:37.887568 30839 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I0129 22:50:14.893096 30839 solver.cpp:218] Iteration 47100 (2.70232 iter/s, 37.0052s/100 iters), loss = 0.668126
I0129 22:50:14.898519 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.668126 (* 1 = 0.668126 loss)
I0129 22:50:14.898548 30839 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I0129 22:50:51.950433 30839 solver.cpp:218] Iteration 47200 (2.69891 iter/s, 37.052s/100 iters), loss = 0.89817
I0129 22:50:51.950796 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.89817 (* 1 = 0.89817 loss)
I0129 22:50:51.950826 30839 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I0129 22:51:29.057919 30839 solver.cpp:218] Iteration 47300 (2.69485 iter/s, 37.1078s/100 iters), loss = 0.723732
I0129 22:51:29.058172 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.723732 (* 1 = 0.723732 loss)
I0129 22:51:29.058202 30839 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I0129 22:52:06.221359 30839 solver.cpp:218] Iteration 47400 (2.69079 iter/s, 37.1638s/100 iters), loss = 0.768722
I0129 22:52:06.226837 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.768722 (* 1 = 0.768722 loss)
I0129 22:52:06.226878 30839 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I0129 22:52:43.189041 30839 solver.cpp:218] Iteration 47500 (2.70543 iter/s, 36.9628s/100 iters), loss = 0.812336
I0129 22:52:43.194407 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.812336 (* 1 = 0.812336 loss)
I0129 22:52:43.194430 30839 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I0129 22:53:20.269142 30839 solver.cpp:218] Iteration 47600 (2.69722 iter/s, 37.0752s/100 iters), loss = 0.923241
I0129 22:53:20.275173 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.923241 (* 1 = 0.923241 loss)
I0129 22:53:20.275213 30839 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I0129 22:53:57.356461 30839 solver.cpp:218] Iteration 47700 (2.69675 iter/s, 37.0817s/100 iters), loss = 0.554245
I0129 22:53:57.356735 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.554245 (* 1 = 0.554245 loss)
I0129 22:53:57.356767 30839 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I0129 22:54:34.436724 30839 solver.cpp:218] Iteration 47800 (2.69684 iter/s, 37.0804s/100 iters), loss = 1.06771
I0129 22:54:34.442235 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.06771 (* 1 = 1.06771 loss)
I0129 22:54:34.442279 30839 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I0129 22:55:11.539285 30839 solver.cpp:218] Iteration 47900 (2.6956 iter/s, 37.0975s/100 iters), loss = 0.575632
I0129 22:55:11.545315 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.575632 (* 1 = 0.575632 loss)
I0129 22:55:11.545356 30839 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I0129 22:55:48.687913 30839 solver.cpp:218] Iteration 48000 (2.6923 iter/s, 37.1429s/100 iters), loss = 0.739321
I0129 22:55:48.693380 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.739321 (* 1 = 0.739321 loss)
I0129 22:55:48.693416 30839 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I0129 22:56:25.619509 30839 solver.cpp:218] Iteration 48100 (2.70809 iter/s, 36.9264s/100 iters), loss = 0.695565
I0129 22:56:25.624882 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.695565 (* 1 = 0.695565 loss)
I0129 22:56:25.624908 30839 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I0129 22:57:02.542372 30839 solver.cpp:218] Iteration 48200 (2.70872 iter/s, 36.9177s/100 iters), loss = 0.788262
I0129 22:57:02.542629 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.788262 (* 1 = 0.788262 loss)
I0129 22:57:02.542660 30839 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I0129 22:57:39.510469 30839 solver.cpp:218] Iteration 48300 (2.70504 iter/s, 36.9681s/100 iters), loss = 0.672229
I0129 22:57:39.515954 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.672229 (* 1 = 0.672229 loss)
I0129 22:57:39.515991 30839 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I0129 22:58:16.451946 30839 solver.cpp:218] Iteration 48400 (2.70737 iter/s, 36.9362s/100 iters), loss = 0.53382
I0129 22:58:16.452160 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.53382 (* 1 = 0.53382 loss)
I0129 22:58:16.452188 30839 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I0129 22:58:53.321527 30839 solver.cpp:218] Iteration 48500 (2.71227 iter/s, 36.8695s/100 iters), loss = 0.660446
I0129 22:58:53.321812 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.660446 (* 1 = 0.660446 loss)
I0129 22:58:53.321836 30839 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I0129 22:59:30.279716 30839 solver.cpp:218] Iteration 48600 (2.70577 iter/s, 36.958s/100 iters), loss = 0.576086
I0129 22:59:30.285218 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.576086 (* 1 = 0.576086 loss)
I0129 22:59:30.285269 30839 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I0129 23:00:07.225924 30839 solver.cpp:218] Iteration 48700 (2.70703 iter/s, 36.9409s/100 iters), loss = 0.902213
I0129 23:00:07.226203 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.902213 (* 1 = 0.902213 loss)
I0129 23:00:07.226241 30839 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I0129 23:00:44.120621 30839 solver.cpp:218] Iteration 48800 (2.71043 iter/s, 36.8945s/100 iters), loss = 0.870947
I0129 23:00:44.126013 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.870947 (* 1 = 0.870947 loss)
I0129 23:00:44.126044 30839 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I0129 23:01:21.073652 30839 solver.cpp:218] Iteration 48900 (2.70653 iter/s, 36.9477s/100 iters), loss = 0.604797
I0129 23:01:21.078954 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.604797 (* 1 = 0.604797 loss)
I0129 23:01:21.078974 30839 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I0129 23:01:57.973366 30839 solver.cpp:218] Iteration 49000 (2.71043 iter/s, 36.8945s/100 iters), loss = 0.721474
I0129 23:01:57.978853 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.721474 (* 1 = 0.721474 loss)
I0129 23:01:57.978890 30839 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I0129 23:02:35.002523 30839 solver.cpp:218] Iteration 49100 (2.70097 iter/s, 37.0237s/100 iters), loss = 0.506078
I0129 23:02:35.007957 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.506078 (* 1 = 0.506078 loss)
I0129 23:02:35.007997 30839 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I0129 23:03:12.023360 30839 solver.cpp:218] Iteration 49200 (2.70157 iter/s, 37.0155s/100 iters), loss = 0.700474
I0129 23:03:12.028730 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.700474 (* 1 = 0.700474 loss)
I0129 23:03:12.028746 30839 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I0129 23:03:49.096757 30839 solver.cpp:218] Iteration 49300 (2.69775 iter/s, 37.068s/100 iters), loss = 0.78386
I0129 23:03:49.102147 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.78386 (* 1 = 0.78386 loss)
I0129 23:03:49.102169 30839 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I0129 23:04:26.074035 30839 solver.cpp:218] Iteration 49400 (2.70476 iter/s, 36.9719s/100 iters), loss = 0.871093
I0129 23:04:26.074257 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.871093 (* 1 = 0.871093 loss)
I0129 23:04:26.074285 30839 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I0129 23:05:03.035115 30839 solver.cpp:218] Iteration 49500 (2.70557 iter/s, 36.9608s/100 iters), loss = 0.796866
I0129 23:05:03.040560 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.796866 (* 1 = 0.796866 loss)
I0129 23:05:03.040587 30839 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I0129 23:05:40.136723 30839 solver.cpp:218] Iteration 49600 (2.6957 iter/s, 37.0961s/100 iters), loss = 0.814232
I0129 23:05:40.142232 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.814232 (* 1 = 0.814232 loss)
I0129 23:05:40.142277 30839 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I0129 23:06:17.068528 30839 solver.cpp:218] Iteration 49700 (2.7081 iter/s, 36.9263s/100 iters), loss = 0.921707
I0129 23:06:17.073889 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.921707 (* 1 = 0.921707 loss)
I0129 23:06:17.073904 30839 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I0129 23:06:54.020885 30839 solver.cpp:218] Iteration 49800 (2.70658 iter/s, 36.9469s/100 iters), loss = 0.647232
I0129 23:06:54.026340 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.647232 (* 1 = 0.647232 loss)
I0129 23:06:54.026365 30839 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I0129 23:07:31.063993 30839 solver.cpp:218] Iteration 49900 (2.69996 iter/s, 37.0376s/100 iters), loss = 0.690122
I0129 23:07:31.069360 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.690122 (* 1 = 0.690122 loss)
I0129 23:07:31.069380 30839 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I0129 23:08:07.693442 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_50000.caffemodel
I0129 23:08:08.383049 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_50000.solverstate
I0129 23:08:08.959714 30839 solver.cpp:218] Iteration 50000 (2.6392 iter/s, 37.8903s/100 iters), loss = 0.81044
I0129 23:08:08.959774 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.81044 (* 1 = 0.81044 loss)
I0129 23:08:08.959785 30839 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I0129 23:08:45.802060 30839 solver.cpp:218] Iteration 50100 (2.71428 iter/s, 36.8422s/100 iters), loss = 0.880894
I0129 23:08:45.807427 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.880894 (* 1 = 0.880894 loss)
I0129 23:08:45.807454 30839 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I0129 23:09:22.863734 30839 solver.cpp:218] Iteration 50200 (2.6986 iter/s, 37.0562s/100 iters), loss = 0.822198
I0129 23:09:22.869233 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.822198 (* 1 = 0.822198 loss)
I0129 23:09:22.869276 30839 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I0129 23:09:59.969350 30839 solver.cpp:218] Iteration 50300 (2.69542 iter/s, 37.1s/100 iters), loss = 0.982778
I0129 23:09:59.969650 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.982778 (* 1 = 0.982778 loss)
I0129 23:09:59.969681 30839 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I0129 23:10:37.111970 30839 solver.cpp:218] Iteration 50400 (2.69235 iter/s, 37.1422s/100 iters), loss = 1.04991
I0129 23:10:37.117456 30839 solver.cpp:237]     Train net output #0: softmax_loss = 1.04991 (* 1 = 1.04991 loss)
I0129 23:10:37.117506 30839 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I0129 23:11:14.151093 30839 solver.cpp:218] Iteration 50500 (2.70025 iter/s, 37.0336s/100 iters), loss = 0.770806
I0129 23:11:14.156599 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.770806 (* 1 = 0.770806 loss)
I0129 23:11:14.156638 30839 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I0129 23:11:51.095700 30839 solver.cpp:218] Iteration 50600 (2.70717 iter/s, 36.939s/100 iters), loss = 0.83993
I0129 23:11:51.101197 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.83993 (* 1 = 0.83993 loss)
I0129 23:11:51.101269 30839 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I0129 23:12:28.195091 30839 solver.cpp:218] Iteration 50700 (2.69587 iter/s, 37.0938s/100 iters), loss = 0.934864
I0129 23:12:28.200577 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.934864 (* 1 = 0.934864 loss)
I0129 23:12:28.200626 30839 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I0129 23:13:05.419773 30839 solver.cpp:218] Iteration 50800 (2.68679 iter/s, 37.2191s/100 iters), loss = 0.727274
I0129 23:13:05.425243 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.727274 (* 1 = 0.727274 loss)
I0129 23:13:05.425282 30839 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I0129 23:13:42.455231 30839 solver.cpp:218] Iteration 50900 (2.70052 iter/s, 37.0299s/100 iters), loss = 0.698378
I0129 23:13:42.460733 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.698378 (* 1 = 0.698378 loss)
I0129 23:13:42.460774 30839 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I0129 23:14:19.506237 30839 solver.cpp:218] Iteration 51000 (2.69939 iter/s, 37.0454s/100 iters), loss = 0.733343
I0129 23:14:19.511597 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.733343 (* 1 = 0.733343 loss)
I0129 23:14:19.511617 30839 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I0129 23:14:56.649363 30839 solver.cpp:218] Iteration 51100 (2.69269 iter/s, 37.1376s/100 iters), loss = 0.725107
I0129 23:14:56.654840 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.725107 (* 1 = 0.725107 loss)
I0129 23:14:56.654881 30839 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I0129 23:15:33.732538 30839 solver.cpp:218] Iteration 51200 (2.69705 iter/s, 37.0776s/100 iters), loss = 0.733791
I0129 23:15:33.738034 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.733791 (* 1 = 0.733791 loss)
I0129 23:15:33.738072 30839 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I0129 23:16:10.820952 30839 solver.cpp:218] Iteration 51300 (2.69667 iter/s, 37.0828s/100 iters), loss = 0.649867
I0129 23:16:10.821138 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.649867 (* 1 = 0.649867 loss)
I0129 23:16:10.821162 30839 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I0129 23:16:47.888116 30839 solver.cpp:218] Iteration 51400 (2.69783 iter/s, 37.0668s/100 iters), loss = 0.67487
I0129 23:16:47.893419 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.67487 (* 1 = 0.67487 loss)
I0129 23:16:47.893448 30839 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I0129 23:17:25.061149 30839 solver.cpp:218] Iteration 51500 (2.69052 iter/s, 37.1676s/100 iters), loss = 0.841794
I0129 23:17:25.066623 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.841794 (* 1 = 0.841794 loss)
I0129 23:17:25.066676 30839 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I0129 23:18:02.179468 30839 solver.cpp:218] Iteration 51600 (2.6945 iter/s, 37.1127s/100 iters), loss = 0.731861
I0129 23:18:02.184897 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.731861 (* 1 = 0.731861 loss)
I0129 23:18:02.184940 30839 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I0129 23:18:40.087755 30839 solver.cpp:218] Iteration 51700 (2.63833 iter/s, 37.9027s/100 iters), loss = 0.654547
I0129 23:18:40.093189 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.654547 (* 1 = 0.654547 loss)
I0129 23:18:40.093212 30839 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I0129 23:19:17.045964 30839 solver.cpp:218] Iteration 51800 (2.70617 iter/s, 36.9526s/100 iters), loss = 0.642363
I0129 23:19:17.046267 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.642363 (* 1 = 0.642363 loss)
I0129 23:19:17.046310 30839 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I0129 23:19:54.036885 30839 solver.cpp:218] Iteration 51900 (2.7034 iter/s, 36.9905s/100 iters), loss = 0.658999
I0129 23:19:54.042253 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.658999 (* 1 = 0.658999 loss)
I0129 23:19:54.042268 30839 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I0129 23:20:31.336997 30839 solver.cpp:218] Iteration 52000 (2.68135 iter/s, 37.2946s/100 iters), loss = 0.543055
I0129 23:20:31.343005 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.543055 (* 1 = 0.543055 loss)
I0129 23:20:31.343041 30839 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I0129 23:21:08.631439 30839 solver.cpp:218] Iteration 52100 (2.68181 iter/s, 37.2883s/100 iters), loss = 0.679598
I0129 23:21:08.636909 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.679598 (* 1 = 0.679598 loss)
I0129 23:21:08.636941 30839 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I0129 23:21:45.547264 30839 solver.cpp:218] Iteration 52200 (2.70928 iter/s, 36.9102s/100 iters), loss = 0.666414
I0129 23:21:45.552621 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.666414 (* 1 = 0.666414 loss)
I0129 23:21:45.552654 30839 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I0129 23:22:22.833485 30839 solver.cpp:218] Iteration 52300 (2.68235 iter/s, 37.2807s/100 iters), loss = 0.781666
I0129 23:22:22.833763 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.781666 (* 1 = 0.781666 loss)
I0129 23:22:22.833793 30839 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I0129 23:23:00.138566 30839 solver.cpp:218] Iteration 52400 (2.68064 iter/s, 37.3046s/100 iters), loss = 0.658728
I0129 23:23:00.138876 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.658728 (* 1 = 0.658728 loss)
I0129 23:23:00.138911 30839 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I0129 23:23:37.267515 30839 solver.cpp:218] Iteration 52500 (2.69335 iter/s, 37.1285s/100 iters), loss = 0.459883
I0129 23:23:37.273030 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.459883 (* 1 = 0.459883 loss)
I0129 23:23:37.273084 30839 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I0129 23:24:14.294315 30839 solver.cpp:218] Iteration 52600 (2.70116 iter/s, 37.0212s/100 iters), loss = 0.749219
I0129 23:24:14.294543 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.749219 (* 1 = 0.749219 loss)
I0129 23:24:14.294564 30839 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I0129 23:24:51.403347 30839 solver.cpp:218] Iteration 52700 (2.69475 iter/s, 37.1092s/100 iters), loss = 0.662278
I0129 23:24:51.408779 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.662278 (* 1 = 0.662278 loss)
I0129 23:24:51.408807 30839 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I0129 23:25:28.533411 30839 solver.cpp:218] Iteration 52800 (2.69348 iter/s, 37.1267s/100 iters), loss = 0.618885
I0129 23:25:28.538894 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.618885 (* 1 = 0.618885 loss)
I0129 23:25:28.538931 30839 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I0129 23:26:05.652320 30839 solver.cpp:218] Iteration 52900 (2.6943 iter/s, 37.1154s/100 iters), loss = 0.689019
I0129 23:26:05.657780 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.689019 (* 1 = 0.689019 loss)
I0129 23:26:05.657819 30839 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I0129 23:26:42.791345 30839 solver.cpp:218] Iteration 53000 (2.69285 iter/s, 37.1354s/100 iters), loss = 0.695665
I0129 23:26:42.791626 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.695665 (* 1 = 0.695665 loss)
I0129 23:26:42.791656 30839 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I0129 23:27:19.864511 30839 solver.cpp:218] Iteration 53100 (2.69727 iter/s, 37.0746s/100 iters), loss = 0.560923
I0129 23:27:19.864688 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.560923 (* 1 = 0.560923 loss)
I0129 23:27:19.864703 30839 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I0129 23:27:56.855041 30839 solver.cpp:218] Iteration 53200 (2.7033 iter/s, 36.9919s/100 iters), loss = 0.777302
I0129 23:27:56.860348 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.777302 (* 1 = 0.777302 loss)
I0129 23:27:56.860370 30839 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I0129 23:28:33.818547 30839 solver.cpp:218] Iteration 53300 (2.70565 iter/s, 36.9597s/100 iters), loss = 0.596173
I0129 23:28:33.818750 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.596173 (* 1 = 0.596173 loss)
I0129 23:28:33.818769 30839 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I0129 23:29:10.660457 30839 solver.cpp:218] Iteration 53400 (2.71422 iter/s, 36.8431s/100 iters), loss = 0.816336
I0129 23:29:10.660758 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.816336 (* 1 = 0.816336 loss)
I0129 23:29:10.660821 30839 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I0129 23:29:47.412158 30839 solver.cpp:218] Iteration 53500 (2.72089 iter/s, 36.7526s/100 iters), loss = 0.594502
I0129 23:29:47.417593 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.594502 (* 1 = 0.594502 loss)
I0129 23:29:47.417632 30839 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I0129 23:30:24.344647 30839 solver.cpp:218] Iteration 53600 (2.70795 iter/s, 36.9283s/100 iters), loss = 0.679092
I0129 23:30:24.350085 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.679092 (* 1 = 0.679092 loss)
I0129 23:30:24.350112 30839 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I0129 23:31:01.196086 30839 solver.cpp:218] Iteration 53700 (2.71392 iter/s, 36.8471s/100 iters), loss = 0.649975
I0129 23:31:01.201563 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.649975 (* 1 = 0.649975 loss)
I0129 23:31:01.201617 30839 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I0129 23:31:38.194670 30839 solver.cpp:218] Iteration 53800 (2.70313 iter/s, 36.9942s/100 iters), loss = 0.528626
I0129 23:31:38.194932 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.528626 (* 1 = 0.528626 loss)
I0129 23:31:38.194950 30839 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I0129 23:32:15.216912 30839 solver.cpp:218] Iteration 53900 (2.70103 iter/s, 37.023s/100 iters), loss = 0.743152
I0129 23:32:15.222381 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.743152 (* 1 = 0.743152 loss)
I0129 23:32:15.222416 30839 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I0129 23:32:52.345901 30839 solver.cpp:218] Iteration 54000 (2.69364 iter/s, 37.1245s/100 iters), loss = 0.72797
I0129 23:32:52.351367 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.72797 (* 1 = 0.72797 loss)
I0129 23:32:52.351409 30839 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I0129 23:33:29.330405 30839 solver.cpp:218] Iteration 54100 (2.70417 iter/s, 36.9799s/100 iters), loss = 0.670529
I0129 23:33:29.330696 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.670529 (* 1 = 0.670529 loss)
I0129 23:33:29.330731 30839 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I0129 23:34:06.267119 30839 solver.cpp:218] Iteration 54200 (2.70729 iter/s, 36.9372s/100 iters), loss = 0.620828
I0129 23:34:06.272604 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.620828 (* 1 = 0.620828 loss)
I0129 23:34:06.272644 30839 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I0129 23:34:43.274904 30839 solver.cpp:218] Iteration 54300 (2.70248 iter/s, 37.0031s/100 iters), loss = 0.567056
I0129 23:34:43.280274 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.567056 (* 1 = 0.567056 loss)
I0129 23:34:43.280295 30839 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I0129 23:35:20.366111 30839 solver.cpp:218] Iteration 54400 (2.6964 iter/s, 37.0865s/100 iters), loss = 0.602913
I0129 23:35:20.371436 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.602913 (* 1 = 0.602913 loss)
I0129 23:35:20.371457 30839 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I0129 23:35:57.440896 30839 solver.cpp:218] Iteration 54500 (2.69759 iter/s, 37.0701s/100 iters), loss = 0.388951
I0129 23:35:57.441195 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.388951 (* 1 = 0.388951 loss)
I0129 23:35:57.441222 30839 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I0129 23:36:34.429848 30839 solver.cpp:218] Iteration 54600 (2.70349 iter/s, 36.9893s/100 iters), loss = 0.676059
I0129 23:36:34.435246 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.676059 (* 1 = 0.676059 loss)
I0129 23:36:34.435269 30839 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I0129 23:37:11.516815 30839 solver.cpp:218] Iteration 54700 (2.69671 iter/s, 37.0822s/100 iters), loss = 0.656808
I0129 23:37:11.517088 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.656808 (* 1 = 0.656808 loss)
I0129 23:37:11.517119 30839 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I0129 23:37:48.566395 30839 solver.cpp:218] Iteration 54800 (2.69907 iter/s, 37.0498s/100 iters), loss = 0.54695
I0129 23:37:48.571797 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.54695 (* 1 = 0.54695 loss)
I0129 23:37:48.571842 30839 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I0129 23:38:25.482050 30839 solver.cpp:218] Iteration 54900 (2.70923 iter/s, 36.9108s/100 iters), loss = 0.705561
I0129 23:38:25.487576 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.705561 (* 1 = 0.705561 loss)
I0129 23:38:25.487594 30839 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I0129 23:39:02.017966 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_55000.caffemodel
I0129 23:39:02.688465 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_55000.solverstate
I0129 23:39:03.269886 30839 solver.cpp:218] Iteration 55000 (2.64671 iter/s, 37.7828s/100 iters), loss = 0.615844
I0129 23:39:03.269959 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.615844 (* 1 = 0.615844 loss)
I0129 23:39:03.269973 30839 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I0129 23:39:39.963670 30839 solver.cpp:218] Iteration 55100 (2.72523 iter/s, 36.6942s/100 iters), loss = 0.687698
I0129 23:39:39.969038 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.687698 (* 1 = 0.687698 loss)
I0129 23:39:39.969061 30839 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I0129 23:40:16.662915 30839 solver.cpp:218] Iteration 55200 (2.72523 iter/s, 36.6942s/100 iters), loss = 0.442198
I0129 23:40:16.668325 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.442198 (* 1 = 0.442198 loss)
I0129 23:40:16.668368 30839 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I0129 23:40:53.290132 30839 solver.cpp:218] Iteration 55300 (2.73058 iter/s, 36.6222s/100 iters), loss = 0.659126
I0129 23:40:53.290390 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.659126 (* 1 = 0.659126 loss)
I0129 23:40:53.290418 30839 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I0129 23:41:29.822715 30839 solver.cpp:218] Iteration 55400 (2.73728 iter/s, 36.5326s/100 iters), loss = 0.792112
I0129 23:41:29.828069 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.792112 (* 1 = 0.792112 loss)
I0129 23:41:29.828101 30839 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I0129 23:42:06.440397 30839 solver.cpp:218] Iteration 55500 (2.7313 iter/s, 36.6127s/100 iters), loss = 0.709362
I0129 23:42:06.445852 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.709361 (* 1 = 0.709361 loss)
I0129 23:42:06.445884 30839 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I0129 23:42:42.975018 30839 solver.cpp:218] Iteration 55600 (2.73751 iter/s, 36.5295s/100 iters), loss = 0.428254
I0129 23:42:42.980435 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.428254 (* 1 = 0.428254 loss)
I0129 23:42:42.980478 30839 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I0129 23:43:19.514575 30839 solver.cpp:218] Iteration 55700 (2.73715 iter/s, 36.5344s/100 iters), loss = 0.681753
I0129 23:43:19.519912 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.681753 (* 1 = 0.681753 loss)
I0129 23:43:19.519935 30839 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I0129 23:43:56.044466 30839 solver.cpp:218] Iteration 55800 (2.73786 iter/s, 36.5248s/100 iters), loss = 0.746394
I0129 23:43:56.049851 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.746394 (* 1 = 0.746394 loss)
I0129 23:43:56.049875 30839 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I0129 23:44:32.537684 30839 solver.cpp:218] Iteration 55900 (2.74062 iter/s, 36.4881s/100 iters), loss = 0.985027
I0129 23:44:32.543166 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.985027 (* 1 = 0.985027 loss)
I0129 23:44:32.543205 30839 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I0129 23:45:09.110733 30839 solver.cpp:218] Iteration 56000 (2.73464 iter/s, 36.5678s/100 iters), loss = 0.499566
I0129 23:45:09.116109 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.499566 (* 1 = 0.499566 loss)
I0129 23:45:09.116133 30839 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I0129 23:45:45.613075 30839 solver.cpp:218] Iteration 56100 (2.73994 iter/s, 36.4972s/100 iters), loss = 0.618355
I0129 23:45:45.618460 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.618355 (* 1 = 0.618355 loss)
I0129 23:45:45.618479 30839 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I0129 23:46:22.130901 30839 solver.cpp:218] Iteration 56200 (2.73878 iter/s, 36.5126s/100 iters), loss = 0.868133
I0129 23:46:22.131089 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.868133 (* 1 = 0.868133 loss)
I0129 23:46:22.131106 30839 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I0129 23:46:58.653753 30839 solver.cpp:218] Iteration 56300 (2.73801 iter/s, 36.5228s/100 iters), loss = 0.562278
I0129 23:46:58.654033 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.562278 (* 1 = 0.562278 loss)
I0129 23:46:58.654067 30839 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I0129 23:47:35.197851 30839 solver.cpp:218] Iteration 56400 (2.73643 iter/s, 36.544s/100 iters), loss = 0.759812
I0129 23:47:35.203217 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.759812 (* 1 = 0.759812 loss)
I0129 23:47:35.203236 30839 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I0129 23:48:11.662387 30839 solver.cpp:218] Iteration 56500 (2.74278 iter/s, 36.4593s/100 iters), loss = 0.495435
I0129 23:48:11.662669 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.495435 (* 1 = 0.495435 loss)
I0129 23:48:11.662698 30839 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I0129 23:48:48.185088 30839 solver.cpp:218] Iteration 56600 (2.73803 iter/s, 36.5226s/100 iters), loss = 0.581658
I0129 23:48:48.190455 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.581658 (* 1 = 0.581658 loss)
I0129 23:48:48.190474 30839 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I0129 23:49:24.757689 30839 solver.cpp:218] Iteration 56700 (2.73468 iter/s, 36.5674s/100 iters), loss = 0.738197
I0129 23:49:24.758690 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.738197 (* 1 = 0.738197 loss)
I0129 23:49:24.758718 30839 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I0129 23:50:01.263761 30839 solver.cpp:218] Iteration 56800 (2.73933 iter/s, 36.5052s/100 iters), loss = 0.565147
I0129 23:50:01.269215 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.565146 (* 1 = 0.565146 loss)
I0129 23:50:01.269243 30839 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I0129 23:50:37.832729 30839 solver.cpp:218] Iteration 56900 (2.73496 iter/s, 36.5636s/100 iters), loss = 0.719205
I0129 23:50:37.838109 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.719205 (* 1 = 0.719205 loss)
I0129 23:50:37.838130 30839 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I0129 23:51:14.329885 30839 solver.cpp:218] Iteration 57000 (2.74033 iter/s, 36.4919s/100 iters), loss = 0.591735
I0129 23:51:14.335273 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.591735 (* 1 = 0.591735 loss)
I0129 23:51:14.335294 30839 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I0129 23:51:50.751282 30839 solver.cpp:218] Iteration 57100 (2.74604 iter/s, 36.4161s/100 iters), loss = 0.638704
I0129 23:51:50.756729 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.638704 (* 1 = 0.638704 loss)
I0129 23:51:50.756758 30839 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I0129 23:52:27.205701 30839 solver.cpp:218] Iteration 57200 (2.74356 iter/s, 36.4491s/100 iters), loss = 0.729769
I0129 23:52:27.211061 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.729769 (* 1 = 0.729769 loss)
I0129 23:52:27.211083 30839 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I0129 23:53:03.660035 30839 solver.cpp:218] Iteration 57300 (2.74356 iter/s, 36.449s/100 iters), loss = 0.505051
I0129 23:53:03.665426 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.505051 (* 1 = 0.505051 loss)
I0129 23:53:03.665470 30839 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I0129 23:53:40.128674 30839 solver.cpp:218] Iteration 57400 (2.74248 iter/s, 36.4633s/100 iters), loss = 0.581741
I0129 23:53:40.134142 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.581741 (* 1 = 0.581741 loss)
I0129 23:53:40.134179 30839 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I0129 23:54:16.579672 30839 solver.cpp:218] Iteration 57500 (2.74381 iter/s, 36.4456s/100 iters), loss = 0.675659
I0129 23:54:16.585036 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.675659 (* 1 = 0.675659 loss)
I0129 23:54:16.585054 30839 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I0129 23:54:16.715303 30839 blocking_queue.cpp:49] Waiting for data
I0129 23:54:53.098672 30839 solver.cpp:218] Iteration 57600 (2.7387 iter/s, 36.5137s/100 iters), loss = 0.601533
I0129 23:54:53.104142 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.601533 (* 1 = 0.601533 loss)
I0129 23:54:53.104179 30839 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I0129 23:55:29.526787 30839 solver.cpp:218] Iteration 57700 (2.74554 iter/s, 36.4227s/100 iters), loss = 0.682764
I0129 23:55:29.532169 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.682764 (* 1 = 0.682764 loss)
I0129 23:55:29.532191 30839 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I0129 23:56:05.912761 30839 solver.cpp:218] Iteration 57800 (2.74872 iter/s, 36.3806s/100 iters), loss = 0.840522
I0129 23:56:05.912983 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.840522 (* 1 = 0.840522 loss)
I0129 23:56:05.913012 30839 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I0129 23:56:42.352545 30839 solver.cpp:218] Iteration 57900 (2.74427 iter/s, 36.4396s/100 iters), loss = 0.523871
I0129 23:56:42.357903 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.523871 (* 1 = 0.523871 loss)
I0129 23:56:42.357919 30839 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I0129 23:57:18.779989 30839 solver.cpp:218] Iteration 58000 (2.74558 iter/s, 36.4221s/100 iters), loss = 0.537065
I0129 23:57:18.785362 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.537065 (* 1 = 0.537065 loss)
I0129 23:57:18.785379 30839 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I0129 23:57:55.266926 30839 solver.cpp:218] Iteration 58100 (2.74111 iter/s, 36.4816s/100 iters), loss = 0.827213
I0129 23:57:55.272398 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.827213 (* 1 = 0.827213 loss)
I0129 23:57:55.272436 30839 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I0129 23:58:31.699466 30839 solver.cpp:218] Iteration 58200 (2.74521 iter/s, 36.4271s/100 iters), loss = 0.657461
I0129 23:58:31.699654 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.657461 (* 1 = 0.657461 loss)
I0129 23:58:31.699671 30839 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I0129 23:59:08.164957 30839 solver.cpp:218] Iteration 58300 (2.74245 iter/s, 36.4638s/100 iters), loss = 0.734219
I0129 23:59:08.165246 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.734219 (* 1 = 0.734219 loss)
I0129 23:59:08.165282 30839 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I0129 23:59:44.541934 30839 solver.cpp:218] Iteration 58400 (2.74924 iter/s, 36.3737s/100 iters), loss = 0.56149
I0129 23:59:44.547302 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.56149 (* 1 = 0.56149 loss)
I0129 23:59:44.547322 30839 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I0130 00:00:21.053740 30839 solver.cpp:218] Iteration 58500 (2.73946 iter/s, 36.5036s/100 iters), loss = 0.611036
I0130 00:00:21.059109 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.611036 (* 1 = 0.611036 loss)
I0130 00:00:21.059132 30839 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I0130 00:00:57.552271 30839 solver.cpp:218] Iteration 58600 (2.74044 iter/s, 36.4905s/100 iters), loss = 0.697736
I0130 00:00:57.552558 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.697736 (* 1 = 0.697736 loss)
I0130 00:00:57.552588 30839 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I0130 00:01:34.108765 30839 solver.cpp:218] Iteration 58700 (2.73571 iter/s, 36.5536s/100 iters), loss = 0.563859
I0130 00:01:34.114198 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.563859 (* 1 = 0.563859 loss)
I0130 00:01:34.114234 30839 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I0130 00:02:10.600037 30839 solver.cpp:218] Iteration 58800 (2.74097 iter/s, 36.4835s/100 iters), loss = 0.560511
I0130 00:02:10.605420 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.560511 (* 1 = 0.560511 loss)
I0130 00:02:10.605438 30839 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I0130 00:02:47.031519 30839 solver.cpp:218] Iteration 58900 (2.74546 iter/s, 36.4238s/100 iters), loss = 0.546695
I0130 00:02:47.036936 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.546695 (* 1 = 0.546695 loss)
I0130 00:02:47.036974 30839 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I0130 00:03:23.550726 30839 solver.cpp:218] Iteration 59000 (2.73885 iter/s, 36.5117s/100 iters), loss = 0.604376
I0130 00:03:23.556140 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.604376 (* 1 = 0.604376 loss)
I0130 00:03:23.556180 30839 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I0130 00:03:59.991403 30839 solver.cpp:218] Iteration 59100 (2.74475 iter/s, 36.4333s/100 iters), loss = 0.622174
I0130 00:03:59.996763 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.622174 (* 1 = 0.622174 loss)
I0130 00:03:59.996785 30839 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I0130 00:04:36.434703 30839 solver.cpp:218] Iteration 59200 (2.74454 iter/s, 36.436s/100 iters), loss = 0.602056
I0130 00:04:36.434989 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.602056 (* 1 = 0.602056 loss)
I0130 00:04:36.435019 30839 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I0130 00:05:12.931183 30839 solver.cpp:218] Iteration 59300 (2.74015 iter/s, 36.4943s/100 iters), loss = 0.950103
I0130 00:05:12.936635 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.950103 (* 1 = 0.950103 loss)
I0130 00:05:12.936699 30839 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I0130 00:05:49.405326 30839 solver.cpp:218] Iteration 59400 (2.74221 iter/s, 36.467s/100 iters), loss = 0.4639
I0130 00:05:49.410681 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.4639 (* 1 = 0.4639 loss)
I0130 00:05:49.410696 30839 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I0130 00:06:25.865641 30839 solver.cpp:218] Iteration 59500 (2.74324 iter/s, 36.4533s/100 iters), loss = 0.851979
I0130 00:06:25.871116 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.851979 (* 1 = 0.851979 loss)
I0130 00:06:25.871160 30839 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I0130 00:07:02.298460 30839 solver.cpp:218] Iteration 59600 (2.74531 iter/s, 36.4258s/100 iters), loss = 0.619044
I0130 00:07:02.303855 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.619044 (* 1 = 0.619044 loss)
I0130 00:07:02.303882 30839 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I0130 00:07:38.728839 30839 solver.cpp:218] Iteration 59700 (2.74548 iter/s, 36.4235s/100 iters), loss = 0.48632
I0130 00:07:38.729109 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.48632 (* 1 = 0.48632 loss)
I0130 00:07:38.729138 30839 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I0130 00:08:15.271672 30839 solver.cpp:218] Iteration 59800 (2.73664 iter/s, 36.5411s/100 iters), loss = 0.693926
I0130 00:08:15.277046 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.693926 (* 1 = 0.693926 loss)
I0130 00:08:15.277068 30839 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I0130 00:08:51.670202 30839 solver.cpp:218] Iteration 59900 (2.74787 iter/s, 36.3918s/100 iters), loss = 0.679665
I0130 00:08:51.670464 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.679665 (* 1 = 0.679665 loss)
I0130 00:08:51.670492 30839 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I0130 00:09:27.593839 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_60000.caffemodel
I0130 00:09:28.551204 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_60000.solverstate
I0130 00:09:29.131734 30839 solver.cpp:218] Iteration 60000 (2.66952 iter/s, 37.4599s/100 iters), loss = 0.722918
I0130 00:09:29.131805 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.722918 (* 1 = 0.722918 loss)
I0130 00:09:29.131817 30839 sgd_solver.cpp:46] MultiStep Status: Iteration 60000, step = 2
I0130 00:09:29.131824 30839 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I0130 00:10:05.522454 30839 solver.cpp:218] Iteration 60100 (2.74806 iter/s, 36.3893s/100 iters), loss = 0.375062
I0130 00:10:05.527779 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.375062 (* 1 = 0.375062 loss)
I0130 00:10:05.527796 30839 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I0130 00:10:41.931352 30839 solver.cpp:218] Iteration 60200 (2.74708 iter/s, 36.4023s/100 iters), loss = 0.416889
I0130 00:10:41.936700 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.416889 (* 1 = 0.416889 loss)
I0130 00:10:41.936714 30839 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I0130 00:11:18.281306 30839 solver.cpp:218] Iteration 60300 (2.75153 iter/s, 36.3434s/100 iters), loss = 0.568637
I0130 00:11:18.286746 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.568637 (* 1 = 0.568637 loss)
I0130 00:11:18.286767 30839 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I0130 00:11:54.685371 30839 solver.cpp:218] Iteration 60400 (2.74744 iter/s, 36.3975s/100 iters), loss = 0.523566
I0130 00:11:54.690731 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.523566 (* 1 = 0.523566 loss)
I0130 00:11:54.690745 30839 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I0130 00:12:31.212198 30839 solver.cpp:218] Iteration 60500 (2.7382 iter/s, 36.5204s/100 iters), loss = 0.49029
I0130 00:12:31.218178 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.49029 (* 1 = 0.49029 loss)
I0130 00:12:31.218212 30839 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I0130 00:13:07.701876 30839 solver.cpp:218] Iteration 60600 (2.74103 iter/s, 36.4827s/100 iters), loss = 0.489137
I0130 00:13:07.707468 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.489137 (* 1 = 0.489137 loss)
I0130 00:13:07.707510 30839 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I0130 00:13:44.038560 30839 solver.cpp:218] Iteration 60700 (2.75254 iter/s, 36.3301s/100 iters), loss = 0.503545
I0130 00:13:44.046036 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.503545 (* 1 = 0.503545 loss)
I0130 00:13:44.046057 30839 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I0130 00:14:20.465690 30839 solver.cpp:218] Iteration 60800 (2.74584 iter/s, 36.4187s/100 iters), loss = 0.553158
I0130 00:14:20.471047 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.553158 (* 1 = 0.553158 loss)
I0130 00:14:20.471061 30839 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I0130 00:14:56.863396 30839 solver.cpp:218] Iteration 60900 (2.7479 iter/s, 36.3914s/100 iters), loss = 0.522681
I0130 00:14:56.868861 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.522681 (* 1 = 0.522681 loss)
I0130 00:14:56.868903 30839 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I0130 00:15:33.368585 30839 solver.cpp:218] Iteration 61000 (2.73981 iter/s, 36.4988s/100 iters), loss = 0.579512
I0130 00:15:33.373946 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.579512 (* 1 = 0.579512 loss)
I0130 00:15:33.373961 30839 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I0130 00:16:09.771709 30839 solver.cpp:218] Iteration 61100 (2.74749 iter/s, 36.3969s/100 iters), loss = 0.56132
I0130 00:16:09.777181 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.56132 (* 1 = 0.56132 loss)
I0130 00:16:09.777215 30839 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I0130 00:16:46.158576 30839 solver.cpp:218] Iteration 61200 (2.74872 iter/s, 36.3806s/100 iters), loss = 0.385534
I0130 00:16:46.164561 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.385534 (* 1 = 0.385534 loss)
I0130 00:16:46.164602 30839 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I0130 00:17:22.613777 30839 solver.cpp:218] Iteration 61300 (2.7436 iter/s, 36.4484s/100 iters), loss = 0.552803
I0130 00:17:22.619139 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.552803 (* 1 = 0.552803 loss)
I0130 00:17:22.619153 30839 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I0130 00:17:59.011852 30839 solver.cpp:218] Iteration 61400 (2.74786 iter/s, 36.3919s/100 iters), loss = 0.412987
I0130 00:17:59.017213 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.412987 (* 1 = 0.412987 loss)
I0130 00:17:59.017227 30839 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I0130 00:18:35.497100 30839 solver.cpp:218] Iteration 61500 (2.7413 iter/s, 36.4791s/100 iters), loss = 0.504722
I0130 00:18:35.502146 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.504722 (* 1 = 0.504722 loss)
I0130 00:18:35.502171 30839 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I0130 00:19:11.841809 30839 solver.cpp:218] Iteration 61600 (2.75187 iter/s, 36.3389s/100 iters), loss = 0.597956
I0130 00:19:11.842123 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.597956 (* 1 = 0.597956 loss)
I0130 00:19:11.842162 30839 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I0130 00:19:48.204203 30839 solver.cpp:218] Iteration 61700 (2.75017 iter/s, 36.3614s/100 iters), loss = 0.393631
I0130 00:19:48.209568 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.393631 (* 1 = 0.393631 loss)
I0130 00:19:48.209583 30839 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I0130 00:20:24.589761 30839 solver.cpp:218] Iteration 61800 (2.74881 iter/s, 36.3794s/100 iters), loss = 0.490743
I0130 00:20:24.590009 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.490743 (* 1 = 0.490743 loss)
I0130 00:20:24.590042 30839 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I0130 00:21:00.919909 30839 solver.cpp:218] Iteration 61900 (2.75261 iter/s, 36.3292s/100 iters), loss = 0.375737
I0130 00:21:00.924978 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.375737 (* 1 = 0.375737 loss)
I0130 00:21:00.924994 30839 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I0130 00:21:37.366364 30839 solver.cpp:218] Iteration 62000 (2.74419 iter/s, 36.4407s/100 iters), loss = 0.434268
I0130 00:21:37.366595 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.434268 (* 1 = 0.434268 loss)
I0130 00:21:37.366616 30839 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I0130 00:22:13.753382 30839 solver.cpp:218] Iteration 62100 (2.7483 iter/s, 36.3861s/100 iters), loss = 0.502461
I0130 00:22:13.758749 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.502461 (* 1 = 0.502461 loss)
I0130 00:22:13.758762 30839 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I0130 00:22:50.100829 30839 solver.cpp:218] Iteration 62200 (2.75168 iter/s, 36.3414s/100 iters), loss = 0.310318
I0130 00:22:50.106204 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.310318 (* 1 = 0.310318 loss)
I0130 00:22:50.106218 30839 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I0130 00:23:26.476737 30839 solver.cpp:218] Iteration 62300 (2.74953 iter/s, 36.3698s/100 iters), loss = 0.446341
I0130 00:23:26.482322 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.446341 (* 1 = 0.446341 loss)
I0130 00:23:26.482360 30839 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I0130 00:24:02.830312 30839 solver.cpp:218] Iteration 62400 (2.75123 iter/s, 36.3473s/100 iters), loss = 0.445718
I0130 00:24:02.835801 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.445718 (* 1 = 0.445718 loss)
I0130 00:24:02.835851 30839 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I0130 00:24:39.187726 30839 solver.cpp:218] Iteration 62500 (2.75094 iter/s, 36.3513s/100 iters), loss = 0.412591
I0130 00:24:39.194743 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.412591 (* 1 = 0.412591 loss)
I0130 00:24:39.194764 30839 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I0130 00:25:15.539075 30839 solver.cpp:218] Iteration 62600 (2.75151 iter/s, 36.3437s/100 iters), loss = 0.563151
I0130 00:25:15.544483 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.563151 (* 1 = 0.563151 loss)
I0130 00:25:15.544509 30839 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I0130 00:25:51.946208 30839 solver.cpp:218] Iteration 62700 (2.74717 iter/s, 36.4011s/100 iters), loss = 0.516841
I0130 00:25:51.947579 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.516841 (* 1 = 0.516841 loss)
I0130 00:25:51.947615 30839 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I0130 00:26:28.328948 30839 solver.cpp:218] Iteration 62800 (2.74871 iter/s, 36.3807s/100 iters), loss = 0.525692
I0130 00:26:28.329169 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.525692 (* 1 = 0.525692 loss)
I0130 00:26:28.329190 30839 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I0130 00:27:04.687171 30839 solver.cpp:218] Iteration 62900 (2.75047 iter/s, 36.3574s/100 iters), loss = 0.445643
I0130 00:27:04.692528 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.445643 (* 1 = 0.445643 loss)
I0130 00:27:04.692543 30839 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I0130 00:27:41.048704 30839 solver.cpp:218] Iteration 63000 (2.75061 iter/s, 36.3555s/100 iters), loss = 0.645068
I0130 00:27:41.049113 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.645068 (* 1 = 0.645068 loss)
I0130 00:27:41.049145 30839 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I0130 00:28:17.363628 30839 solver.cpp:218] Iteration 63100 (2.75376 iter/s, 36.3139s/100 iters), loss = 0.543458
I0130 00:28:17.369243 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.543458 (* 1 = 0.543458 loss)
I0130 00:28:17.369282 30839 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I0130 00:28:53.745050 30839 solver.cpp:218] Iteration 63200 (2.74912 iter/s, 36.3752s/100 iters), loss = 0.584319
I0130 00:28:53.750442 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.584319 (* 1 = 0.584319 loss)
I0130 00:28:53.750468 30839 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I0130 00:29:30.066747 30839 solver.cpp:218] Iteration 63300 (2.75363 iter/s, 36.3157s/100 iters), loss = 0.471165
I0130 00:29:30.072180 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.471165 (* 1 = 0.471165 loss)
I0130 00:29:30.072197 30839 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I0130 00:30:06.413069 30839 solver.cpp:218] Iteration 63400 (2.75177 iter/s, 36.3403s/100 iters), loss = 0.438791
I0130 00:30:06.418689 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.438791 (* 1 = 0.438791 loss)
I0130 00:30:06.418728 30839 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I0130 00:30:42.748572 30839 solver.cpp:218] Iteration 63500 (2.7526 iter/s, 36.3293s/100 iters), loss = 0.413283
I0130 00:30:42.753942 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.413283 (* 1 = 0.413283 loss)
I0130 00:30:42.753957 30839 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I0130 00:31:19.143786 30839 solver.cpp:218] Iteration 63600 (2.74807 iter/s, 36.3892s/100 iters), loss = 0.655549
I0130 00:31:19.149277 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.655549 (* 1 = 0.655549 loss)
I0130 00:31:19.149324 30839 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I0130 00:31:55.513294 30839 solver.cpp:218] Iteration 63700 (2.75001 iter/s, 36.3635s/100 iters), loss = 0.628705
I0130 00:31:55.518659 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.628705 (* 1 = 0.628705 loss)
I0130 00:31:55.518674 30839 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I0130 00:32:31.904067 30839 solver.cpp:218] Iteration 63800 (2.7484 iter/s, 36.3848s/100 iters), loss = 0.615606
I0130 00:32:31.909616 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.615606 (* 1 = 0.615606 loss)
I0130 00:32:31.909665 30839 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I0130 00:33:08.313655 30839 solver.cpp:218] Iteration 63900 (2.74696 iter/s, 36.4038s/100 iters), loss = 0.515529
I0130 00:33:08.313894 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.515529 (* 1 = 0.515529 loss)
I0130 00:33:08.313913 30839 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I0130 00:33:44.605846 30839 solver.cpp:218] Iteration 64000 (2.75538 iter/s, 36.2927s/100 iters), loss = 0.622075
I0130 00:33:44.606117 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.622075 (* 1 = 0.622075 loss)
I0130 00:33:44.606139 30839 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I0130 00:34:20.976125 30839 solver.cpp:218] Iteration 64100 (2.74947 iter/s, 36.3706s/100 iters), loss = 0.37372
I0130 00:34:20.981505 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.37372 (* 1 = 0.37372 loss)
I0130 00:34:20.981524 30839 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I0130 00:34:57.461833 30839 solver.cpp:218] Iteration 64200 (2.74116 iter/s, 36.4809s/100 iters), loss = 0.467973
I0130 00:34:57.467447 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.467973 (* 1 = 0.467973 loss)
I0130 00:34:57.467483 30839 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I0130 00:35:33.808476 30839 solver.cpp:218] Iteration 64300 (2.75167 iter/s, 36.3415s/100 iters), loss = 0.439619
I0130 00:35:33.808807 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.439619 (* 1 = 0.439619 loss)
I0130 00:35:33.808841 30839 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I0130 00:36:10.175294 30839 solver.cpp:218] Iteration 64400 (2.74975 iter/s, 36.367s/100 iters), loss = 0.453557
I0130 00:36:10.175652 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.453557 (* 1 = 0.453557 loss)
I0130 00:36:10.175684 30839 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I0130 00:36:46.598580 30839 solver.cpp:218] Iteration 64500 (2.74549 iter/s, 36.4233s/100 iters), loss = 0.47806
I0130 00:36:46.603677 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.47806 (* 1 = 0.47806 loss)
I0130 00:36:46.603713 30839 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I0130 00:37:24.408799 30839 solver.cpp:218] Iteration 64600 (2.64512 iter/s, 37.8055s/100 iters), loss = 0.358138
I0130 00:37:24.414221 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.358138 (* 1 = 0.358138 loss)
I0130 00:37:24.414243 30839 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I0130 00:38:00.797231 30839 solver.cpp:218] Iteration 64700 (2.74851 iter/s, 36.3833s/100 iters), loss = 0.499733
I0130 00:38:00.802714 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.499733 (* 1 = 0.499733 loss)
I0130 00:38:00.802763 30839 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I0130 00:38:37.272825 30839 solver.cpp:218] Iteration 64800 (2.74196 iter/s, 36.4703s/100 iters), loss = 0.235123
I0130 00:38:37.273161 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.235123 (* 1 = 0.235123 loss)
I0130 00:38:37.273195 30839 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I0130 00:39:13.674651 30839 solver.cpp:218] Iteration 64900 (2.74713 iter/s, 36.4017s/100 iters), loss = 0.47139
I0130 00:39:13.680055 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.47139 (* 1 = 0.47139 loss)
I0130 00:39:13.680093 30839 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I0130 00:39:49.685317 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_65000.caffemodel
I0130 00:39:50.372757 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_65000.solverstate
I0130 00:39:50.951660 30839 solver.cpp:218] Iteration 65000 (2.68299 iter/s, 37.2718s/100 iters), loss = 0.250827
I0130 00:39:50.951730 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.250827 (* 1 = 0.250827 loss)
I0130 00:39:50.951746 30839 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I0130 00:40:27.287820 30839 solver.cpp:218] Iteration 65100 (2.75208 iter/s, 36.3361s/100 iters), loss = 0.343445
I0130 00:40:27.295642 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.343445 (* 1 = 0.343445 loss)
I0130 00:40:27.295675 30839 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I0130 00:41:03.663229 30839 solver.cpp:218] Iteration 65200 (2.7497 iter/s, 36.3676s/100 iters), loss = 0.518778
I0130 00:41:03.663538 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.518778 (* 1 = 0.518778 loss)
I0130 00:41:03.663566 30839 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I0130 00:41:40.042464 30839 solver.cpp:218] Iteration 65300 (2.74884 iter/s, 36.379s/100 iters), loss = 0.471845
I0130 00:41:40.042783 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.471845 (* 1 = 0.471845 loss)
I0130 00:41:40.042812 30839 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I0130 00:42:16.328392 30839 solver.cpp:218] Iteration 65400 (2.75591 iter/s, 36.2856s/100 iters), loss = 0.401009
I0130 00:42:16.333742 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.401009 (* 1 = 0.401009 loss)
I0130 00:42:16.333756 30839 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I0130 00:42:52.701575 30839 solver.cpp:218] Iteration 65500 (2.74968 iter/s, 36.3678s/100 iters), loss = 0.505303
I0130 00:42:52.701805 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.505303 (* 1 = 0.505303 loss)
I0130 00:42:52.701827 30839 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I0130 00:43:29.106477 30839 solver.cpp:218] Iteration 65600 (2.7469 iter/s, 36.4046s/100 iters), loss = 0.296499
I0130 00:43:29.111937 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.296499 (* 1 = 0.296499 loss)
I0130 00:43:29.111979 30839 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I0130 00:43:59.389153 30839 blocking_queue.cpp:49] Waiting for data
I0130 00:44:05.421707 30839 solver.cpp:218] Iteration 65700 (2.75408 iter/s, 36.3098s/100 iters), loss = 0.389756
I0130 00:44:05.427251 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.389756 (* 1 = 0.389756 loss)
I0130 00:44:05.427281 30839 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I0130 00:44:41.707933 30839 solver.cpp:218] Iteration 65800 (2.75629 iter/s, 36.2806s/100 iters), loss = 0.397162
I0130 00:44:41.713423 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.397162 (* 1 = 0.397162 loss)
I0130 00:44:41.713469 30839 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I0130 00:45:18.012715 30839 solver.cpp:218] Iteration 65900 (2.75488 iter/s, 36.2992s/100 iters), loss = 0.573309
I0130 00:45:18.018123 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.573309 (* 1 = 0.573309 loss)
I0130 00:45:18.018159 30839 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I0130 00:45:54.396446 30839 solver.cpp:218] Iteration 66000 (2.7489 iter/s, 36.3782s/100 iters), loss = 0.456307
I0130 00:45:54.401808 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.456307 (* 1 = 0.456307 loss)
I0130 00:45:54.401823 30839 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I0130 00:46:30.734529 30839 solver.cpp:218] Iteration 66100 (2.75235 iter/s, 36.3326s/100 iters), loss = 0.37364
I0130 00:46:30.740017 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.37364 (* 1 = 0.37364 loss)
I0130 00:46:30.740043 30839 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I0130 00:47:07.053795 30839 solver.cpp:218] Iteration 66200 (2.75379 iter/s, 36.3136s/100 iters), loss = 0.432154
I0130 00:47:07.059161 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.432154 (* 1 = 0.432154 loss)
I0130 00:47:07.059175 30839 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I0130 00:47:43.321288 30839 solver.cpp:218] Iteration 66300 (2.75771 iter/s, 36.2619s/100 iters), loss = 0.566279
I0130 00:47:43.326880 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.566279 (* 1 = 0.566279 loss)
I0130 00:47:43.326910 30839 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I0130 00:48:19.628134 30839 solver.cpp:218] Iteration 66400 (2.75474 iter/s, 36.3011s/100 iters), loss = 0.309917
I0130 00:48:19.633512 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.309917 (* 1 = 0.309917 loss)
I0130 00:48:19.633530 30839 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I0130 00:48:56.017756 30839 solver.cpp:218] Iteration 66500 (2.74846 iter/s, 36.384s/100 iters), loss = 0.434299
I0130 00:48:56.018069 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.434299 (* 1 = 0.434299 loss)
I0130 00:48:56.018121 30839 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I0130 00:49:32.304800 30839 solver.cpp:218] Iteration 66600 (2.75584 iter/s, 36.2866s/100 iters), loss = 0.468789
I0130 00:49:32.310153 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.468789 (* 1 = 0.468789 loss)
I0130 00:49:32.310168 30839 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I0130 00:50:08.641572 30839 solver.cpp:218] Iteration 66700 (2.75246 iter/s, 36.3312s/100 iters), loss = 0.289886
I0130 00:50:08.647127 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.289886 (* 1 = 0.289886 loss)
I0130 00:50:08.647159 30839 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I0130 00:50:44.976532 30839 solver.cpp:218] Iteration 66800 (2.75261 iter/s, 36.3292s/100 iters), loss = 0.403853
I0130 00:50:44.982096 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.403853 (* 1 = 0.403853 loss)
I0130 00:50:44.982139 30839 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I0130 00:51:21.302209 30839 solver.cpp:218] Iteration 66900 (2.75331 iter/s, 36.3199s/100 iters), loss = 0.376347
I0130 00:51:21.307829 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.376347 (* 1 = 0.376347 loss)
I0130 00:51:21.307852 30839 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I0130 00:51:57.747650 30839 solver.cpp:218] Iteration 67000 (2.74427 iter/s, 36.4395s/100 iters), loss = 0.400003
I0130 00:51:57.753258 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.400003 (* 1 = 0.400003 loss)
I0130 00:51:57.753291 30839 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I0130 00:52:34.075965 30839 solver.cpp:218] Iteration 67100 (2.75312 iter/s, 36.3225s/100 iters), loss = 0.363104
I0130 00:52:34.081427 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.363104 (* 1 = 0.363104 loss)
I0130 00:52:34.081447 30839 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I0130 00:53:10.444572 30839 solver.cpp:218] Iteration 67200 (2.75006 iter/s, 36.3629s/100 iters), loss = 0.407256
I0130 00:53:10.444860 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.407256 (* 1 = 0.407256 loss)
I0130 00:53:10.444897 30839 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I0130 00:53:46.858728 30839 solver.cpp:218] Iteration 67300 (2.74623 iter/s, 36.4136s/100 iters), loss = 0.486172
I0130 00:53:46.858997 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.486172 (* 1 = 0.486172 loss)
I0130 00:53:46.859040 30839 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I0130 00:54:23.127889 30839 solver.cpp:218] Iteration 67400 (2.7572 iter/s, 36.2686s/100 iters), loss = 0.306061
I0130 00:54:23.133244 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.306061 (* 1 = 0.306061 loss)
I0130 00:54:23.133258 30839 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I0130 00:54:59.482358 30839 solver.cpp:218] Iteration 67500 (2.75112 iter/s, 36.3488s/100 iters), loss = 0.512508
I0130 00:54:59.488322 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.512508 (* 1 = 0.512508 loss)
I0130 00:54:59.488340 30839 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I0130 00:55:35.814735 30839 solver.cpp:218] Iteration 67600 (2.75284 iter/s, 36.3261s/100 iters), loss = 0.549537
I0130 00:55:35.820379 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.549537 (* 1 = 0.549537 loss)
I0130 00:55:35.820415 30839 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I0130 00:56:12.188737 30839 solver.cpp:218] Iteration 67700 (2.74966 iter/s, 36.3681s/100 iters), loss = 0.262057
I0130 00:56:12.194147 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.262057 (* 1 = 0.262057 loss)
I0130 00:56:12.194166 30839 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I0130 00:56:48.577963 30839 solver.cpp:218] Iteration 67800 (2.7485 iter/s, 36.3834s/100 iters), loss = 0.457164
I0130 00:56:48.583338 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.457164 (* 1 = 0.457164 loss)
I0130 00:56:48.583364 30839 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I0130 00:57:24.911590 30839 solver.cpp:218] Iteration 67900 (2.7527 iter/s, 36.3279s/100 iters), loss = 0.40314
I0130 00:57:24.911797 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.40314 (* 1 = 0.40314 loss)
I0130 00:57:24.911819 30839 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I0130 00:58:01.282876 30839 solver.cpp:218] Iteration 68000 (2.74946 iter/s, 36.3708s/100 iters), loss = 0.342757
I0130 00:58:01.288473 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.342757 (* 1 = 0.342757 loss)
I0130 00:58:01.288507 30839 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I0130 00:58:37.700296 30839 solver.cpp:218] Iteration 68100 (2.74638 iter/s, 36.4115s/100 iters), loss = 0.609394
I0130 00:58:37.705716 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.609394 (* 1 = 0.609394 loss)
I0130 00:58:37.705734 30839 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I0130 00:59:14.088850 30839 solver.cpp:218] Iteration 68200 (2.74855 iter/s, 36.3828s/100 iters), loss = 0.460098
I0130 00:59:14.094471 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.460098 (* 1 = 0.460098 loss)
I0130 00:59:14.094494 30839 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I0130 00:59:50.427811 30839 solver.cpp:218] Iteration 68300 (2.75232 iter/s, 36.3329s/100 iters), loss = 0.405697
I0130 00:59:50.433423 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.405697 (* 1 = 0.405697 loss)
I0130 00:59:50.433460 30839 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I0130 01:00:26.902024 30839 solver.cpp:218] Iteration 68400 (2.74211 iter/s, 36.4683s/100 iters), loss = 0.424863
I0130 01:00:26.907483 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.424863 (* 1 = 0.424863 loss)
I0130 01:00:26.907522 30839 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I0130 01:01:03.323640 30839 solver.cpp:218] Iteration 68500 (2.74607 iter/s, 36.4157s/100 iters), loss = 0.530792
I0130 01:01:03.329144 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.530792 (* 1 = 0.530792 loss)
I0130 01:01:03.329181 30839 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I0130 01:01:39.686558 30839 solver.cpp:218] Iteration 68600 (2.7505 iter/s, 36.3571s/100 iters), loss = 0.281056
I0130 01:01:39.686769 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.281056 (* 1 = 0.281056 loss)
I0130 01:01:39.686800 30839 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I0130 01:02:16.064903 30839 solver.cpp:218] Iteration 68700 (2.74893 iter/s, 36.3778s/100 iters), loss = 0.469308
I0130 01:02:16.065121 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.469308 (* 1 = 0.469308 loss)
I0130 01:02:16.065148 30839 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I0130 01:02:52.446243 30839 solver.cpp:218] Iteration 68800 (2.74871 iter/s, 36.3807s/100 iters), loss = 0.275256
I0130 01:02:52.451866 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.275256 (* 1 = 0.275256 loss)
I0130 01:02:52.451910 30839 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I0130 01:03:28.857524 30839 solver.cpp:218] Iteration 68900 (2.74685 iter/s, 36.4053s/100 iters), loss = 0.265799
I0130 01:03:28.857736 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.265799 (* 1 = 0.265799 loss)
I0130 01:03:28.857766 30839 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I0130 01:04:05.238739 30839 solver.cpp:218] Iteration 69000 (2.74871 iter/s, 36.3806s/100 iters), loss = 0.244846
I0130 01:04:05.238947 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.244846 (* 1 = 0.244846 loss)
I0130 01:04:05.238975 30839 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I0130 01:04:41.581324 30839 solver.cpp:218] Iteration 69100 (2.75164 iter/s, 36.342s/100 iters), loss = 0.401112
I0130 01:04:41.586908 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.401112 (* 1 = 0.401112 loss)
I0130 01:04:41.586940 30839 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I0130 01:05:17.966462 30839 solver.cpp:218] Iteration 69200 (2.74882 iter/s, 36.3792s/100 iters), loss = 0.491435
I0130 01:05:17.972118 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.491435 (* 1 = 0.491435 loss)
I0130 01:05:17.972142 30839 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I0130 01:05:54.390858 30839 solver.cpp:218] Iteration 69300 (2.74587 iter/s, 36.4183s/100 iters), loss = 0.453511
I0130 01:05:54.396440 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.453511 (* 1 = 0.453511 loss)
I0130 01:05:54.396473 30839 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I0130 01:06:30.748541 30839 solver.cpp:218] Iteration 69400 (2.7509 iter/s, 36.3518s/100 iters), loss = 0.345729
I0130 01:06:30.753962 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.345729 (* 1 = 0.345729 loss)
I0130 01:06:30.753980 30839 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I0130 01:07:07.133936 30839 solver.cpp:218] Iteration 69500 (2.7488 iter/s, 36.3795s/100 iters), loss = 0.493683
I0130 01:07:07.139333 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.493683 (* 1 = 0.493683 loss)
I0130 01:07:07.139360 30839 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I0130 01:07:43.497805 30839 solver.cpp:218] Iteration 69600 (2.75036 iter/s, 36.3589s/100 iters), loss = 0.292537
I0130 01:07:43.503469 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.292537 (* 1 = 0.292537 loss)
I0130 01:07:43.503502 30839 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I0130 01:08:19.824131 30839 solver.cpp:218] Iteration 69700 (2.75323 iter/s, 36.321s/100 iters), loss = 0.453308
I0130 01:08:19.830121 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.453308 (* 1 = 0.453308 loss)
I0130 01:08:19.830139 30839 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I0130 01:08:56.211136 30839 solver.cpp:218] Iteration 69800 (2.74866 iter/s, 36.3813s/100 iters), loss = 0.332734
I0130 01:08:56.211328 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.332734 (* 1 = 0.332734 loss)
I0130 01:08:56.211344 30839 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I0130 01:09:32.516432 30839 solver.cpp:218] Iteration 69900 (2.75441 iter/s, 36.3054s/100 iters), loss = 0.268852
I0130 01:09:32.521865 30839 solver.cpp:237]     Train net output #0: softmax_loss = 0.268852 (* 1 = 0.268852 loss)
I0130 01:09:32.521881 30839 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I0130 01:10:08.460455 30839 solver.cpp:447] Snapshotting to binary proto file face_snapshot/vgg_train_test_iter_70000.caffemodel
I0130 01:10:09.158026 30839 sgd_solver.cpp:273] Snapshotting solver state to binary proto file face_snapshot/vgg_train_test_iter_70000.solverstate
I0130 01:10:09.508218 30839 solver.cpp:310] Iteration 70000, loss = 0.27228
I0130 01:10:09.508273 30839 solver.cpp:315] Optimization Done.
I0130 01:10:09.508280 30839 caffe.cpp:259] Optimization Done.
